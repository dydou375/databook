#!/usr/bin/env python3
"""
Extracteur de livres OpenLibrary - Script autonome
==================================================

Ce script extrait les informations des livres depuis les fichiers de donn√©es OpenLibrary
et fournit des fonctions de test pour valider le bon fonctionnement.

Bas√© sur l'analyse du notebook analyse_csv_auteurs.ipynb
"""

import json
import gzip
import os
import pandas as pd
import re
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Optional, Tuple, Union


class ExtracteurLivres:
    """Classe principale pour extraire les informations des livres depuis OpenLibrary"""
    
    def __init__(self, base_path: str):
        """
        Initialise l'extracteur avec le chemin de base des fichiers OpenLibrary
        
        Args:
            base_path: Chemin vers le dossier contenant les fichiers OpenLibrary
        """
        self.base_path = base_path
        self.fichier_editions = None
        self.fichier_works = None
        self.fichier_auteurs = None
        self._detecter_fichiers()
    
    def _detecter_fichiers(self):
        """D√©tecte automatiquement les fichiers disponibles dans le r√©pertoire"""
        print("üîç D√©tection des fichiers disponibles...")
        
        if not os.path.exists(self.base_path):
            print(f"‚ùå Le r√©pertoire {self.base_path} n'existe pas")
            return
        
        for filename in os.listdir(self.base_path):
            file_path = os.path.join(self.base_path, filename)
            
            if 'edition' in filename.lower():
                self.fichier_editions = file_path
                print(f"‚úÖ Fichier √©ditions d√©tect√©: {filename}")
            elif 'work' in filename.lower():
                self.fichier_works = file_path
                print(f"‚úÖ Fichier works d√©tect√©: {filename}")
            elif 'author' in filename.lower():
                self.fichier_auteurs = file_path
                print(f"‚úÖ Fichier auteurs d√©tect√©: {filename}")
    
    def analyser_taille_fichier(self, fichier_path: str) -> Dict:
        """
        Analyse la taille et structure d'un fichier OpenLibrary
        
        Args:
            fichier_path: Chemin vers le fichier √† analyser
            
        Returns:
            Dictionnaire avec les informations du fichier
        """
        if not os.path.exists(fichier_path):
            return {'erreur': 'Fichier non trouv√©'}
        
        taille_octets = os.path.getsize(fichier_path)
        taille_mb = taille_octets / (1024 * 1024)
        taille_gb = taille_octets / (1024 * 1024 * 1024)
        
        info = {
            'fichier': os.path.basename(fichier_path),
            'taille_octets': taille_octets,
            'taille_mb': round(taille_mb, 2),
            'taille_gb': round(taille_gb, 2),
            'est_compresse': fichier_path.endswith('.gz')
        }
        
        # Si c'est un fichier gzip, essayer de lire la taille d√©compress√©e
        if info['est_compresse']:
            try:
                import struct
                with open(fichier_path, 'rb') as f:
                    f.seek(-4, 2)
                    taille_decompresse = struct.unpack('<I', f.read(4))[0]
                    info['taille_decompresse_gb'] = round(taille_decompresse / (1024**3), 2)
            except:
                info['taille_decompresse_gb'] = 'Inconnue'
        
        print(f"üìÅ {info['fichier']}")
        print(f"   Taille: {info['taille_mb']} MB ({info['taille_gb']} GB)")
        if 'taille_decompresse_gb' in info:
            print(f"   D√©compress√©: {info['taille_decompresse_gb']} GB")
        
        return info
    
    def extraire_editions_echantillon(self, max_livres: int = 1000, 
                                    criteres: Optional[Dict] = None) -> List[Dict]:
        """
        Extrait un √©chantillon d'√©ditions selon des crit√®res sp√©cifiques
        
        Args:
            max_livres: Nombre maximum de livres √† extraire
            criteres: Dictionnaire de crit√®res de filtrage
            
        Returns:
            Liste de dictionnaires contenant les informations des livres
        """
        if not self.fichier_editions:
            print("‚ùå Aucun fichier d'√©ditions disponible")
            return []
        
        print(f"üìö Extraction de {max_livres:,} √©ditions depuis {os.path.basename(self.fichier_editions)}")
        
        # Crit√®res par d√©faut
        if criteres is None:
            criteres = {
                'avec_titre': True,
                'avec_isbn': False,
                'avec_auteur': False,
                'annee_min': None,
                'annee_max': None,
                'langues': None
            }
        
        livres_extraits = []
        total_traites = 0
        editions_trouvees = 0
        
        try:
            # Ouvrir le fichier (gzip ou normal)
            open_func = gzip.open if self.fichier_editions.endswith('.gz') else open
            mode = 'rt' if self.fichier_editions.endswith('.gz') else 'r'
            
            with open_func(self.fichier_editions, mode, encoding='utf-8') as f:
                for i, ligne in enumerate(f):
                    if len(livres_extraits) >= max_livres:
                        break
                    
                    parties = ligne.strip().split('\t')
                    if len(parties) >= 5 and parties[0] == '/type/edition':
                        editions_trouvees += 1
                        
                        try:
                            donnees_json = json.loads(parties[4])
                            livre = self._extraire_infos_livre(parties, donnees_json)
                            
                            # Appliquer les crit√®res de filtrage
                            if self._respecte_criteres(livre, criteres):
                                livres_extraits.append(livre)
                        
                        except (json.JSONDecodeError, Exception):
                            continue
                    
                    total_traites += 1
                    
                    # Afficher le progr√®s
                    if total_traites % 10000 == 0:
                        print(f"   Trait√©: {total_traites:,} - √âditions: {editions_trouvees:,} - Extraits: {len(livres_extraits):,}")
        
        except Exception as e:
            print(f"‚ùå Erreur lors de l'extraction: {e}")
            return []
        
        print(f"‚úÖ Extraction termin√©e: {len(livres_extraits):,} livres extraits")
        return livres_extraits
    
    def _extraire_infos_livre(self, parties: List[str], donnees_json: Dict) -> Dict:
        """
        Extrait les informations structur√©es d'un livre depuis les donn√©es JSON
        
        Args:
            parties: Parties de la ligne (type, id, revision, timestamp, json)
            donnees_json: Donn√©es JSON pars√©es du livre
            
        Returns:
            Dictionnaire avec les informations du livre
        """
        livre = {
            'type_entree': parties[0],
            'id_livre': parties[1],
            'revision': parties[2],
            'timestamp': parties[3],
            'titre': donnees_json.get('title', ''),
            'sous_titre': donnees_json.get('subtitle', ''),
            'isbn_10': '',
            'isbn_13': '',
            'editeurs': '',
            'date_publication': donnees_json.get('publish_date', ''),
            'annee_publication': None,
            'nombre_pages': donnees_json.get('number_of_pages', ''),
            'langues': '',
            'auteurs': '',
            'oeuvres': '',
            'format_physique': donnees_json.get('physical_format', ''),
            'nom_edition': donnees_json.get('edition_name', ''),
            'description': '',
            'sujets': '',
            'couvertures': '',
            'poids': donnees_json.get('weight', ''),
            'dimensions': donnees_json.get('dimensions', '')
        }
        
        # Extraire l'ann√©e de publication
        if livre['date_publication']:
            match_annee = re.search(r'\b(\d{4})\b', str(livre['date_publication']))
            if match_annee:
                annee = int(match_annee.group(1))
                if 1000 <= annee <= datetime.now().year:
                    livre['annee_publication'] = annee
        
        # Extraire ISBN
        if 'isbn_10' in donnees_json and donnees_json['isbn_10']:
            livre['isbn_10'] = self._extraire_premier_element(donnees_json['isbn_10'])
        
        if 'isbn_13' in donnees_json and donnees_json['isbn_13']:
            livre['isbn_13'] = self._extraire_premier_element(donnees_json['isbn_13'])
        
        # Extraire √©diteurs
        if 'publishers' in donnees_json and donnees_json['publishers']:
            if isinstance(donnees_json['publishers'], list):
                livre['editeurs'] = ' | '.join(donnees_json['publishers'])
            else:
                livre['editeurs'] = str(donnees_json['publishers'])
        
        # Extraire langues
        if 'languages' in donnees_json and donnees_json['languages']:
            langues = []
            for lang in donnees_json['languages']:
                if isinstance(lang, dict) and 'key' in lang:
                    code_langue = lang['key'].replace('/languages/', '')
                    langues.append(code_langue)
                else:
                    langues.append(str(lang))
            livre['langues'] = ' | '.join(langues)
        
        # Extraire auteurs
        if 'authors' in donnees_json and donnees_json['authors']:
            auteurs = []
            for auteur in donnees_json['authors']:
                if isinstance(auteur, dict) and 'key' in auteur:
                    auteurs.append(auteur['key'])
                else:
                    auteurs.append(str(auteur))
            livre['auteurs'] = ' | '.join(auteurs)
        
        # Extraire ≈ìuvres li√©es
        if 'works' in donnees_json and donnees_json['works']:
            oeuvres = []
            for oeuvre in donnees_json['works']:
                if isinstance(oeuvre, dict) and 'key' in oeuvre:
                    oeuvres.append(oeuvre['key'])
                else:
                    oeuvres.append(str(oeuvre))
            livre['oeuvres'] = ' | '.join(oeuvres)
        
        # Extraire description
        if 'description' in donnees_json:
            desc = donnees_json['description']
            if isinstance(desc, dict) and 'value' in desc:
                livre['description'] = desc['value']
            elif isinstance(desc, str):
                livre['description'] = desc
        
        # Extraire sujets
        if 'subjects' in donnees_json and donnees_json['subjects']:
            if isinstance(donnees_json['subjects'], list):
                livre['sujets'] = ' | '.join(donnees_json['subjects'])
            else:
                livre['sujets'] = str(donnees_json['subjects'])
        
        # Extraire couvertures
        if 'covers' in donnees_json and donnees_json['covers']:
            if isinstance(donnees_json['covers'], list):
                livre['couvertures'] = ' | '.join([str(c) for c in donnees_json['covers']])
            else:
                livre['couvertures'] = str(donnees_json['covers'])
        
        return livre
    
    def _extraire_premier_element(self, element: Union[str, List]) -> str:
        """Extrait le premier √©l√©ment d'une liste ou retourne la cha√Æne"""
        if isinstance(element, list) and element:
            return str(element[0])
        return str(element) if element else ''
    
    def _respecte_criteres(self, livre: Dict, criteres: Dict) -> bool:
        """
        V√©rifie si un livre respecte les crit√®res de filtrage
        
        Args:
            livre: Dictionnaire avec les informations du livre
            criteres: Crit√®res de filtrage
            
        Returns:
            True si le livre respecte tous les crit√®res
        """
        # Titre requis
        if criteres.get('avec_titre', True) and not livre['titre']:
            return False
        
        # ISBN requis
        if criteres.get('avec_isbn', False) and not (livre['isbn_10'] or livre['isbn_13']):
            return False
        
        # Auteur requis
        if criteres.get('avec_auteur', False) and not livre['auteurs']:
            return False
        
        # Filtrage par ann√©e
        if livre['annee_publication']:
            if criteres.get('annee_min') and livre['annee_publication'] < criteres['annee_min']:
                return False
            if criteres.get('annee_max') and livre['annee_publication'] > criteres['annee_max']:
                return False
        
        # Filtrage par langue
        if criteres.get('langues') and livre['langues']:
            langues_livre = livre['langues'].split(' | ')
            langues_acceptees = criteres['langues']
            if not any(lang in langues_acceptees for lang in langues_livre):
                return False
        
        return True
    
    def analyser_livres_extraits(self, livres: List[Dict]) -> pd.DataFrame:
        """
        Analyse les livres extraits et retourne un DataFrame avec des statistiques
        
        Args:
            livres: Liste des livres extraits
            
        Returns:
            DataFrame pandas avec les livres et des statistiques
        """
        if not livres:
            print("‚ùå Aucun livre √† analyser")
            return pd.DataFrame()
        
        print(f"\nüìä ANALYSE DE {len(livres):,} LIVRES EXTRAITS")
        print("=" * 60)
        
        df = pd.DataFrame(livres)
        
        # Statistiques de base
        print(f"üìè Dimensions: {df.shape[0]:,} livres √ó {df.shape[1]} colonnes")
        
        # Taux de remplissage des m√©tadonn√©es
        print(f"\nüìã QUALIT√â DES M√âTADONN√âES:")
        champs_importants = ['titre', 'annee_publication', 'isbn_13', 'isbn_10', 
                        'editeurs', 'langues', 'auteurs', 'nombre_pages', 'description']
        
        for champ in champs_importants:
            if champ in df.columns:
                non_vides = df[champ].notna() & (df[champ] != '')
                pourcentage = (non_vides.sum() / len(df)) * 100
                print(f"   ‚Ä¢ {champ:<20} : {non_vides.sum():>6,} ({pourcentage:>5.1f}%)")
        
        # Analyse des ann√©es de publication
        if 'annee_publication' in df.columns:
            annees = df['annee_publication'].dropna()
            if len(annees) > 0:
                print(f"\nüìÖ ANN√âES DE PUBLICATION:")
                print(f"   ‚Ä¢ Plage: {annees.min():.0f} - {annees.max():.0f}")
                print(f"   ‚Ä¢ Moyenne: {annees.mean():.0f}")
                print(f"   ‚Ä¢ M√©diane: {annees.median():.0f}")
                
                # R√©partition par d√©cennie
                print(f"\n   R√©partition par d√©cennie:")
                for decennie in range(1900, 2030, 10):
                    compte = annees[(annees >= decennie) & (annees < decennie + 10)].count()
                    if compte > 0:
                        pourcentage = (compte / len(annees)) * 100
                        print(f"     - {decennie}s: {compte:,} livres ({pourcentage:.1f}%)")
        
        # Analyse des langues
        if 'langues' in df.columns:
            toutes_langues = []
            for langues in df['langues'].dropna():
                if langues:
                    toutes_langues.extend(langues.split(' | '))
            
            if toutes_langues:
                comptes_langues = pd.Series(toutes_langues).value_counts().head(10)
                print(f"\nüåç TOP 10 LANGUES:")
                for langue, compte in comptes_langues.items():
                    pourcentage = (compte / len(toutes_langues)) * 100
                    print(f"   ‚Ä¢ {langue:<12}: {compte:,} ({pourcentage:.1f}%)")
        
        # Analyse des √©diteurs
        if 'editeurs' in df.columns:
            tous_editeurs = []
            for editeurs in df['editeurs'].dropna():
                if editeurs:
                    tous_editeurs.extend(editeurs.split(' | '))
            
            if tous_editeurs:
                comptes_editeurs = pd.Series(tous_editeurs).value_counts().head(10)
                print(f"\nüè¢ TOP 10 √âDITEURS:")
                for editeur, compte in comptes_editeurs.items():
                    nom_court = editeur[:30] + "..." if len(editeur) > 30 else editeur
                    print(f"   ‚Ä¢ {nom_court:<33}: {compte:,}")
        
        # Analyse des pages
        if 'nombre_pages' in df.columns:
            pages_numeriques = pd.to_numeric(df['nombre_pages'], errors='coerce').dropna()
            if len(pages_numeriques) > 0:
                print(f"\nüìÑ STATISTIQUES DES PAGES:")
                print(f"   ‚Ä¢ Moyenne: {pages_numeriques.mean():.0f} pages")
                print(f"   ‚Ä¢ M√©diane: {pages_numeriques.median():.0f} pages")
                print(f"   ‚Ä¢ Min - Max: {pages_numeriques.min():.0f} - {pages_numeriques.max():.0f} pages")
                
                # R√©partition par tranches
                print(f"   ‚Ä¢ R√©partition:")
                print(f"     - Moins de 100 pages: {(pages_numeriques < 100).sum():,}")
                print(f"     - 100-300 pages: {((pages_numeriques >= 100) & (pages_numeriques <= 300)).sum():,}")
                print(f"     - Plus de 300 pages: {(pages_numeriques > 300).sum():,}")
        
        # Exemples de livres avec m√©tadonn√©es riches
        print(f"\nüìö EXEMPLES DE LIVRES AVEC M√âTADONN√âES COMPL√àTES:")
        print("-" * 60)
        
        # Calculer un score de qualit√©
        score_qualite = 0
        for champ in ['isbn_13', 'editeurs', 'auteurs', 'description', 'sujets']:
            if champ in df.columns:
                score_qualite += (df[champ].notna() & (df[champ] != '')).astype(int)
        
        df['score_qualite'] = score_qualite
        livres_qualite = df[df['score_qualite'] >= 3].head(5)
        
        for i, (_, livre) in enumerate(livres_qualite.iterrows(), 1):
            print(f"{i}. üìñ {livre['titre']}")
            if pd.notna(livre['sous_titre']) and livre['sous_titre']:
                print(f"   Sous-titre: {livre['sous_titre']}")
            if pd.notna(livre['annee_publication']):
                print(f"   Ann√©e: {livre['annee_publication']:.0f}")
            if pd.notna(livre['editeurs']) and livre['editeurs']:
                editeurs_courts = livre['editeurs'][:80] + "..." if len(livre['editeurs']) > 80 else livre['editeurs']
                print(f"   √âditeur: {editeurs_courts}")
            if pd.notna(livre['langues']) and livre['langues']:
                print(f"   Langues: {livre['langues']}")
            if pd.notna(livre['isbn_13']) and livre['isbn_13']:
                print(f"   ISBN-13: {livre['isbn_13']}")
            print()
        
        return df
    
    def sauvegarder_livres(self, df: pd.DataFrame, nom_fichier: str = "livres_openlibrary.csv"):
        """
        Sauvegarde le DataFrame des livres en CSV
        
        Args:
            df: DataFrame contenant les livres
            nom_fichier: Nom du fichier de sauvegarde
        """
        try:
            df.to_csv(nom_fichier, index=False, encoding='utf-8')
            print(f"üíæ Livres sauvegard√©s dans: {nom_fichier}")
            print(f"   Nombre de livres: {len(df):,}")
            print(f"   Colonnes: {len(df.columns)}")
        except Exception as e:
            print(f"‚ùå Erreur lors de la sauvegarde: {e}")


def test_extracteur_basique():
    """Test de base de l'extracteur"""
    print("\nüß™ TEST BASIQUE DE L'EXTRACTEUR")
    print("=" * 50)
    
    # Chemin de base (√† adapter selon votre configuration)
    base_path = r"C:\Users\dd758\Formation_IA_Greta\Projet_possible certif\Livre_analyse\data_book\databook\data\fichier_openlibrary"
    
    if not os.path.exists(base_path):
        print(f"‚ùå Chemin de test non trouv√©: {base_path}")
        print("üí° Modifiez la variable 'base_path' dans test_extracteur_basique()")
        return False
    
    # Cr√©er l'extracteur
    extracteur = ExtracteurLivres(base_path)
    
    # V√©rifier qu'au moins un fichier est disponible
    if not extracteur.fichier_editions:
        print("‚ùå Aucun fichier d'√©ditions d√©tect√©")
        return False
    
    # Analyser la taille du fichier
    info_fichier = extracteur.analyser_taille_fichier(extracteur.fichier_editions)
    print(f"‚úÖ Fichier analys√©: {info_fichier}")
    
    # Extraire un petit √©chantillon
    print("\nüìö Extraction d'un √©chantillon de 100 livres...")
    livres = extracteur.extraire_editions_echantillon(max_livres=100)
    
    if not livres:
        print("‚ùå Aucun livre extrait")
        return False
    
    print(f"‚úÖ {len(livres)} livres extraits avec succ√®s")
    
    # Analyser les livres
    df = extracteur.analyser_livres_extraits(livres)
    
    if df.empty:
        print("‚ùå DataFrame vide")
        return False
    
    print(f"‚úÖ DataFrame cr√©√© avec {len(df)} livres")
    return True


def test_extracteur_avance():
    """Test avanc√© avec crit√®res de filtrage"""
    print("\nüß™ TEST AVANC√â AVEC CRIT√àRES")
    print("=" * 50)
    
    base_path = r"C:\Users\dd758\Formation_IA_Greta\Projet_possible certif\Livre_analyse\data_book\databook\data\fichier_openlibrary"
    
    if not os.path.exists(base_path):
        print(f"‚ùå Chemin de test non trouv√©: {base_path}")
        return False
    
    extracteur = ExtracteurLivres(base_path)
    
    # Crit√®res de filtrage avanc√©s
    criteres = {
        'avec_titre': True,
        'avec_isbn': True,
        'avec_auteur': True,
        'annee_min': 2000,
        'annee_max': 2024,
        'langues': ['eng', 'fre', 'spa', 'ger']
    }
    
    print("üîç Crit√®res de filtrage:")
    for cle, valeur in criteres.items():
        print(f"   ‚Ä¢ {cle}: {valeur}")
    
    livres = extracteur.extraire_editions_echantillon(max_livres=500, criteres=criteres)
    
    if not livres:
        print("‚ùå Aucun livre correspondant aux crit√®res")
        return False
    
    print(f"‚úÖ {len(livres)} livres extraits selon les crit√®res")
    
    # Analyser et sauvegarder
    df = extracteur.analyser_livres_extraits(livres)
    extracteur.sauvegarder_livres(df, "livres_filtres_test.csv")
    
    return True


def test_performance():
    """Test de performance sur un √©chantillon plus large"""
    print("\nüß™ TEST DE PERFORMANCE")
    print("=" * 50)
    
    base_path = r"C:\Users\dd758\Formation_IA_Greta\Projet_possible certif\Livre_analyse\data_book\databook\data\fichier_openlibrary"
    
    if not os.path.exists(base_path):
        print(f"‚ùå Chemin de test non trouv√©: {base_path}")
        return False
    
    extracteur = ExtracteurLivres(base_path)
    
    # Test avec 5000 livres
    import time
    debut = time.time()
    
    livres = extracteur.extraire_editions_echantillon(max_livres=5000)
    
    fin = time.time()
    duree = fin - debut
    
    if livres:
        print(f"‚úÖ Performance: {len(livres)} livres extraits en {duree:.2f} secondes")
        print(f"   Vitesse: {len(livres)/duree:.1f} livres/seconde")
        
        # Analyse rapide
        df = extracteur.analyser_livres_extraits(livres)
        extracteur.sauvegarder_livres(df, "livres_performance_test.csv")
        
        return True
    else:
        print("‚ùå √âchec du test de performance")
        return False


def main():
    """Fonction principale pour ex√©cuter les tests"""
    print("üöÄ EXTRACTEUR DE LIVRES OPENLIBRARY")
    print("=" * 60)
    print("Ce script extrait les informations des livres depuis les fichiers OpenLibrary")
    print("Bas√© sur l'analyse du notebook analyse_csv_auteurs.ipynb")
    print()
    
    # Ex√©cuter les tests
    tests = [
        ("Test basique", test_extracteur_basique),
        ("Test avanc√©", test_extracteur_avance),
        ("Test performance", test_performance)
    ]
    
    resultats = {}
    
    for nom_test, fonction_test in tests:
        print(f"\n{'='*20} {nom_test.upper()} {'='*20}")
        try:
            resultats[nom_test] = fonction_test()
        except Exception as e:
            print(f"‚ùå Erreur dans {nom_test}: {e}")
            resultats[nom_test] = False
    
    # R√©sum√© des tests
    print(f"\n{'='*20} R√âSUM√â DES TESTS {'='*20}")
    for nom_test, succes in resultats.items():
        statut = "‚úÖ R√âUSSI" if succes else "‚ùå √âCHEC"
        print(f"{nom_test:<20}: {statut}")
    
    # Instruction d'utilisation
    if any(resultats.values()):
        print(f"\nüí° UTILISATION PERSONNALIS√âE:")
        print(f"   # Cr√©er un extracteur")
        print(f"   extracteur = ExtracteurLivres('chemin/vers/dossier/openlibrary')")
        print(f"   ")
        print(f"   # Extraire des livres avec crit√®res")
        print(f"   criteres = {{'avec_isbn': True, 'annee_min': 2000}}")
        print(f"   livres = extracteur.extraire_editions_echantillon(max_livres=1000, criteres=criteres)")
        print(f"   ")
        print(f"   # Analyser et sauvegarder")
        print(f"   df = extracteur.analyser_livres_extraits(livres)")
        print(f"   extracteur.sauvegarder_livres(df, 'mes_livres.csv')")


if __name__ == "__main__":
    main()