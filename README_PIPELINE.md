# ğŸš€ PIPELINE MASTER DATABOOK

Un systÃ¨me automatisÃ© complet pour la rÃ©cupÃ©ration et le traitement des donnÃ©es de livres.

## ğŸ¯ Qu'est-ce que c'est ?

Le **Pipeline DataBook** est un systÃ¨me qui automatise entiÃ¨rement la chaÃ®ne de traitement des donnÃ©es de votre projet d'analyse de livres :

1. **ğŸ“¡ RÃ©cupÃ©ration automatique** depuis les APIs (Google Books, OpenLibrary)
2. **ğŸ•·ï¸ Scrapping intelligent** des critiques (Babelio)
3. **ğŸ“Š Nettoyage et formatage** des donnÃ©es CSV
4. **ğŸ—„ï¸ Import automatique** vers PostgreSQL et MongoDB
5. **âœ… Validation et monitoring** complets

## âš¡ DÃ©marrage ultra-rapide

```bash
# Test et lancement automatique
python test_pipeline.py --rapide
python demarrage_rapide.py --auto

# Ou dÃ©marrage interactif
python pipeline_master.py
```

## ğŸ“‹ Ce qui a Ã©tÃ© crÃ©Ã©

### ğŸ¯ Scripts principaux
- **`pipeline_master.py`** : Script principal avec menu interactif
- **`demarrage_rapide.py`** : Lancement automatique avec dÃ©tection environnement
- **`test_pipeline.py`** : Tests complets de validation

### âš™ï¸ Configuration
- **`config_pipeline.json`** : Configuration complÃ¨te du pipeline
- **`GUIDE_PIPELINE.md`** : Guide dÃ©taillÃ© d'utilisation

### ğŸ”§ FonctionnalitÃ©s

#### ğŸ¤– DÃ©tection automatique
- âœ… Modules Python installÃ©s
- âœ… Structure des dossiers
- âœ… Connexions aux bases de donnÃ©es
- âœ… Espace disque disponible
- âœ… Recommandations automatiques

#### ğŸ“Š 3 configurations prÃªtes
- **ğŸš€ Minimale** : 100 livres, tests rapides (5-10 min)
- **ğŸ“Š Standard** : 1000 livres, usage normal (30-60 min)  
- **ğŸ¯ ComplÃ¨te** : 5000+ livres, production (2-4h)

#### ğŸ”„ ExÃ©cution flexible
- **Pipeline complet** : Toutes les Ã©tapes en une fois
- **Ã‰tapes individuelles** : API, scrapping, BDD sÃ©parÃ©ment
- **Mode interactif** : Menu avec choix utilisateur
- **Mode automatique** : Zero configuration

#### ğŸ“‹ Monitoring avancÃ©
- **Logs dÃ©taillÃ©s** : Timestamp, niveaux, messages
- **Rapports JSON** : Statistiques, erreurs, durÃ©es
- **Progression en temps rÃ©el** : Affichage Ã©tape par Ã©tape

## ğŸš€ Utilisation

### Option 1 : Le plus simple
```bash
python demarrage_rapide.py --auto
```
â†’ DÃ©tection automatique + configuration optimale + lancement

### Option 2 : Avec choix de configuration
```bash
python demarrage_rapide.py --auto --config standard
```

### Option 3 : Menu interactif complet
```bash
python pipeline_master.py
```
â†’ Menu avec 9 options (pipeline complet, Ã©tapes individuelles, diagnostics...)

### Option 4 : Tests avant utilisation
```bash
python test_pipeline.py --complet
```

## ğŸ“Š Qu'est-ce que Ã§a fait concrÃ¨tement ?

### Ã‰tape 1 : ğŸ“¡ RÃ©cupÃ©ration API (10-30 min)
- **Depuis Google Books** : MÃ©tadonnÃ©es livres par catÃ©gories
- **Depuis OpenLibrary** : DonnÃ©es bibliographiques Ã©tendues
- **RÃ©sultat** : Fichiers JSON organisÃ©s par source et catÃ©gorie

### Ã‰tape 2 : ğŸ•·ï¸ Scrapping Babelio (20-120 min)
- **Recherche par ISBN** depuis vos donnÃ©es existantes
- **Extraction** : Critiques, notes, rÃ©partition Ã©toiles
- **RÃ©sultat** : Fichiers JSON avec donnÃ©es sociales

### Ã‰tape 3 : ğŸ“Š Nettoyage CSV (5-15 min)
- **DÃ©duplication** automatique
- **Validation** : ISBN, dates, formats
- **Normalisation** : Encodage, structure
- **RÃ©sultat** : CSV propres prÃªts pour BDD

### Ã‰tape 4 : ğŸ—„ï¸ Import PostgreSQL (10-60 min)
- **Tables relationnelles** : livre, auteur, editeur, langue, sujet
- **Relations** : Tables de liaison automatiques
- **Performance** : ~1000 livres/minute
- **RÃ©sultat** : Base relationnelle normalisÃ©e

### Ã‰tape 5 : ğŸƒ Import MongoDB (5-20 min)
- **Documents JSON** : Structure dÃ©normalisÃ©e
- **Index automatiques** : titre, auteurs, ISBN
- **Collections** : livres avec donnÃ©es complÃ¨tes
- **RÃ©sultat** : Base NoSQL pour requÃªtes rapides

## ğŸ› ï¸ Configuration automatique

Le systÃ¨me s'adapte automatiquement Ã  votre environnement :

### ğŸ” DÃ©tection intelligente
- **Modules manquants** â†’ Proposition d'installation automatique
- **Espace disque limitÃ©** â†’ Configuration minimale recommandÃ©e
- **BDD inaccessibles** â†’ Adaptation du pipeline
- **Erreurs rÃ©seau** â†’ Retry automatique avec dÃ©lais

### âš™ï¸ 3 niveaux de configuration

| Configuration | Livres API | Scrapping | DurÃ©e | Espace | Usage |
|---------------|------------|-----------|-------|--------|-------|
| **ğŸš€ Minimale** | 100 | 50 | 5-10 min | ~50 MB | Tests, dÃ©veloppement |
| **ğŸ“Š Standard** | 1000 | 500 | 30-60 min | ~500 MB | DÃ©mos, analyses |
| **ğŸ¯ ComplÃ¨te** | 5000+ | 2000+ | 2-4h | ~2 GB | Production, ML |

## ğŸ“ Structure crÃ©Ã©e

```
databook/
â”œâ”€â”€ ğŸ¯ pipeline_master.py          # Script principal 
â”œâ”€â”€ ğŸš€ demarrage_rapide.py         # Lancement auto
â”œâ”€â”€ ğŸ§ª test_pipeline.py            # Tests validation
â”œâ”€â”€ âš™ï¸ config_pipeline.json        # Configuration
â”œâ”€â”€ ğŸ“– GUIDE_PIPELINE.md           # Guide dÃ©taillÃ©
â”œâ”€â”€ ğŸ“„ README_PIPELINE.md          # Ce fichier
â”‚
â”œâ”€â”€ scripts/                       # Vos scripts existants
â”‚   â”œâ”€â”€ api/                      # RÃ©cupÃ©ration API
â”‚   â””â”€â”€ scrapping/                # Scrapping web
â”‚
â”œâ”€â”€ bdd/                          # Scripts base de donnÃ©es
â”‚   â”œâ”€â”€ livres/                   # PostgreSQL
â”‚   â””â”€â”€ nosql/                    # MongoDB
â”‚
â””â”€â”€ data/                         # DonnÃ©es gÃ©nÃ©rÃ©es
    â”œâ”€â”€ livre_json/               # Fichiers JSON
    â””â”€â”€ *.csv                     # Fichiers CSV
```

## ğŸ”§ Personnalisation

### Modifier les limites
```python
# Dans pipeline_master.py ou config_pipeline.json
config['api']['max_livres_par_categorie'] = 2000
config['scrapping']['max_livres_babelio'] = 1000
```

### Ajouter une source de donnÃ©es
1. CrÃ©er script dans `scripts/api/mon_nouveau_script.py`
2. Modifier `pipeline_master.py` pour l'inclure
3. Ajouter configuration dans `config_pipeline.json`

### Changer les bases de donnÃ©es
```json
{
  "bdd": {
    "postgresql": {
      "url": "postgresql://user:pass@server:5432/db"
    },
    "mongodb": {
      "url": "mongodb://server:27017/"
    }
  }
}
```

## ğŸš¨ RÃ©solution des problÃ¨mes

### âŒ Modules manquants
```bash
pip install requests pandas beautifulsoup4 sqlalchemy psycopg2-binary pymongo
```

### âŒ Bases de donnÃ©es inaccessibles
- PostgreSQL : VÃ©rifier que le service est dÃ©marrÃ©
- MongoDB : VÃ©rifier la connexion avec `mongo --host localhost:27017`

### âŒ Timeouts API
- RÃ©duire `max_livres_par_categorie` dans la config
- Augmenter `delai_requetes` pour Ã©viter le rate limiting

### âŒ Espace disque insuffisant
- Utiliser configuration "minimale"
- Nettoyer avec : `python pipeline_master.py` â†’ Option 8

## ğŸ“Š Monitoring et rapports

### Logs automatiques
- **Fichier** : `pipeline_master_YYYYMMDD_HHMMSS.log`
- **Contenu** : Progression, erreurs, statistiques

### Rapports JSON
- **Fichier** : `rapport_pipeline_YYYYMMDD_HHMMSS.json`
- **Contenu** : Configuration, rÃ©sultats, durÃ©es, erreurs

### Diagnostics
```bash
python demarrage_rapide.py --status
python test_pipeline.py --rapide
```

## ğŸ“ Exemples d'usage

### DÃ©veloppement rapide
```bash
python demarrage_rapide.py --config minimal
# 100 livres en 10 minutes pour tests
```

### DÃ©monstration
```bash
python demarrage_rapide.py --config standard  
# 1000 livres en 1 heure pour prÃ©sentation
```

### Production
```bash
python demarrage_rapide.py --config complet
# 5000+ livres en quelques heures pour analyses
```

### Tests uniquement
```bash
python test_pipeline.py --complet
# Validation complÃ¨te avant utilisation
```

## ğŸ”„ Workflow recommandÃ©

### 1ï¸âƒ£ PremiÃ¨re utilisation
```bash
# Tests pour validation
python test_pipeline.py --rapide

# Si OK, lancement minimal pour test
python demarrage_rapide.py --config minimal

# Si tout fonctionne, configuration standard
python demarrage_rapide.py --config standard
```

### 2ï¸âƒ£ Utilisation rÃ©guliÃ¨re
```bash
# Lancement automatique optimal
python demarrage_rapide.py --auto
```

### 3ï¸âƒ£ Maintenance
```bash
# Diagnostics
python demarrage_rapide.py --status

# Tests complets
python test_pipeline.py --complet

# Nettoyage
python pipeline_master.py  # Option 8
```

## ğŸ“ˆ Performances attendues

### RÃ©cupÃ©ration API
- **Google Books** : ~40 livres/requÃªte, 1 requÃªte/2s
- **OpenLibrary** : ~100 livres/requÃªte, 1 requÃªte/3s
- **DÃ©bit moyen** : ~1000 livres/heure

### Scrapping Babelio
- **Recherche** : 1 livre/3s avec dÃ©lais
- **Extraction** : MÃ©tadonnÃ©es + critiques + notes
- **DÃ©bit moyen** : ~500 livres/heure

### Import bases de donnÃ©es
- **PostgreSQL** : ~1000 livres/minute
- **MongoDB** : ~2000 documents/minute

## ğŸ† Avantages du pipeline

### âœ… Pour vous
- **ZÃ©ro configuration** : DÃ©tection automatique
- **Gain de temps Ã©norme** : Heures â†’ Minutes
- **FiabilitÃ©** : Gestion d'erreurs, retry automatique
- **FlexibilitÃ©** : Ã‰tapes individuelles ou complÃ¨tes

### âœ… Pour votre projet
- **DonnÃ©es cohÃ©rentes** : Format standardisÃ©
- **Volume important** : Milliers de livres facilement
- **Sources multiples** : APIs + scrapping combinÃ©s
- **PrÃªt pour analyse** : BDD relationnelle + NoSQL

### âœ… Pour la maintenance
- **Logs dÃ©taillÃ©s** : Debugging facile
- **Rapports automatiques** : Monitoring inclus
- **Tests intÃ©grÃ©s** : Validation continue
- **Documentation complÃ¨te** : Guide + exemples

---

## ğŸš€ Commencez maintenant !

```bash
# 1. Tests rapides (2 minutes)
python test_pipeline.py --rapide

# 2. Premier essai (10 minutes)  
python demarrage_rapide.py --config minimal

# 3. Si satisfait, configuration complÃ¨te
python demarrage_rapide.py --auto
```

**ğŸ¯ RÃ©sultat** : Des milliers de livres avec mÃ©tadonnÃ©es, critiques et donnÃ©es structurÃ©es, prÃªts pour vos analyses !

---

*Pipeline DataBook v1.0 - Automatisation complÃ¨te de la rÃ©cupÃ©ration de donnÃ©es* 