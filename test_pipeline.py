#!/usr/bin/env python3
"""
TESTS PIPELINE DATABOOK
=======================

Script de tests pour valider le bon fonctionnement du pipeline.
VÃ©rifie tous les composants et dÃ©pendances avant exÃ©cution.

Usage:
    python test_pipeline.py
    python test_pipeline.py --complet
    python test_pipeline.py --rapide
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime
import argparse

# Ajouter le rÃ©pertoire parent au path
sys.path.insert(0, str(Path(__file__).parent))

class TesteurPipeline:
    """Classe de tests pour le pipeline DataBook"""
    
    def __init__(self, mode_complet=False):
        self.workspace = Path(__file__).parent
        self.mode_complet = mode_complet
        self.resultats = {
            'debut': datetime.now(),
            'tests': {},
            'erreurs': [],
            'avertissements': []
        }
        
        print("ğŸ§ª TESTS PIPELINE DATABOOK")
        print("=" * 50)
        print(f"ğŸ“‚ Workspace: {self.workspace}")
        print(f"ğŸ”§ Mode: {'Complet' if mode_complet else 'Rapide'}")
        print()
    
    def test_modules_python(self):
        """Test 1: VÃ©rification des modules Python"""
        print("ğŸ TEST 1: Modules Python")
        print("-" * 30)
        
        modules_requis = {
            'requests': 'ğŸ“¡ RequÃªtes API',
            'pandas': 'ğŸ“Š Traitement donnÃ©es',
            'bs4': 'ğŸ•·ï¸ Scrapping web',
            'sqlalchemy': 'ğŸ—„ï¸ ORM PostgreSQL',
            'pymongo': 'ğŸƒ Driver MongoDB'
        }
        
        modules_optionnels = {
            'psycopg2': 'ğŸ”— Driver PostgreSQL',
            'numpy': 'ğŸ”¢ Calculs numÃ©riques',
            'matplotlib': 'ğŸ“ˆ Graphiques',
            'jupyter': 'ğŸ““ Notebooks'
        }
        
        modules_ok = []
        modules_manquants = []
        
        # Test modules requis
        for module, description in modules_requis.items():
            try:
                __import__(module)
                modules_ok.append(module)
                print(f"âœ… {module}: {description}")
            except ImportError:
                modules_manquants.append(module)
                print(f"âŒ {module}: {description} - MANQUANT")
        
        # Test modules optionnels
        print("\nğŸ“¦ Modules optionnels:")
        for module, description in modules_optionnels.items():
            try:
                __import__(module)
                print(f"âœ… {module}: {description}")
            except ImportError:
                print(f"âš ï¸ {module}: {description} - optionnel")
        
        self.resultats['tests']['modules'] = {
            'requis_ok': modules_ok,
            'requis_manquants': modules_manquants,
            'succes': len(modules_manquants) == 0
        }
        
        if modules_manquants:
            self.resultats['erreurs'].append(f"Modules manquants: {', '.join(modules_manquants)}")
            return False
        
        return True
    
    def test_structure_dossiers(self):
        """Test 2: VÃ©rification structure des dossiers"""
        print("\nğŸ“ TEST 2: Structure des dossiers")
        print("-" * 35)
        
        dossiers_requis = {
            'scripts': 'ğŸ“œ Scripts de rÃ©cupÃ©ration',
            'scripts/api': 'ğŸ“¡ Scripts API',
            'scripts/scrapping': 'ğŸ•·ï¸ Scripts scrapping',
            'bdd': 'ğŸ—„ï¸ Scripts base de donnÃ©es',
            'bdd/livres': 'ğŸ“š Scripts PostgreSQL',
            'bdd/nosql': 'ğŸƒ Scripts MongoDB'
        }
        
        dossiers_optionnels = {
            'data': 'ğŸ“Š DonnÃ©es gÃ©nÃ©rÃ©es',
            'data/livre_json': 'ğŸ“„ Fichiers JSON',
            'data/fichier_openlibrary': 'ğŸ“š DonnÃ©es OpenLibrary',
            'docs': 'ğŸ“‹ Documentation',
            'test': 'ğŸ§ª Tests'
        }
        
        dossiers_ok = []
        dossiers_manquants = []
        
        # Test dossiers requis
        for chemin, description in dossiers_requis.items():
            dossier = self.workspace / chemin
            if dossier.exists() and dossier.is_dir():
                dossiers_ok.append(chemin)
                print(f"âœ… {chemin}: {description}")
            else:
                dossiers_manquants.append(chemin)
                print(f"âŒ {chemin}: {description} - MANQUANT")
        
        # Test dossiers optionnels
        print("\nğŸ“‚ Dossiers optionnels:")
        for chemin, description in dossiers_optionnels.items():
            dossier = self.workspace / chemin
            if dossier.exists() and dossier.is_dir():
                print(f"âœ… {chemin}: {description}")
            else:
                print(f"âš ï¸ {chemin}: {description} - optionnel")
        
        self.resultats['tests']['dossiers'] = {
            'requis_ok': dossiers_ok,
            'requis_manquants': dossiers_manquants,
            'succes': len(dossiers_manquants) == 0
        }
        
        if dossiers_manquants:
            self.resultats['avertissements'].append(f"Dossiers manquants: {', '.join(dossiers_manquants)}")
            return False
        
        return True
    
    def test_fichiers_essentiels(self):
        """Test 3: VÃ©rification des fichiers essentiels"""
        print("\nğŸ“„ TEST 3: Fichiers essentiels")
        print("-" * 30)
        
        fichiers_requis = {
            'pipeline_master.py': 'ğŸ¯ Script principal',
            'demarrage_rapide.py': 'ğŸš€ Script dÃ©marrage',
            'config_pipeline.json': 'âš™ï¸ Configuration'
        }
        
        fichiers_scripts = {
            'scripts/api/recupÃ©ration_api_livre_amelioree.py': 'ğŸ“¡ RÃ©cupÃ©ration API',
            'scripts/scrapping/babelio_scraper_final.py': 'ğŸ•·ï¸ Scrapping Babelio',
            'bdd/livres/formatage_bdd_postgresql.py': 'ğŸ—„ï¸ Import PostgreSQL',
            'bdd/nosql/import_mongodb.py': 'ğŸƒ Import MongoDB'
        }
        
        fichiers_ok = []
        fichiers_manquants = []
        
        # Test fichiers requis
        for fichier, description in fichiers_requis.items():
            chemin = self.workspace / fichier
            if chemin.exists() and chemin.is_file():
                fichiers_ok.append(fichier)
                taille = chemin.stat().st_size / 1024
                print(f"âœ… {fichier}: {description} ({taille:.1f} KB)")
            else:
                fichiers_manquants.append(fichier)
                print(f"âŒ {fichier}: {description} - MANQUANT")
        
        # Test scripts
        print("\nğŸ“œ Scripts spÃ©cialisÃ©s:")
        for fichier, description in fichiers_scripts.items():
            chemin = self.workspace / fichier
            if chemin.exists() and chemin.is_file():
                taille = chemin.stat().st_size / 1024
                print(f"âœ… {fichier}: {description} ({taille:.1f} KB)")
            else:
                print(f"âš ï¸ {fichier}: {description} - non trouvÃ©")
        
        self.resultats['tests']['fichiers'] = {
            'requis_ok': fichiers_ok,
            'requis_manquants': fichiers_manquants,
            'succes': len(fichiers_manquants) == 0
        }
        
        if fichiers_manquants:
            self.resultats['erreurs'].append(f"Fichiers manquants: {', '.join(fichiers_manquants)}")
            return False
        
        return True
    
    def test_configuration(self):
        """Test 4: Validation de la configuration"""
        print("\nâš™ï¸ TEST 4: Configuration")
        print("-" * 25)
        
        try:
            config_file = self.workspace / "config_pipeline.json"
            
            if not config_file.exists():
                print("âŒ Fichier config_pipeline.json manquant")
                self.resultats['erreurs'].append("Configuration manquante")
                return False
            
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # VÃ©rifier les sections essentielles
            sections_requises = ['pipeline', 'api', 'scrapping', 'bdd']
            for section in sections_requises:
                if section in config:
                    print(f"âœ… Section '{section}' prÃ©sente")
                else:
                    print(f"âŒ Section '{section}' manquante")
                    self.resultats['erreurs'].append(f"Section config manquante: {section}")
                    return False
            
            # VÃ©rifier les URLs de base de donnÃ©es
            if 'postgresql' in config['bdd']:
                print(f"âœ… Configuration PostgreSQL")
            else:
                print(f"âš ï¸ Configuration PostgreSQL manquante")
                
            if 'mongodb' in config['bdd']:
                print(f"âœ… Configuration MongoDB")
            else:
                print(f"âš ï¸ Configuration MongoDB manquante")
            
            self.resultats['tests']['configuration'] = {
                'fichier_present': True,
                'sections_ok': sections_requises,
                'succes': True
            }
            
            return True
            
        except json.JSONDecodeError as e:
            print(f"âŒ Erreur JSON dans la configuration: {e}")
            self.resultats['erreurs'].append(f"JSON invalide: {e}")
            return False
        except Exception as e:
            print(f"âŒ Erreur lecture configuration: {e}")
            self.resultats['erreurs'].append(f"Erreur config: {e}")
            return False
    
    def test_imports_pipeline(self):
        """Test 5: Import des modules du pipeline"""
        print("\nğŸ”§ TEST 5: Imports pipeline")
        print("-" * 30)
        
        try:
            # Test import pipeline_master
            from pipeline_master import PipelineMaster
            print("âœ… Import PipelineMaster rÃ©ussi")
            
            # Test instanciation
            pipeline = PipelineMaster()
            print("âœ… Instanciation PipelineMaster rÃ©ussie")
            
            # Test mÃ©thodes essentielles
            if hasattr(pipeline, 'executer_etape_api'):
                print("âœ… MÃ©thode executer_etape_api prÃ©sente")
            else:
                print("âŒ MÃ©thode executer_etape_api manquante")
                return False
            
            if hasattr(pipeline, 'verifier_environnement'):
                print("âœ… MÃ©thode verifier_environnement prÃ©sente")
            else:
                print("âŒ MÃ©thode verifier_environnement manquante")
                return False
            
            self.resultats['tests']['imports'] = {
                'pipeline_master': True,
                'instanciation': True,
                'methodes': True,
                'succes': True
            }
            
            return True
            
        except ImportError as e:
            print(f"âŒ Erreur import pipeline_master: {e}")
            self.resultats['erreurs'].append(f"Import failed: {e}")
            return False
        except Exception as e:
            print(f"âŒ Erreur instanciation: {e}")
            self.resultats['erreurs'].append(f"Instanciation failed: {e}")
            return False
    
    def test_connexions_bdd(self):
        """Test 6: Test des connexions aux bases de donnÃ©es"""
        print("\nğŸ—„ï¸ TEST 6: Connexions bases de donnÃ©es")
        print("-" * 40)
        
        resultats_bdd = {}
        
        # Test PostgreSQL
        try:
            import psycopg2
            print("âœ… Driver PostgreSQL disponible")
            
            # Test de connexion (sans bloquer si Ã©chec)
            try:
                from sqlalchemy import create_engine
                engine = create_engine("postgresql://postgres:postgres@localhost:5432/databook", 
                                    pool_pre_ping=True)
                with engine.connect() as conn:
                    result = conn.execute("SELECT version()")
                    version = result.fetchone()[0]
                    print(f"âœ… PostgreSQL connectÃ©: {version.split(',')[0]}")
                    resultats_bdd['postgresql'] = True
            except Exception as e:
                print(f"âš ï¸ PostgreSQL non accessible: {e}")
                resultats_bdd['postgresql'] = False
                self.resultats['avertissements'].append("PostgreSQL inaccessible")
                
        except ImportError:
            print("âŒ Driver PostgreSQL manquant")
            resultats_bdd['postgresql'] = False
            self.resultats['avertissements'].append("Driver PostgreSQL manquant")
        
        # Test MongoDB
        try:
            import pymongo
            print("âœ… Driver MongoDB disponible")
            
            # Test de connexion
            try:
                client = pymongo.MongoClient("mongodb://localhost:27017/", 
                                           serverSelectionTimeoutMS=3000)
                info = client.server_info()
                print(f"âœ… MongoDB connectÃ©: version {info['version']}")
                resultats_bdd['mongodb'] = True
                client.close()
            except Exception as e:
                print(f"âš ï¸ MongoDB non accessible: {e}")
                resultats_bdd['mongodb'] = False
                self.resultats['avertissements'].append("MongoDB inaccessible")
                
        except ImportError:
            print("âŒ Driver MongoDB manquant")
            resultats_bdd['mongodb'] = False
            self.resultats['avertissements'].append("Driver MongoDB manquant")
        
        self.resultats['tests']['bdd'] = resultats_bdd
        
        # Au moins une BDD doit Ãªtre accessible pour les tests complets
        if self.mode_complet:
            return any(resultats_bdd.values())
        else:
            return True  # En mode rapide, on n'exige pas les BDD
    
    def test_fonctionnel_minimal(self):
        """Test 7: Test fonctionnel minimal du pipeline"""
        if not self.mode_complet:
            return True
            
        print("\nğŸš€ TEST 7: Test fonctionnel minimal")
        print("-" * 35)
        
        try:
            from pipeline_master import PipelineMaster
            
            pipeline = PipelineMaster()
            
            # Test configuration
            print("ğŸ”§ Test modification configuration...")
            pipeline.config['api']['max_livres_par_categorie'] = 10  # TrÃ¨s petit pour test
            print("âœ… Configuration modifiÃ©e")
            
            # Test vÃ©rification environnement
            print("ğŸ” Test vÃ©rification environnement...")
            result = pipeline.verifier_environnement()
            if result:
                print("âœ… VÃ©rification environnement rÃ©ussie")
            else:
                print("âš ï¸ VÃ©rification environnement avec avertissements")
            
            self.resultats['tests']['fonctionnel'] = {
                'configuration': True,
                'verification_env': result,
                'succes': True
            }
            
            return True
            
        except Exception as e:
            print(f"âŒ Erreur test fonctionnel: {e}")
            self.resultats['erreurs'].append(f"Test fonctionnel: {e}")
            return False
    
    def executer_tous_tests(self):
        """ExÃ©cute tous les tests dans l'ordre"""
        tests = [
            ("Modules Python", self.test_modules_python),
            ("Structure dossiers", self.test_structure_dossiers),
            ("Fichiers essentiels", self.test_fichiers_essentiels),
            ("Configuration", self.test_configuration),
            ("Imports pipeline", self.test_imports_pipeline),
            ("Connexions BDD", self.test_connexions_bdd),
        ]
        
        if self.mode_complet:
            tests.append(("Test fonctionnel", self.test_fonctionnel_minimal))
        
        resultats_tests = {}
        tous_ok = True
        
        for nom_test, fonction_test in tests:
            try:
                resultat = fonction_test()
                resultats_tests[nom_test] = resultat
                if not resultat:
                    tous_ok = False
            except Exception as e:
                print(f"\nâŒ ERREUR CRITIQUE dans {nom_test}: {e}")
                resultats_tests[nom_test] = False
                tous_ok = False
                self.resultats['erreurs'].append(f"Erreur critique {nom_test}: {e}")
        
        self.resultats['fin'] = datetime.now()
        self.resultats['duree'] = (self.resultats['fin'] - self.resultats['debut']).total_seconds()
        self.resultats['tests_individuels'] = resultats_tests
        self.resultats['succes_global'] = tous_ok
        
        return tous_ok
    
    def generer_rapport(self):
        """GÃ©nÃ¨re le rapport final des tests"""
        print("\n" + "="*60)
        print("ğŸ“Š RAPPORT FINAL DES TESTS")
        print("="*60)
        
        print(f"â±ï¸ DurÃ©e totale: {self.resultats['duree']:.1f} secondes")
        print(f"ğŸ§ª Mode: {'Complet' if self.mode_complet else 'Rapide'}")
        print()
        
        # RÃ©sultats par test
        print("ğŸ“‹ RÃ‰SULTATS PAR TEST:")
        for nom_test, resultat in self.resultats['tests_individuels'].items():
            icone = "âœ…" if resultat else "âŒ"
            print(f"   {icone} {nom_test}")
        
        # Erreurs
        if self.resultats['erreurs']:
            print(f"\nâŒ ERREURS ({len(self.resultats['erreurs'])}):")
            for erreur in self.resultats['erreurs']:
                print(f"   â€¢ {erreur}")
        
        # Avertissements
        if self.resultats['avertissements']:
            print(f"\nâš ï¸ AVERTISSEMENTS ({len(self.resultats['avertissements'])}):")
            for avertissement in self.resultats['avertissements']:
                print(f"   â€¢ {avertissement}")
        
        # Status final
        print(f"\nğŸ¯ STATUS FINAL:")
        if self.resultats['succes_global']:
            print("   âœ… TOUS LES TESTS RÃ‰USSIS - Pipeline prÃªt Ã  l'utilisation")
        else:
            print("   âŒ Ã‰CHECS DÃ‰TECTÃ‰S - Corriger les erreurs avant utilisation")
        
        # Sauvegarder rapport
        rapport_file = self.workspace / f"test_rapport_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        try:
            with open(rapport_file, 'w', encoding='utf-8') as f:
                json.dump(self.resultats, f, indent=2, default=str)
            print(f"\nğŸ“„ Rapport sauvegardÃ©: {rapport_file.name}")
        except Exception as e:
            print(f"\nâš ï¸ Impossible de sauvegarder le rapport: {e}")
        
        return self.resultats['succes_global']

def main():
    """Fonction principale"""
    parser = argparse.ArgumentParser(description="Tests Pipeline DataBook")
    parser.add_argument('--complet', action='store_true', help='Tests complets avec connexions BDD')
    parser.add_argument('--rapide', action='store_true', help='Tests rapides uniquement')
    
    args = parser.parse_args()
    
    # DÃ©terminer le mode
    if args.complet:
        mode_complet = True
    elif args.rapide:
        mode_complet = False
    else:
        # Mode par dÃ©faut: demander Ã  l'utilisateur
        reponse = input("Tests complets avec BDD? (o/N): ").strip().lower()
        mode_complet = reponse == 'o'
    
    # ExÃ©cuter les tests
    testeur = TesteurPipeline(mode_complet=mode_complet)
    
    try:
        succes = testeur.executer_tous_tests()
        testeur.generer_rapport()
        
        return 0 if succes else 1
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Tests interrompus par l'utilisateur")
        return 2
    except Exception as e:
        print(f"\nâŒ Erreur fatale dans les tests: {e}")
        return 3

if __name__ == "__main__":
    sys.exit(main())