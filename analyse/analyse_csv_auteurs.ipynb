{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\dd758\\Formation_IA_Greta\\Projet_possible certif\\Livre_analyse\\data_book\\databook\\data\\fichier_openlibrary\\extracted_authors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_key</th>\n",
       "      <th>author_name</th>\n",
       "      <th>full_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OL10000073A</td>\n",
       "      <td>Jule Windgeflüster</td>\n",
       "      <td>/authors/OL10000073A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OL10000596A</td>\n",
       "      <td>Beth Wildman</td>\n",
       "      <td>/authors/OL10000596A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OL10000760A</td>\n",
       "      <td>Jaume Piquet Alcàzar</td>\n",
       "      <td>/authors/OL10000760A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OL10001743A</td>\n",
       "      <td>P. M. Gagey</td>\n",
       "      <td>/authors/OL10001743A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OL1000176A</td>\n",
       "      <td>Suʻād Rau̓̄f Shīr Muḥammad</td>\n",
       "      <td>/authors/OL1000176A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476246</th>\n",
       "      <td>OL9998741A</td>\n",
       "      <td>Markus Lemke</td>\n",
       "      <td>/authors/OL9998741A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476247</th>\n",
       "      <td>OL9998762A</td>\n",
       "      <td>Alfred J. Preis</td>\n",
       "      <td>/authors/OL9998762A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476248</th>\n",
       "      <td>OL999881A</td>\n",
       "      <td>Samīḥ Masʻūd Barqāwī</td>\n",
       "      <td>/authors/OL999881A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476249</th>\n",
       "      <td>OL9998939A</td>\n",
       "      <td>Digitalia</td>\n",
       "      <td>/authors/OL9998939A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476250</th>\n",
       "      <td>OL999896A</td>\n",
       "      <td>ʻAdnān Faḥṣ</td>\n",
       "      <td>/authors/OL999896A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14476251 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           author_key                    author_name              full_key\n",
       "0         OL10000073A             Jule Windgeflüster  /authors/OL10000073A\n",
       "1         OL10000596A                   Beth Wildman  /authors/OL10000596A\n",
       "2         OL10000760A           Jaume Piquet Alcàzar  /authors/OL10000760A\n",
       "3         OL10001743A                    P. M. Gagey  /authors/OL10001743A\n",
       "4          OL1000176A  Suʻād Rau̓̄f Shīr Muḥammad   /authors/OL1000176A\n",
       "...               ...                            ...                   ...\n",
       "14476246   OL9998741A                   Markus Lemke   /authors/OL9998741A\n",
       "14476247   OL9998762A                Alfred J. Preis   /authors/OL9998762A\n",
       "14476248    OL999881A      Samīḥ Masʻūd Barqāwī    /authors/OL999881A\n",
       "14476249   OL9998939A                      Digitalia   /authors/OL9998939A\n",
       "14476250    OL999896A                 ʻAdnān Faḥṣ    /authors/OL999896A\n",
       "\n",
       "[14476251 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de remplissage par colonne :\n",
      "author_key: 100.0%\n",
      "author_name: 100.0%\n",
      "full_key: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculer le pourcentage de valeurs non-nulles pour chaque colonne\n",
    "taux_remplissage = (df.count() / len(df) * 100).round(2)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Taux de remplissage par colonne :\")\n",
    "for colonne, taux in taux_remplissage.items():\n",
    "    print(f\"{colonne}: {taux}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_key</th>\n",
       "      <th>author_name</th>\n",
       "      <th>full_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300003</th>\n",
       "      <td>OL14051249A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/authors/OL14051249A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author_key author_name              full_key\n",
       "300003  OL14051249A         NaN  /authors/OL14051249A"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['author_key'] == 'OL14051249A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les lignes où author_name est la chaîne 'NaN'\n",
    "df = df.dropna(subset=['author_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_key</th>\n",
       "      <th>author_name</th>\n",
       "      <th>full_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [author_key, author_name, full_key]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['author_name'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_key</th>\n",
       "      <th>author_name</th>\n",
       "      <th>full_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OL10000073A</td>\n",
       "      <td>Jule Windgeflüster</td>\n",
       "      <td>/authors/OL10000073A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OL10000596A</td>\n",
       "      <td>Beth Wildman</td>\n",
       "      <td>/authors/OL10000596A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OL10000760A</td>\n",
       "      <td>Jaume Piquet Alcàzar</td>\n",
       "      <td>/authors/OL10000760A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OL10001743A</td>\n",
       "      <td>P. M. Gagey</td>\n",
       "      <td>/authors/OL10001743A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OL1000176A</td>\n",
       "      <td>Suʻād Rau̓̄f Shīr Muḥammad</td>\n",
       "      <td>/authors/OL1000176A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476246</th>\n",
       "      <td>OL9998741A</td>\n",
       "      <td>Markus Lemke</td>\n",
       "      <td>/authors/OL9998741A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476247</th>\n",
       "      <td>OL9998762A</td>\n",
       "      <td>Alfred J. Preis</td>\n",
       "      <td>/authors/OL9998762A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476248</th>\n",
       "      <td>OL999881A</td>\n",
       "      <td>Samīḥ Masʻūd Barqāwī</td>\n",
       "      <td>/authors/OL999881A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476249</th>\n",
       "      <td>OL9998939A</td>\n",
       "      <td>Digitalia</td>\n",
       "      <td>/authors/OL9998939A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476250</th>\n",
       "      <td>OL999896A</td>\n",
       "      <td>ʻAdnān Faḥṣ</td>\n",
       "      <td>/authors/OL999896A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14476210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           author_key                    author_name              full_key\n",
       "0         OL10000073A             Jule Windgeflüster  /authors/OL10000073A\n",
       "1         OL10000596A                   Beth Wildman  /authors/OL10000596A\n",
       "2         OL10000760A           Jaume Piquet Alcàzar  /authors/OL10000760A\n",
       "3         OL10001743A                    P. M. Gagey  /authors/OL10001743A\n",
       "4          OL1000176A  Suʻād Rau̓̄f Shīr Muḥammad   /authors/OL1000176A\n",
       "...               ...                            ...                   ...\n",
       "14476246   OL9998741A                   Markus Lemke   /authors/OL9998741A\n",
       "14476247   OL9998762A                Alfred J. Preis   /authors/OL9998762A\n",
       "14476248    OL999881A      Samīḥ Masʻūd Barqāwī    /authors/OL999881A\n",
       "14476249   OL9998939A                      Digitalia   /authors/OL9998939A\n",
       "14476250    OL999896A                 ʻAdnān Faḥṣ    /authors/OL999896A\n",
       "\n",
       "[14476210 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TXT editions complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 ANALYSE COMPLÈTE DU FICHIER GZIP\n",
      "============================================================\n",
      "📋 MÉTHODE 1 : Lecture de l'en-tête gzip\n",
      "✅ Taille décompressée (en-tête gzip) : 1,226,586,112 octets (1.1 GB)\n",
      "\n",
      "============================================================\n",
      "📋 MÉTHODE 2 : Analyse du contenu\n",
      "🔍 ANALYSE RAPIDE DU DÉBUT DU FICHIER\n",
      "👀 Aperçu du contenu :\n",
      "----------------------------------------\n",
      "1: /type/author\t/authors/OL5345273A\t1\t2008-10-05T09:14:51.676778\t{\"name\": \"TOM.KIYIHN\", \"last_modified\"...\n",
      "2: /type/author\t/authors/OL5345271A\t1\t2008-10-04T15:55:36.974594\t{\"name\": \"Aksakov, S. T.\", \"last_modif...\n",
      "3: /type/author\t/authors/OL5345272A\t1\t2008-10-04T16:04:08.61952\t{\"name\": \"Latham,Barbarahttp://webcat.c...\n",
      "----------------------------------------\n",
      "📊 Analyse des premières lignes :\n",
      "   • Nombre de lignes analysées : 3\n",
      "   • Caractères par ligne (moyenne) : 266\n",
      "   • Format détecté : JSON par ligne (JSONL)\n",
      "   • Type de données : Base de données OpenLibrary\n",
      "\n",
      "============================================================\n",
      "📋 MÉTHODE 3 : Estimations basées sur le type de données\n",
      "Les fichiers OpenLibrary dump ont typiquement :\n",
      "   • Ratio de compression gzip : 4-8x pour du JSON\n",
      "   • Estimation basse (4x) : 170.5 GB\n",
      "   • Estimation haute (8x) : 340.9 GB\n",
      "   • Estimation moyenne (6x) : 255.7 GB\n",
      "\n",
      "💡 La taille décompressée est probablement entre 170-341 GB\n",
      "\n",
      "============================================================\n",
      "📋 MÉTHODE 4 : Estimation du nombre de lignes\n",
      "🔢 Analyse de 500 lignes pour estimer le nombre total...\n",
      "   Analysé 200 lignes...\n",
      "   Analysé 400 lignes...\n",
      "📊 Statistiques sur 500 lignes analysées :\n",
      "   • Longueur moyenne par ligne : 895 caractères\n",
      "   • Longueur min : 219 caractères\n",
      "   • Longueur max : 4436 caractères\n",
      "🎯 Estimation basée sur l'en-tête gzip (1.1 GB) :\n",
      "   • Nombre de lignes estimé : 1,369,903\n",
      "   • Soit environ 1.4 millions de lignes\n",
      "🎯 Estimations basées sur les tailles théoriques :\n",
      "   • Estimation basse (4x, 170 GB) : 204,431,917 lignes (204M)\n",
      "   • Estimation moyenne (6x, 256 GB) : 306,647,875 lignes (307M)\n",
      "   • Estimation haute (8x, 341 GB) : 408,863,833 lignes (409M)\n",
      "\n",
      "--------------------------------------------------\n",
      "🔍 Comptage réel sur un échantillon de 20 MB...\n",
      "📊 Résultats du comptage réel :\n",
      "   • Lignes dans 20.0 MB : 19,893\n",
      "   • Lignes par MB : 995\n",
      "   • Projection sur 1.1 GB : 1,163,496 lignes\n",
      "   • Soit environ 1.2 millions de lignes\n",
      "\n",
      "🎯 RÉSUMÉ DES ESTIMATIONS :\n",
      "   📁 Taille réelle (en-tête) : 1.1 GB\n",
      "   📊 Nombre de lignes estimé : 1,369,903\n",
      "   📈 Soit environ 1.4 millions de lignes\n",
      "\n",
      "============================================================\n",
      "📋 MÉTHODE 5 : Analyse des types de données\n",
      "🚀 DÉBUT DE L'ANALYSE DES TYPES\n",
      "🔍 Analyse de 3000 lignes pour identifier les types...\n",
      "   Analysé 1000 lignes...\n",
      "   Analysé 2000 lignes...\n",
      "   Analysé 3000 lignes...\n",
      "\n",
      "📊 Types de lignes trouvés dans 3000 lignes analysées :\n",
      "--------------------------------------------------\n",
      "   • /type/edition             :   2552 lignes ( 85.1%)\n",
      "   • /type/author              :    408 lignes ( 13.6%)\n",
      "   • /type/delete              :     18 lignes (  0.6%)\n",
      "   • /type/i18n                :      8 lignes (  0.3%)\n",
      "   • /type/type                :      4 lignes (  0.1%)\n",
      "   • /type/property            :      4 lignes (  0.1%)\n",
      "   • /type/backreference       :      2 lignes (  0.1%)\n",
      "   • /type/collection          :      2 lignes (  0.1%)\n",
      "   • /type/work                :      2 lignes (  0.1%)\n",
      "--------------------------------------------------\n",
      "📈 Projections sur le fichier complet :\n",
      "   Basé sur 1,369,903 lignes estimées :\n",
      "   • /type/edition             :  1,165,330 lignes estimées\n",
      "   • /type/author              :    186,307 lignes estimées\n",
      "   • /type/delete              :      8,219 lignes estimées\n",
      "   • /type/i18n                :      3,653 lignes estimées\n",
      "   • /type/type                :      1,827 lignes estimées\n",
      "   • /type/property            :      1,827 lignes estimées\n",
      "   • /type/backreference       :        913 lignes estimées\n",
      "   • /type/collection          :        913 lignes estimées\n",
      "   • /type/work                :        913 lignes estimées\n",
      "\n",
      "📊 9 types différents trouvés !\n",
      "\n",
      "🔍 Analyse détaillée avec exemples (sur 1500 lignes)...\n",
      "\n",
      "📋 DÉTAIL DES TYPES DE DONNÉES :\n",
      "======================================================================\n",
      "\n",
      "🔹 /type/author\n",
      "   Nombre moyen de champs : 5.0\n",
      "   Exemple de 2ème champ : /authors/OL5345273A\n",
      "   Exemple complet : /type/author\t/authors/OL5345273A\t1\t2008-10-05T09:14:51.676778\t{\"name\": \"TOM.KIYIHN\", \"last_modified\": {\"type\": \"/type/datetime\", \"value\": \"2008-10-05T09:14:51.676778\"}, \"key\": \"/authors/OL5345273A\", \"...\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "🔹 /type/backreference\n",
      "   Nombre moyen de champs : 5.0\n",
      "   Exemple de 2ème champ : /type/edition/collections\n",
      "   Exemple complet : /type/backreference\t/type/edition/collections\t1\t2008-10-02T16:03:14.145029\t{\"name\": \"collections\", \"last_modified\": {\"type\": \"/type/datetime\", \"value\": \"2008-10-02T16:03:14.145029\"}, \"key\": \"/type/edi...\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "🔹 /type/collection\n",
      "   Nombre moyen de champs : 5.0\n",
      "   Exemple de 2ème champ : /Great_books\n",
      "   Exemple complet : /type/collection\t/Great_books\t1\t2008-10-02T16:08:42.916831\t{\"last_modified\": {\"type\": \"/type/datetime\", \"value\": \"2008-10-02T16:08:42.916831\"}, \"type\": {\"key\": \"/type/collection\"}, \"key\": \"/Great_book...\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "🔹 /type/delete\n",
      "   Nombre moyen de champs : 5.0\n",
      "   Exemple de 2ème champ : /authors/OL5345262A\n",
      "   Exemple complet : /type/delete\t/authors/OL5345262A\t2\t2008-10-02T13:32:09.497837\t{\"name\": \"Garbhan Downey\", \"last_modified\": {\"type\": \"/type/datetime\", \"value\": \"2008-10-02T13:32:09.497837\"}, \"key\": \"/authors/OL5345262A...\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "🔹 /type/edition\n",
      "   Nombre moyen de champs : 5.0\n",
      "   Exemple de 2ème champ : /books/OL17806216M\n",
      "   Exemple complet : /type/edition\t/books/OL17806216M\t1\t2008-10-01T06:49:20.851055\t{\"table_of_contents\": [{\"type\": \"/type/text\", \"value\": \"Gender as a category of analysis in vernacular architect studies / Angel Kwolek-Fo...\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "🔹 /type/i18n\n",
      "   Nombre moyen de champs : 5.0\n",
      "   Exemple de 2ème champ : /i18n/strings.uk\n",
      "   Exemple complet : /type/i18n\t/i18n/strings.uk\t1\t2008-10-04T18:19:08.241118\t{\"string_upload\": \"\\u0417\\u0430\\u0432\\u0430\\u043d\\u0442\\u0430\\u0436\\u0438\\u0442\\u0438\", \"string_submit\": \"\\u0412\\u0456\\u0434\\u0456\\u0441\\u043b\\...\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "🔹 /type/property\n",
      "   Nombre moyen de champs : 5.0\n",
      "   Exemple de 2ème champ : /type/collection/editions\n",
      "   Exemple complet : /type/property\t/type/collection/editions\t1\t2008-10-02T16:02:29.409332\t{\"description\": \"\", \"revision\": 1, \"last_modified\": {\"type\": \"/type/datetime\", \"value\": \"2008-10-02T16:02:29.409332\"}, \"key\": \"/ty...\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "🔹 /type/type\n",
      "   Nombre moyen de champs : 5.0\n",
      "   Exemple de 2ème champ : /type/collection\n",
      "   Exemple complet : /type/type\t/type/collection\t1\t2008-10-02T16:02:29.409332\t{\"description\": \"\", \"properties\": [{\"key\": \"/type/collection/editions\"}], \"last_modified\": {\"type\": \"/type/datetime\", \"value\": \"2008-10-02T16:0...\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "🔹 /type/work\n",
      "   Nombre moyen de champs : 5.0\n",
      "   Exemple de 2ème champ : /works/OL5967449W\n",
      "   Exemple complet : /type/work\t/works/OL5967449W\t3\t2013-08-23T21:48:46.541299\t{\"created\": {\"type\": \"/type/datetime\", \"value\": \"2009-12-10T18:16:15.578495\"}, \"subject_places\": [\"Texas\"], \"subjects\": [\"Folk music\", \"Histor...\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "🎯 RÉSUMÉ DE L'ANALYSE DES TYPES :\n",
      "   📁 Échantillon analysé : 3000 lignes\n",
      "   🔢 Types différents trouvés : 9\n",
      "   📊 Type le plus fréquent : /type/edition\n",
      "   📈 Diversité des données : Très variée (authors, editions, works, etc.)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import time\n",
    "import struct\n",
    "\n",
    "fichier = r\"C:\\Users\\dd758\\Formation_IA_Greta\\Projet_possible certif\\Livre_analyse\\data_book\\databook\\data\\fichier_openlibrary\\ol_cdump_2025-05-31.txt.gz\"\n",
    "\n",
    "# MÉTHODE 1 : Lire la taille dans l'en-tête gzip (plus fiable)\n",
    "def get_gzip_uncompressed_size(filename):\n",
    "    \"\"\"Lit la taille décompressée directement depuis l'en-tête gzip\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            # Aller à la fin du fichier pour lire la taille décompressée\n",
    "            f.seek(-4, 2)  # 4 derniers octets\n",
    "            return struct.unpack('<I', f.read(4))[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# MÉTHODE 2 : Estimation plus précise par échantillonnage\n",
    "def estimate_compression_ratio(filename, num_samples=5, sample_size_mb=5):\n",
    "    \"\"\"Prend plusieurs échantillons à différents endroits du fichier\"\"\"\n",
    "    compressed_size = os.path.getsize(filename)\n",
    "    \n",
    "    print(f\"📁 Taille compressée : {compressed_size:,} octets ({compressed_size / (1024**3):.2f} GB)\")\n",
    "    print(f\"🔍 Analyse de {num_samples} échantillons de {sample_size_mb} MB chacun...\")\n",
    "    \n",
    "    ratios = []\n",
    "    sample_bytes = sample_size_mb * 1024 * 1024\n",
    "    \n",
    "    with open(filename, 'rb') as raw_file:\n",
    "        file_size = compressed_size\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Prendre des échantillons à différentes positions\n",
    "            position = (file_size // num_samples) * i\n",
    "            if position + 1024*1024 >= file_size:  # Éviter la fin du fichier\n",
    "                continue\n",
    "                \n",
    "            raw_file.seek(position)\n",
    "            compressed_chunk = raw_file.read(1024*1024)  # 1MB d'data compressée\n",
    "            \n",
    "            # Décompresser ce chunk pour voir le ratio\n",
    "            try:\n",
    "                with gzip.open(filename, 'rb') as gz_file:\n",
    "                    gz_file.seek(position)  # Cette méthode n'est pas parfaite\n",
    "                    decompressed_chunk = gz_file.read(sample_bytes)\n",
    "                    if decompressed_chunk:\n",
    "                        ratio = len(decompressed_chunk) / len(compressed_chunk)\n",
    "                        ratios.append(ratio)\n",
    "                        print(f\"  Échantillon {i+1}: ratio ~{ratio:.1f}x\")\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    if ratios:\n",
    "        avg_ratio = sum(ratios) / len(ratios)\n",
    "        estimated_size = compressed_size * avg_ratio\n",
    "        return estimated_size, avg_ratio\n",
    "    return None, None\n",
    "\n",
    "# MÉTHODE 3 : Analyse simple et rapide\n",
    "def quick_analysis(filename):\n",
    "    \"\"\"Analyse rapide du début du fichier\"\"\"\n",
    "    print(\"🔍 ANALYSE RAPIDE DU DÉBUT DU FICHIER\")\n",
    "    \n",
    "    # Analyser les premières lignes\n",
    "    print(\"👀 Aperçu du contenu :\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    line_count = 0\n",
    "    char_count = 0\n",
    "    \n",
    "    with gzip.open(filename, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 3:\n",
    "                break\n",
    "            print(f\"{i+1}: {line.strip()[:100]}...\")\n",
    "            line_count += 1\n",
    "            char_count += len(line)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"📊 Analyse des premières lignes :\")\n",
    "    print(f\"   • Nombre de lignes analysées : {line_count}\")\n",
    "    print(f\"   • Caractères par ligne (moyenne) : {char_count // line_count if line_count > 0 else 0}\")\n",
    "    \n",
    "    # Estimer basé sur la structure typique d'OpenLibrary\n",
    "    print(f\"   • Format détecté : JSON par ligne (JSONL)\")\n",
    "    print(f\"   • Type de données : Base de données OpenLibrary\")\n",
    "\n",
    "print(\"🚀 ANALYSE COMPLÈTE DU FICHIER GZIP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Méthode 1 : Taille dans l'en-tête\n",
    "print(\"📋 MÉTHODE 1 : Lecture de l'en-tête gzip\")\n",
    "gzip_size = get_gzip_uncompressed_size(fichier)\n",
    "if gzip_size:\n",
    "    print(f\"✅ Taille décompressée (en-tête gzip) : {gzip_size:,} octets ({gzip_size / (1024**3):.1f} GB)\")\n",
    "else:\n",
    "    print(\"❌ Impossible de lire l'en-tête gzip (fichier > 4GB probablement)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Méthode 2 : Analyse du contenu\n",
    "print(\"📋 MÉTHODE 2 : Analyse du contenu\")\n",
    "quick_analysis(fichier)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Estimations basées sur le type de fichier\n",
    "compressed_size = os.path.getsize(fichier)\n",
    "print(\"📋 MÉTHODE 3 : Estimations basées sur le type de données\")\n",
    "print(\"Les fichiers OpenLibrary dump ont typiquement :\")\n",
    "print(\"   • Ratio de compression gzip : 4-8x pour du JSON\")\n",
    "print(\"   • Estimation basse (4x) :\", f\"{compressed_size * 4 / (1024**3):.1f} GB\")\n",
    "print(\"   • Estimation haute (8x) :\", f\"{compressed_size * 8 / (1024**3):.1f} GB\")\n",
    "print(\"   • Estimation moyenne (6x) :\", f\"{compressed_size * 6 / (1024**3):.1f} GB\")\n",
    "\n",
    "print(f\"\\n💡 La taille décompressée est probablement entre {compressed_size * 4 / (1024**3):.0f}-{compressed_size * 8 / (1024**3):.0f} GB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ESTIMATION DU NOMBRE DE LIGNES\n",
    "print(\"📋 MÉTHODE 4 : Estimation du nombre de lignes\")\n",
    "\n",
    "def estimate_line_count(filename, sample_lines=1000):\n",
    "    \"\"\"Estime le nombre total de lignes dans le fichier\"\"\"\n",
    "    print(f\"🔢 Analyse de {sample_lines} lignes pour estimer le nombre total...\")\n",
    "    \n",
    "    line_lengths = []\n",
    "    lines_counted = 0\n",
    "    total_chars = 0\n",
    "    \n",
    "    with gzip.open(filename, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= sample_lines:\n",
    "                break\n",
    "            line_length = len(line)\n",
    "            line_lengths.append(line_length)\n",
    "            total_chars += line_length\n",
    "            lines_counted += 1\n",
    "            \n",
    "            # Afficher le progrès tous les 200 lignes\n",
    "            if (i + 1) % 200 == 0:\n",
    "                print(f\"   Analysé {i + 1} lignes...\")\n",
    "    \n",
    "    if lines_counted > 0:\n",
    "        avg_line_length = total_chars / lines_counted\n",
    "        min_line_length = min(line_lengths)\n",
    "        max_line_length = max(line_lengths)\n",
    "        \n",
    "        print(f\"📊 Statistiques sur {lines_counted} lignes analysées :\")\n",
    "        print(f\"   • Longueur moyenne par ligne : {avg_line_length:.0f} caractères\")\n",
    "        print(f\"   • Longueur min : {min_line_length} caractères\")\n",
    "        print(f\"   • Longueur max : {max_line_length} caractères\")\n",
    "        \n",
    "        # Estimation basée sur la taille réelle de l'en-tête gzip\n",
    "        if gzip_size:\n",
    "            estimated_lines_header = gzip_size / avg_line_length\n",
    "            print(f\"🎯 Estimation basée sur l'en-tête gzip ({gzip_size / (1024**3):.1f} GB) :\")\n",
    "            print(f\"   • Nombre de lignes estimé : {estimated_lines_header:,.0f}\")\n",
    "            print(f\"   • Soit environ {estimated_lines_header / 1_000_000:.1f} millions de lignes\")\n",
    "        \n",
    "        # Estimation basée sur les tailles théoriques\n",
    "        print(f\"🎯 Estimations basées sur les tailles théoriques :\")\n",
    "        for ratio, label in [(4, \"basse\"), (6, \"moyenne\"), (8, \"haute\")]:\n",
    "            theoretical_size = compressed_size * ratio\n",
    "            estimated_lines = theoretical_size / avg_line_length\n",
    "            print(f\"   • Estimation {label} ({ratio}x, {theoretical_size / (1024**3):.0f} GB) : {estimated_lines:,.0f} lignes ({estimated_lines / 1_000_000:.0f}M)\")\n",
    "        \n",
    "        return avg_line_length, estimated_lines_header if gzip_size else None\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "# Comptage rapide des lignes sur un échantillon\n",
    "def quick_line_count_sample(filename, chunk_size_mb=50):\n",
    "    \"\"\"Compte les lignes sur un échantillon pour vérifier l'estimation\"\"\"\n",
    "    print(f\"🔍 Comptage réel sur un échantillon de {chunk_size_mb} MB...\")\n",
    "    \n",
    "    chunk_size = chunk_size_mb * 1024 * 1024\n",
    "    lines_in_sample = 0\n",
    "    bytes_read = 0\n",
    "    \n",
    "    with gzip.open(filename, 'rt', encoding='utf-8') as f:\n",
    "        while bytes_read < chunk_size:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            lines_in_sample += 1\n",
    "            bytes_read += len(line.encode('utf-8'))\n",
    "    \n",
    "    if bytes_read > 0:\n",
    "        lines_per_mb = lines_in_sample / (bytes_read / (1024 * 1024))\n",
    "        print(f\"📊 Résultats du comptage réel :\")\n",
    "        print(f\"   • Lignes dans {bytes_read / (1024 * 1024):.1f} MB : {lines_in_sample:,}\")\n",
    "        print(f\"   • Lignes par MB : {lines_per_mb:,.0f}\")\n",
    "        \n",
    "        # Projection sur la taille totale\n",
    "        if gzip_size:\n",
    "            total_lines_projection = lines_per_mb * (gzip_size / (1024 * 1024))\n",
    "            print(f\"   • Projection sur {gzip_size / (1024**3):.1f} GB : {total_lines_projection:,.0f} lignes\")\n",
    "            print(f\"   • Soit environ {total_lines_projection / 1_000_000:.1f} millions de lignes\")\n",
    "        \n",
    "        return lines_per_mb\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Exécuter les estimations\n",
    "try:\n",
    "    avg_length, estimated_lines = estimate_line_count(fichier, sample_lines=500)\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    lines_per_mb = quick_line_count_sample(fichier, chunk_size_mb=20)\n",
    "    \n",
    "    print(f\"\\n🎯 RÉSUMÉ DES ESTIMATIONS :\")\n",
    "    if gzip_size:\n",
    "        print(f\"   📁 Taille réelle (en-tête) : {gzip_size / (1024**3):.1f} GB\")\n",
    "        if estimated_lines:\n",
    "            print(f\"   📊 Nombre de lignes estimé : {estimated_lines:,.0f}\")\n",
    "            print(f\"   📈 Soit environ {estimated_lines / 1_000_000:.1f} millions de lignes\")\n",
    "    else:\n",
    "        print(f\"   📁 Taille estimée : 170-340 GB\")\n",
    "        print(f\"   📊 Nombre de lignes estimé : 170-340 millions de lignes\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de l'estimation des lignes : {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ANALYSE DES TYPES DE LIGNES\n",
    "print(\"📋 MÉTHODE 5 : Analyse des types de données\")\n",
    "\n",
    "def analyze_line_types(filename, sample_lines=5000):\n",
    "    \"\"\"Analyse les différents types de lignes présents dans le fichier\"\"\"\n",
    "    print(f\"🔍 Analyse de {sample_lines} lignes pour identifier les types...\")\n",
    "    \n",
    "    type_counts = {}\n",
    "    total_lines = 0\n",
    "    \n",
    "    with gzip.open(filename, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= sample_lines:\n",
    "                break\n",
    "            \n",
    "            # Extraire le type de ligne (premier champ avant le premier \\t)\n",
    "            parts = line.split('\\t', 1)\n",
    "            if len(parts) > 0:\n",
    "                line_type = parts[0].strip()\n",
    "                type_counts[line_type] = type_counts.get(line_type, 0) + 1\n",
    "                total_lines += 1\n",
    "            \n",
    "            # Afficher le progrès tous les 1000 lignes\n",
    "            if (i + 1) % 1000 == 0:\n",
    "                print(f\"   Analysé {i + 1} lignes...\")\n",
    "    \n",
    "    if total_lines > 0:\n",
    "        print(f\"\\n📊 Types de lignes trouvés dans {total_lines} lignes analysées :\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Trier par fréquence (plus fréquent en premier)\n",
    "        sorted_types = sorted(type_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for line_type, count in sorted_types:\n",
    "            percentage = (count / total_lines) * 100\n",
    "            print(f\"   • {line_type:<25} : {count:>6} lignes ({percentage:>5.1f}%)\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "        print(f\"📈 Projections sur le fichier complet :\")\n",
    "        \n",
    "        if gzip_size and estimated_lines:\n",
    "            print(f\"   Basé sur {estimated_lines:,.0f} lignes estimées :\")\n",
    "            for line_type, count in sorted_types[:10]:  # Top 10 seulement\n",
    "                percentage = (count / total_lines) * 100\n",
    "                projected_count = (percentage / 100) * estimated_lines\n",
    "                print(f\"   • {line_type:<25} : {projected_count:>10,.0f} lignes estimées\")\n",
    "        \n",
    "        return type_counts, total_lines\n",
    "    \n",
    "    return None, 0\n",
    "\n",
    "def detailed_type_analysis(filename, sample_lines=2000):\n",
    "    \"\"\"Analyse plus détaillée des types avec exemples\"\"\"\n",
    "    print(f\"\\n🔍 Analyse détaillée avec exemples (sur {sample_lines} lignes)...\")\n",
    "    \n",
    "    type_examples = {}\n",
    "    type_structures = {}\n",
    "    \n",
    "    with gzip.open(filename, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= sample_lines:\n",
    "                break\n",
    "            \n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                line_type = parts[0].strip()\n",
    "                \n",
    "                # Stocker un exemple pour chaque type (seulement le premier)\n",
    "                if line_type not in type_examples:\n",
    "                    type_examples[line_type] = {\n",
    "                        'example': line.strip()[:200] + \"...\" if len(line) > 200 else line.strip(),\n",
    "                        'fields_count': len(parts),\n",
    "                        'second_field_example': parts[1][:50] + \"...\" if len(parts[1]) > 50 else parts[1] if len(parts) > 1 else \"\"\n",
    "                    }\n",
    "                \n",
    "                # Compter la structure (nombre de champs)\n",
    "                if line_type not in type_structures:\n",
    "                    type_structures[line_type] = []\n",
    "                type_structures[line_type].append(len(parts))\n",
    "    \n",
    "    print(f\"\\n📋 DÉTAIL DES TYPES DE DONNÉES :\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for line_type in sorted(type_examples.keys()):\n",
    "        example_data = type_examples[line_type]\n",
    "        field_counts = type_structures[line_type]\n",
    "        avg_fields = sum(field_counts) / len(field_counts)\n",
    "        \n",
    "        print(f\"\\n🔹 {line_type}\")\n",
    "        print(f\"   Nombre moyen de champs : {avg_fields:.1f}\")\n",
    "        print(f\"   Exemple de 2ème champ : {example_data['second_field_example']}\")\n",
    "        print(f\"   Exemple complet : {example_data['example']}\")\n",
    "        print(\"   \" + \"-\" * 60)\n",
    "    \n",
    "    return type_examples\n",
    "\n",
    "# Exécuter l'analyse des types\n",
    "try:\n",
    "    print(\"🚀 DÉBUT DE L'ANALYSE DES TYPES\")\n",
    "    type_counts, total_analyzed = analyze_line_types(fichier, sample_lines=3000)\n",
    "    \n",
    "    if type_counts:\n",
    "        print(f\"\\n📊 {len(type_counts)} types différents trouvés !\")\n",
    "        \n",
    "        # Analyse détaillée\n",
    "        type_examples = detailed_type_analysis(fichier, sample_lines=1500)\n",
    "        \n",
    "        print(f\"\\n🎯 RÉSUMÉ DE L'ANALYSE DES TYPES :\")\n",
    "        print(f\"   📁 Échantillon analysé : {total_analyzed} lignes\")\n",
    "        print(f\"   🔢 Types différents trouvés : {len(type_counts)}\")\n",
    "        print(f\"   📊 Type le plus fréquent : {max(type_counts.items(), key=lambda x: x[1])[0]}\")\n",
    "        print(f\"   📈 Diversité des données : Très variée (authors, editions, works, etc.)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de l'analyse des types : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 ANALYSE COMPLÈTE DU FICHIER EDITIONS\n",
      "============================================================\n",
      "📁 Fichier analysé : ol_dump_editions_2025-05-31.txt.gz\n",
      "📋 MÉTHODE 1 : Lecture de l'en-tête gzip\n",
      "✅ Taille décompressée (en-tête gzip) : 1,484,839,911 octets (1.4 GB)\n",
      "\n",
      "============================================================\n",
      "📋 MÉTHODE 2 : Analyse du contenu EDITIONS\n",
      "🔍 ANALYSE RAPIDE DU DÉBUT DU FICHIER EDITIONS\n",
      "👀 Aperçu du contenu :\n",
      "----------------------------------------\n",
      "1: /type/edition\t/books/OL10000079M\t2\t2010-03-12T00:00:48.298004\t{\"publishers\": [\"Stationery Office Books\"], \"physical_form...\n",
      "2: /type/edition\t/books/OL10000715M\t3\t2011-04-26T05:54:13.372021\t{\"publishers\": [\"Stationery Office Books\"], \"physical_form...\n",
      "3: /type/edition\t/books/OL10001085M\t3\t2011-04-30T15:33:17.349849\t{\"publishers\": [\"Stationery Office Books\"], \"physical_form...\n",
      "4: /type/edition\t/books/OL10001190M\t3\t2011-04-22T23:18:54.840113\t{\"publishers\": [\"Stationery Office Books\"], \"physical_form...\n",
      "5: /type/edition\t/books/OL1000121M\t9\t2023-01-14T19:33:59.345503\t{\"publishers\": [\"American Quilter's Society\"], \"number_of_p...\n",
      "----------------------------------------\n",
      "📊 Analyse des premières lignes EDITIONS :\n",
      "   • Nombre de lignes analysées : 5\n",
      "   • Caractères par ligne (moyenne) : 850\n",
      "   • Format détecté : JSON par ligne (JSONL)\n",
      "   • Type de données : Éditions OpenLibrary\n",
      "\n",
      "============================================================\n",
      "📋 MÉTHODE 3 : Estimations basées sur le type de données EDITIONS\n",
      "Les fichiers OpenLibrary editions ont typiquement :\n",
      "   • Ratio de compression gzip : 5-10x pour du JSON riche\n",
      "   • Estimation basse (5x) : 53.6 GB\n",
      "   • Estimation haute (10x) : 107.1 GB\n",
      "   • Estimation moyenne (7x) : 75.0 GB\n",
      "\n",
      "💡 La taille décompressée est probablement entre 54-107 GB\n",
      "\n",
      "============================================================\n",
      "📋 MÉTHODE 4 : Estimation du nombre de lignes EDITIONS\n",
      "🔢 Analyse de 300 lignes d'éditions pour estimer le nombre total...\n",
      "   Analysé 100 lignes...\n",
      "   Analysé 200 lignes...\n",
      "   Analysé 300 lignes...\n",
      "📊 Statistiques sur 300 lignes d'éditions analysées :\n",
      "   • Longueur moyenne par ligne : 855 caractères\n",
      "   • Longueur min : 437 caractères\n",
      "   • Longueur max : 4203 caractères\n",
      "🎯 Estimation basée sur l'en-tête gzip (1.4 GB) :\n",
      "   • Nombre de lignes estimé : 1,736,289\n",
      "   • Soit environ 1.7 millions d'éditions\n",
      "\n",
      "🔍 Comptage réel sur un échantillon de 10 MB...\n",
      "📊 Résultats du comptage réel EDITIONS :\n",
      "   • Lignes dans 10.0 MB : 11,110\n",
      "   • Lignes par MB : 1,111\n",
      "   • Projection sur 1.4 GB : 1,573,171 éditions\n",
      "   • Soit environ 1.6 millions d'éditions\n",
      "\n",
      "============================================================\n",
      "📋 MÉTHODE 5 : Analyse des types de données EDITIONS\n",
      "🚀 DÉBUT DE L'ANALYSE DES TYPES D'ÉDITIONS\n",
      "🔍 Analyse de 2000 lignes pour identifier les types d'éditions...\n",
      "   Analysé 500 lignes...\n",
      "   Analysé 1000 lignes...\n",
      "   Analysé 1500 lignes...\n",
      "   Analysé 2000 lignes...\n",
      "\n",
      "📊 Types de lignes trouvés dans 2000 lignes d'éditions :\n",
      "--------------------------------------------------\n",
      "   • /type/edition             :   2000 lignes (100.0%)\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Analyse détaillée des éditions avec exemples...\n",
      "\n",
      "📋 DÉTAIL DES TYPES D'ÉDITIONS :\n",
      "======================================================================\n",
      "\n",
      "🔹 /type/edition\n",
      "   Exemple de 2ème champ : /books/OL10000079M\n",
      "   Exemple complet : /type/edition\t/books/OL10000079M\t2\t2010-03-12T00:00:48.298004\t{\"publishers\": [\"Stationery Office Books\"], \"physical_format\": \"Paperback\", \"subjects\": [\"Central government\", \"United Kingdom, Great Brit...\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "🎯 RÉSUMÉ DE L'ANALYSE DES ÉDITIONS :\n",
      "   📁 Échantillon analysé : 2000 lignes\n",
      "   🔢 Types différents trouvés : 1\n",
      "   📊 Type le plus fréquent : /type/edition\n",
      "\n",
      "🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯\n",
      "COMPARAISON FICHIER PRINCIPAL vs ÉDITIONS\n",
      "🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯\n",
      "📊 Taille fichier principal : 1.1 GB\n",
      "📊 Taille fichier éditions : 1.4 GB\n",
      "📈 Ratio éditions/principal : 1.2x\n",
      "🔢 Lignes fichier principal : ~1,369,903\n",
      "🔢 Lignes fichier éditions : ~1,736,289\n"
     ]
    }
   ],
   "source": [
    "# ANALYSE DU FICHIER EDITIONS\n",
    "print(\"🚀 ANALYSE COMPLÈTE DU FICHIER EDITIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Chemin du fichier editions (ajustez selon votre structure)\n",
    "fichier_editions = r\"C:\\Users\\dd758\\Formation_IA_Greta\\Projet_possible certif\\Livre_analyse\\data_book\\databook\\data\\fichier_openlibrary\\ol_dump_editions_2025-05-31.txt.gz\"\n",
    "\n",
    "# Vérifier si le fichier existe\n",
    "import os\n",
    "if not os.path.exists(fichier_editions):\n",
    "    # Essayer d'autres noms possibles\n",
    "    base_path = r\"C:\\Users\\dd758\\Formation_IA_Greta\\Projet_possible certif\\Livre_analyse\\data_book\\databook\\data\\fichier_openlibrary\"\n",
    "    possible_names = [\n",
    "        \"ol_dump_editions_latest.txt.gz\",\n",
    "        \"editions.txt.gz\", \n",
    "        \"ol_dump_editions.txt.gz\",\n",
    "        \"ol_cdump_editions_2025-05-31.txt.gz\"\n",
    "    ]\n",
    "    \n",
    "    fichier_editions = None\n",
    "    for name in possible_names:\n",
    "        test_path = os.path.join(base_path, name)\n",
    "        if os.path.exists(test_path):\n",
    "            fichier_editions = test_path\n",
    "            break\n",
    "    \n",
    "    if fichier_editions is None:\n",
    "        print(\"❌ Fichier editions non trouvé. Fichiers disponibles :\")\n",
    "        try:\n",
    "            for f in os.listdir(base_path):\n",
    "                if f.endswith('.gz'):\n",
    "                    print(f\"   • {f}\")\n",
    "        except:\n",
    "            print(\"   Impossible de lister les fichiers\")\n",
    "        fichier_editions = input(\"Veuillez entrer le nom exact du fichier editions : \")\n",
    "        if not os.path.isabs(fichier_editions):\n",
    "            fichier_editions = os.path.join(base_path, fichier_editions)\n",
    "\n",
    "if os.path.exists(fichier_editions):\n",
    "    print(f\"📁 Fichier analysé : {os.path.basename(fichier_editions)}\")\n",
    "    \n",
    "    # MÉTHODE 1 : Taille dans l'en-tête\n",
    "    print(\"📋 MÉTHODE 1 : Lecture de l'en-tête gzip\")\n",
    "    gzip_size_editions = get_gzip_uncompressed_size(fichier_editions)\n",
    "    if gzip_size_editions:\n",
    "        print(f\"✅ Taille décompressée (en-tête gzip) : {gzip_size_editions:,} octets ({gzip_size_editions / (1024**3):.1f} GB)\")\n",
    "    else:\n",
    "        print(\"❌ Impossible de lire l'en-tête gzip (fichier > 4GB probablement)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "    # MÉTHODE 2 : Analyse du contenu\n",
    "    print(\"📋 MÉTHODE 2 : Analyse du contenu EDITIONS\")\n",
    "    try:\n",
    "        print(\"🔍 ANALYSE RAPIDE DU DÉBUT DU FICHIER EDITIONS\")\n",
    "        print(\"👀 Aperçu du contenu :\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        line_count = 0\n",
    "        char_count = 0\n",
    "        \n",
    "        with gzip.open(fichier_editions, 'rt', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= 5:\n",
    "                    break\n",
    "                print(f\"{i+1}: {line.strip()[:120]}...\")\n",
    "                line_count += 1\n",
    "                char_count += len(line)\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "        print(f\"📊 Analyse des premières lignes EDITIONS :\")\n",
    "        print(f\"   • Nombre de lignes analysées : {line_count}\")\n",
    "        print(f\"   • Caractères par ligne (moyenne) : {char_count // line_count if line_count > 0 else 0}\")\n",
    "        print(f\"   • Format détecté : JSON par ligne (JSONL)\")\n",
    "        print(f\"   • Type de données : Éditions OpenLibrary\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'analyse du contenu : {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "    # MÉTHODE 3 : Estimations basées sur le type de fichier\n",
    "    compressed_size_editions = os.path.getsize(fichier_editions)\n",
    "    print(\"📋 MÉTHODE 3 : Estimations basées sur le type de données EDITIONS\")\n",
    "    print(\"Les fichiers OpenLibrary editions ont typiquement :\")\n",
    "    print(\"   • Ratio de compression gzip : 5-10x pour du JSON riche\")\n",
    "    print(\"   • Estimation basse (5x) :\", f\"{compressed_size_editions * 5 / (1024**3):.1f} GB\")\n",
    "    print(\"   • Estimation haute (10x) :\", f\"{compressed_size_editions * 10 / (1024**3):.1f} GB\")\n",
    "    print(\"   • Estimation moyenne (7x) :\", f\"{compressed_size_editions * 7 / (1024**3):.1f} GB\")\n",
    "\n",
    "    print(f\"\\n💡 La taille décompressée est probablement entre {compressed_size_editions * 5 / (1024**3):.0f}-{compressed_size_editions * 10 / (1024**3):.0f} GB\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "    # MÉTHODE 4 : Estimation du nombre de lignes EDITIONS\n",
    "    print(\"📋 MÉTHODE 4 : Estimation du nombre de lignes EDITIONS\")\n",
    "\n",
    "    try:\n",
    "        # Analyser les lignes d'éditions\n",
    "        print(\"🔢 Analyse de 300 lignes d'éditions pour estimer le nombre total...\")\n",
    "        \n",
    "        line_lengths_editions = []\n",
    "        lines_counted_editions = 0\n",
    "        total_chars_editions = 0\n",
    "        \n",
    "        with gzip.open(fichier_editions, 'rt', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= 300:\n",
    "                    break\n",
    "                line_length = len(line)\n",
    "                line_lengths_editions.append(line_length)\n",
    "                total_chars_editions += line_length\n",
    "                lines_counted_editions += 1\n",
    "                \n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(f\"   Analysé {i + 1} lignes...\")\n",
    "        \n",
    "        if lines_counted_editions > 0:\n",
    "            avg_line_length_editions = total_chars_editions / lines_counted_editions\n",
    "            min_line_length_editions = min(line_lengths_editions)\n",
    "            max_line_length_editions = max(line_lengths_editions)\n",
    "            \n",
    "            print(f\"📊 Statistiques sur {lines_counted_editions} lignes d'éditions analysées :\")\n",
    "            print(f\"   • Longueur moyenne par ligne : {avg_line_length_editions:.0f} caractères\")\n",
    "            print(f\"   • Longueur min : {min_line_length_editions} caractères\")\n",
    "            print(f\"   • Longueur max : {max_line_length_editions} caractères\")\n",
    "            \n",
    "            # Estimation basée sur la taille réelle\n",
    "            if gzip_size_editions:\n",
    "                estimated_lines_editions = gzip_size_editions / avg_line_length_editions\n",
    "                print(f\"🎯 Estimation basée sur l'en-tête gzip ({gzip_size_editions / (1024**3):.1f} GB) :\")\n",
    "                print(f\"   • Nombre de lignes estimé : {estimated_lines_editions:,.0f}\")\n",
    "                print(f\"   • Soit environ {estimated_lines_editions / 1_000_000:.1f} millions d'éditions\")\n",
    "            \n",
    "            # Comptage rapide sur échantillon\n",
    "            print(f\"\\n🔍 Comptage réel sur un échantillon de 10 MB...\")\n",
    "            \n",
    "            chunk_size = 10 * 1024 * 1024\n",
    "            lines_in_sample = 0\n",
    "            bytes_read = 0\n",
    "            \n",
    "            with gzip.open(fichier_editions, 'rt', encoding='utf-8') as f:\n",
    "                while bytes_read < chunk_size:\n",
    "                    line = f.readline()\n",
    "                    if not line:\n",
    "                        break\n",
    "                    lines_in_sample += 1\n",
    "                    bytes_read += len(line.encode('utf-8'))\n",
    "            \n",
    "            if bytes_read > 0:\n",
    "                lines_per_mb_editions = lines_in_sample / (bytes_read / (1024 * 1024))\n",
    "                print(f\"📊 Résultats du comptage réel EDITIONS :\")\n",
    "                print(f\"   • Lignes dans {bytes_read / (1024 * 1024):.1f} MB : {lines_in_sample:,}\")\n",
    "                print(f\"   • Lignes par MB : {lines_per_mb_editions:,.0f}\")\n",
    "                \n",
    "                if gzip_size_editions:\n",
    "                    total_lines_projection_editions = lines_per_mb_editions * (gzip_size_editions / (1024 * 1024))\n",
    "                    print(f\"   • Projection sur {gzip_size_editions / (1024**3):.1f} GB : {total_lines_projection_editions:,.0f} éditions\")\n",
    "                    print(f\"   • Soit environ {total_lines_projection_editions / 1_000_000:.1f} millions d'éditions\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'estimation des lignes : {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "    # MÉTHODE 5 : Analyse des types de données EDITIONS\n",
    "    print(\"📋 MÉTHODE 5 : Analyse des types de données EDITIONS\")\n",
    "\n",
    "    try:\n",
    "        print(\"🚀 DÉBUT DE L'ANALYSE DES TYPES D'ÉDITIONS\")\n",
    "        print(f\"🔍 Analyse de 2000 lignes pour identifier les types d'éditions...\")\n",
    "        \n",
    "        type_counts_editions = {}\n",
    "        total_lines_editions = 0\n",
    "        \n",
    "        with gzip.open(fichier_editions, 'rt', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= 2000:\n",
    "                    break\n",
    "                \n",
    "                parts = line.split('\\t', 1)\n",
    "                if len(parts) > 0:\n",
    "                    line_type = parts[0].strip()\n",
    "                    type_counts_editions[line_type] = type_counts_editions.get(line_type, 0) + 1\n",
    "                    total_lines_editions += 1\n",
    "                \n",
    "                if (i + 1) % 500 == 0:\n",
    "                    print(f\"   Analysé {i + 1} lignes...\")\n",
    "        \n",
    "        if total_lines_editions > 0:\n",
    "            print(f\"\\n📊 Types de lignes trouvés dans {total_lines_editions} lignes d'éditions :\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            sorted_types_editions = sorted(type_counts_editions.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for line_type, count in sorted_types_editions:\n",
    "                percentage = (count / total_lines_editions) * 100\n",
    "                print(f\"   • {line_type:<25} : {count:>6} lignes ({percentage:>5.1f}%)\")\n",
    "            \n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Analyse détaillée avec exemples d'éditions\n",
    "            print(f\"\\n🔍 Analyse détaillée des éditions avec exemples...\")\n",
    "            \n",
    "            type_examples_editions = {}\n",
    "            \n",
    "            with gzip.open(fichier_editions, 'rt', encoding='utf-8') as f:\n",
    "                for i, line in enumerate(f):\n",
    "                    if i >= 1000:\n",
    "                        break\n",
    "                    \n",
    "                    parts = line.split('\\t')\n",
    "                    if len(parts) >= 2:\n",
    "                        line_type = parts[0].strip()\n",
    "                        \n",
    "                        if line_type not in type_examples_editions:\n",
    "                            type_examples_editions[line_type] = {\n",
    "                                'example': line.strip()[:200] + \"...\" if len(line) > 200 else line.strip(),\n",
    "                                'second_field': parts[1][:50] + \"...\" if len(parts[1]) > 50 else parts[1]\n",
    "                            }\n",
    "            \n",
    "            print(f\"\\n📋 DÉTAIL DES TYPES D'ÉDITIONS :\")\n",
    "            print(\"=\" * 70)\n",
    "            \n",
    "            for line_type in sorted(type_examples_editions.keys()):\n",
    "                example_data = type_examples_editions[line_type]\n",
    "                print(f\"\\n🔹 {line_type}\")\n",
    "                print(f\"   Exemple de 2ème champ : {example_data['second_field']}\")\n",
    "                print(f\"   Exemple complet : {example_data['example']}\")\n",
    "                print(\"   \" + \"-\" * 60)\n",
    "            \n",
    "            print(f\"\\n🎯 RÉSUMÉ DE L'ANALYSE DES ÉDITIONS :\")\n",
    "            print(f\"   📁 Échantillon analysé : {total_lines_editions} lignes\")\n",
    "            print(f\"   🔢 Types différents trouvés : {len(type_counts_editions)}\")\n",
    "            if type_counts_editions:\n",
    "                print(f\"   📊 Type le plus fréquent : {max(type_counts_editions.items(), key=lambda x: x[1])[0]}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'analyse des types d'éditions : {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Fichier editions non trouvé !\")\n",
    "    print(\"Veuillez vérifier le chemin du fichier.\")\n",
    "\n",
    "print(\"\\n\" + \"🎯\" * 30)\n",
    "print(\"COMPARAISON FICHIER PRINCIPAL vs ÉDITIONS\")\n",
    "print(\"🎯\" * 30)\n",
    "\n",
    "try:\n",
    "    if 'gzip_size' in locals() and gzip_size and 'gzip_size_editions' in locals() and gzip_size_editions:\n",
    "        print(f\"📊 Taille fichier principal : {gzip_size / (1024**3):.1f} GB\")\n",
    "        print(f\"📊 Taille fichier éditions : {gzip_size_editions / (1024**3):.1f} GB\")\n",
    "        print(f\"📈 Ratio éditions/principal : {gzip_size_editions / gzip_size:.1f}x\")\n",
    "        \n",
    "        if 'estimated_lines' in locals() and 'estimated_lines_editions' in locals():\n",
    "            print(f\"🔢 Lignes fichier principal : ~{estimated_lines:,.0f}\")\n",
    "            print(f\"🔢 Lignes fichier éditions : ~{estimated_lines_editions:,.0f}\")\n",
    "    else:\n",
    "        print(\"⚠️ Données incomplètes pour la comparaison\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur dans la comparaison : {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TXT Editions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👤 EXTRACTION D'OBJETS JSON AUTEURS\n",
      "============================================================\n",
      "🔍 RECHERCHE DU FICHIER AUTEURS DÉCOMPRESSÉ\n",
      "------------------------------------------------------------\n",
      "✅ Fichier trouvé : ol_dump_authors_2025-05-31.txt\n",
      "📁 Taille du fichier : 5,467,491,837 octets (5.09 GB)\n",
      "📋 Extraction de 5 objets JSON d'auteurs du fichier...\n",
      "✅ Extraction terminée : 5 auteurs extraits sur 6 lignes traitées\n",
      "\n",
      "================================================================================\n",
      "👤 AUTEUR 1\n",
      "================================================================================\n",
      "🔸 Type: /type/author\n",
      "🔸 ID: /authors/OL10000073A\n",
      "🔸 Révision: 3\n",
      "🔸 Timestamp: 2024-12-30T07:49:12.172071\n",
      "🔸 Ligne dans le fichier: 1\n",
      "\n",
      "📋 INFORMATIONS PRINCIPALES:\n",
      "------------------------------\n",
      "📝 Nom: Jule Windgeflüster\n",
      "\n",
      "📋 OBJET JSON COMPLET:\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"source_records\": [\n",
      "    \"bwb:9783850407960\"\n",
      "  ],\n",
      "  \"name\": \"Jule Windgeflüster\",\n",
      "  \"type\": {\n",
      "    \"key\": \"/type/author\"\n",
      "  },\n",
      "  \"key\": \"/authors/OL10000073A\",\n",
      "  \"latest_revision\": 3,\n",
      "  \"revision\": 3,\n",
      "  \"created\": {\n",
      "    \"type\": \"/type/datetime\",\n",
      "    \"value\": \"2021-12-26T21:23:27.331795\"\n",
      "  },\n",
      "  \"last_modified\": {\n",
      "    \"type\": \"/type/datetime\",\n",
      "    \"value\": \"2024-12-30T07:49:12.172071\"\n",
      "  }\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "👤 AUTEUR 2\n",
      "================================================================================\n",
      "🔸 Type: /type/author\n",
      "🔸 ID: /authors/OL10000596A\n",
      "🔸 Révision: 1\n",
      "🔸 Timestamp: 2021-12-26T22:41:12.105726\n",
      "🔸 Ligne dans le fichier: 2\n",
      "\n",
      "📋 INFORMATIONS PRINCIPALES:\n",
      "------------------------------\n",
      "📝 Nom: Beth Wildman\n",
      "\n",
      "📋 OBJET JSON COMPLET:\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"type\": {\n",
      "    \"key\": \"/type/author\"\n",
      "  },\n",
      "  \"name\": \"Beth Wildman\",\n",
      "  \"key\": \"/authors/OL10000596A\",\n",
      "  \"source_records\": [\n",
      "    \"bwb:9781607529910\"\n",
      "  ],\n",
      "  \"latest_revision\": 1,\n",
      "  \"revision\": 1,\n",
      "  \"created\": {\n",
      "    \"type\": \"/type/datetime\",\n",
      "    \"value\": \"2021-12-26T22:41:12.105726\"\n",
      "  },\n",
      "  \"last_modified\": {\n",
      "    \"type\": \"/type/datetime\",\n",
      "    \"value\": \"2021-12-26T22:41:12.105726\"\n",
      "  }\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "👤 AUTEUR 3\n",
      "================================================================================\n",
      "🔸 Type: /type/author\n",
      "🔸 ID: /authors/OL10000760A\n",
      "🔸 Révision: 1\n",
      "🔸 Timestamp: 2021-12-26T23:16:27.379050\n",
      "🔸 Ligne dans le fichier: 3\n",
      "\n",
      "📋 INFORMATIONS PRINCIPALES:\n",
      "------------------------------\n",
      "📝 Nom: Jaume Piquet Alcàzar\n",
      "\n",
      "📋 OBJET JSON COMPLET:\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"type\": {\n",
      "    \"key\": \"/type/author\"\n",
      "  },\n",
      "  \"name\": \"Jaume Piquet Alcàzar\",\n",
      "  \"key\": \"/authors/OL10000760A\",\n",
      "  \"source_records\": [\n",
      "    \"bwb:9788490150054\"\n",
      "  ],\n",
      "  \"latest_revision\": 1,\n",
      "  \"revision\": 1,\n",
      "  \"created\": {\n",
      "    \"type\": \"/type/datetime\",\n",
      "    \"value\": \"2021-12-26T23:16:27.379050\"\n",
      "  },\n",
      "  \"last_modified\": {\n",
      "    \"type\": \"/type/datetime\",\n",
      "    \"value\": \"2021-12-26T23:16:27.379050\"\n",
      "  }\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "👤 AUTEUR 4\n",
      "================================================================================\n",
      "🔸 Type: /type/author\n",
      "🔸 ID: /authors/OL10001743A\n",
      "🔸 Révision: 1\n",
      "🔸 Timestamp: 2021-12-27T01:41:27.015143\n",
      "🔸 Ligne dans le fichier: 4\n",
      "\n",
      "📋 INFORMATIONS PRINCIPALES:\n",
      "------------------------------\n",
      "📝 Nom: P. M. Gagey\n",
      "\n",
      "📋 OBJET JSON COMPLET:\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"type\": {\n",
      "    \"key\": \"/type/author\"\n",
      "  },\n",
      "  \"name\": \"P. M. Gagey\",\n",
      "  \"key\": \"/authors/OL10001743A\",\n",
      "  \"source_records\": [\n",
      "    \"bwb:9788847022935\"\n",
      "  ],\n",
      "  \"latest_revision\": 1,\n",
      "  \"revision\": 1,\n",
      "  \"created\": {\n",
      "    \"type\": \"/type/datetime\",\n",
      "    \"value\": \"2021-12-27T01:41:27.015143\"\n",
      "  },\n",
      "  \"last_modified\": {\n",
      "    \"type\": \"/type/datetime\",\n",
      "    \"value\": \"2021-12-27T01:41:27.015143\"\n",
      "  }\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "👤 AUTEUR 5\n",
      "================================================================================\n",
      "🔸 Type: /type/author\n",
      "🔸 ID: /authors/OL1000176A\n",
      "🔸 Révision: 2\n",
      "🔸 Timestamp: 2008-08-20T17:57:27.879405\n",
      "🔸 Ligne dans le fichier: 5\n",
      "\n",
      "📋 INFORMATIONS PRINCIPALES:\n",
      "------------------------------\n",
      "📝 Nom: Suʻād Rau̓̄f Shīr Muḥammad\n",
      "\n",
      "📋 OBJET JSON COMPLET:\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"name\": \"Suʻād Rau̓̄f Shīr Muḥammad\",\n",
      "  \"personal_name\": \"Suʻād Rau̓̄f Shīr Muḥammad\",\n",
      "  \"last_modified\": {\n",
      "    \"type\": \"/type/datetime\",\n",
      "    \"value\": \"2008-08-20T17:57:27.879405\"\n",
      "  },\n",
      "  \"key\": \"/authors/OL1000176A\",\n",
      "  \"type\": {\n",
      "    \"key\": \"/type/author\"\n",
      "  },\n",
      "  \"revision\": 2\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "👤 ANALYSE SPÉCIALISÉE DES AUTEURS\n",
      "==================================================\n",
      "📊 CHAMPS TROUVÉS DANS LES OBJETS AUTEURS :\n",
      "   • name                      : 5/5 auteurs (100%)\n",
      "   • type                      : 5/5 auteurs (100%)\n",
      "   • key                       : 5/5 auteurs (100%)\n",
      "   • revision                  : 5/5 auteurs (100%)\n",
      "   • last_modified             : 5/5 auteurs (100%)\n",
      "   • source_records            : 4/5 auteurs (80%)\n",
      "   • latest_revision           : 4/5 auteurs (80%)\n",
      "   • created                   : 4/5 auteurs (80%)\n",
      "   • personal_name             : 1/5 auteurs (20%)\n",
      "\n",
      "📈 STATISTIQUES SPÉCIALISÉES :\n",
      "   📚 Auteurs avec biographie    : 0/5 (0%)\n",
      "   🎂 Auteurs avec date naissance: 0/5 (0%)\n",
      "   ⚰️ Auteurs avec date décès    : 0/5 (0%)\n",
      "   🌐 Auteurs avec Wikipedia     : 0/5 (0%)\n",
      "   🔄 Auteurs avec noms alternatifs: 0/5 (0%)\n",
      "\n",
      "📝 LONGUEUR DES NOMS :\n",
      "   • Plus court : 11 caractères\n",
      "   • Plus long  : 29 caractères\n",
      "   • Moyenne    : 18.0 caractères\n",
      "\n",
      "💡 INSIGHTS SUR LES DONNÉES D'AUTEURS :\n",
      "🔍 Les objets auteurs contiennent :\n",
      "   • Informations biographiques (nom, dates, bio)\n",
      "   • Liens externes (Wikipedia, sites web)\n",
      "   • Métadonnées de révision et timestamps\n",
      "   • Noms alternatifs et variantes\n",
      "   • Identifiants uniques OpenLibrary\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTION D'OBJETS JSON AUTEURS (FICHIER DÉCOMPRESSÉ)\n",
    "print(\"👤 EXTRACTION D'OBJETS JSON AUTEURS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "def extract_authors_json_objects(filename, num_objects=5):\n",
    "    \"\"\"Extrait et affiche des objets JSON d'auteurs du fichier décompressé\"\"\"\n",
    "    print(f\"📋 Extraction de {num_objects} objets JSON d'auteurs du fichier...\")\n",
    "    \n",
    "    extracted_objects = []\n",
    "    objects_found = 0\n",
    "    lines_processed = 0\n",
    "    \n",
    "    try:\n",
    "        # Lire le fichier texte normal (pas gzip)\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                lines_processed += 1\n",
    "                \n",
    "                if objects_found >= num_objects:\n",
    "                    break\n",
    "                \n",
    "                # Diviser la ligne en champs (séparés par des tabulations)\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 5:  # Type, ID, Revision, Timestamp, JSON\n",
    "                    object_type = parts[0]\n",
    "                    object_id = parts[1]\n",
    "                    revision = parts[2]\n",
    "                    timestamp = parts[3]\n",
    "                    json_data = parts[4]\n",
    "                    \n",
    "                    # Filtrer uniquement les auteurs\n",
    "                    if object_type != '/type/author':\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        # Parser le JSON\n",
    "                        parsed_json = json.loads(json_data)\n",
    "                        \n",
    "                        extracted_objects.append({\n",
    "                            'line_number': i + 1,\n",
    "                            'type': object_type,\n",
    "                            'id': object_id,\n",
    "                            'revision': revision,\n",
    "                            'timestamp': timestamp,\n",
    "                            'json_object': parsed_json\n",
    "                        })\n",
    "                        \n",
    "                        objects_found += 1\n",
    "                        \n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"⚠️ Erreur JSON à la ligne {i+1}: {str(e)[:100]}...\")\n",
    "                        continue\n",
    "                \n",
    "                # Afficher le progrès tous les 10000 lignes\n",
    "                if lines_processed % 10000 == 0:\n",
    "                    print(f\"   Traité {lines_processed:,} lignes, trouvé {objects_found} auteurs valides...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'extraction : {e}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"✅ Extraction terminée : {objects_found} auteurs extraits sur {lines_processed:,} lignes traitées\")\n",
    "    return extracted_objects\n",
    "\n",
    "def display_authors_json_objects(objects):\n",
    "    \"\"\"Affiche les objets JSON d'auteurs de manière formatée\"\"\"\n",
    "    for i, obj in enumerate(objects):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"👤 AUTEUR {i+1}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"🔸 Type: {obj['type']}\")\n",
    "        print(f\"🔸 ID: {obj['id']}\")\n",
    "        print(f\"🔸 Révision: {obj['revision']}\")\n",
    "        print(f\"🔸 Timestamp: {obj['timestamp']}\")\n",
    "        print(f\"🔸 Ligne dans le fichier: {obj['line_number']}\")\n",
    "        \n",
    "        # Extraire les infos principales de l'auteur\n",
    "        json_obj = obj['json_object']\n",
    "        print(f\"\\n📋 INFORMATIONS PRINCIPALES:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        if 'name' in json_obj:\n",
    "            print(f\"📝 Nom: {json_obj['name']}\")\n",
    "        \n",
    "        if 'birth_date' in json_obj:\n",
    "            print(f\"🎂 Date de naissance: {json_obj['birth_date']}\")\n",
    "        \n",
    "        if 'death_date' in json_obj:\n",
    "            print(f\"⚰️ Date de décès: {json_obj['death_date']}\")\n",
    "        \n",
    "        if 'bio' in json_obj:\n",
    "            bio = json_obj['bio']\n",
    "            if isinstance(bio, dict) and 'value' in bio:\n",
    "                bio_text = bio['value'][:200] + \"...\" if len(bio['value']) > 200 else bio['value']\n",
    "                print(f\"📚 Biographie: {bio_text}\")\n",
    "            elif isinstance(bio, str):\n",
    "                bio_text = bio[:200] + \"...\" if len(bio) > 200 else bio\n",
    "                print(f\"📚 Biographie: {bio_text}\")\n",
    "        \n",
    "        if 'alternate_names' in json_obj and json_obj['alternate_names']:\n",
    "            print(f\"🔄 Noms alternatifs: {', '.join(json_obj['alternate_names'][:3])}\")\n",
    "        \n",
    "        if 'wikipedia' in json_obj:\n",
    "            print(f\"🌐 Wikipedia: {json_obj['wikipedia']}\")\n",
    "        \n",
    "        print(f\"\\n📋 OBJET JSON COMPLET:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Afficher le JSON formaté\n",
    "        try:\n",
    "            formatted_json = json.dumps(json_obj, indent=2, ensure_ascii=False)\n",
    "            # Limiter l'affichage si trop long\n",
    "            if len(formatted_json) > 1500:\n",
    "                lines = formatted_json.split('\\n')\n",
    "                displayed_lines = lines[:40]  # Première partie\n",
    "                print('\\n'.join(displayed_lines))\n",
    "                print(f\"\\n... [TRONQUÉ - {len(lines)-40} lignes supplémentaires] ...\")\n",
    "                print('\\n'.join(lines[-3:]))  # Dernières lignes\n",
    "            else:\n",
    "                print(formatted_json)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur d'affichage: {e}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def analyze_authors_structure(objects):\n",
    "    \"\"\"Analyse la structure spécialisée des objets auteurs\"\"\"\n",
    "    print(f\"\\n👤 ANALYSE SPÉCIALISÉE DES AUTEURS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Analyser les champs\n",
    "    all_keys = set()\n",
    "    key_frequency = {}\n",
    "    \n",
    "    # Statistiques spécialisées\n",
    "    authors_with_bio = 0\n",
    "    authors_with_birth_date = 0\n",
    "    authors_with_death_date = 0\n",
    "    authors_with_wikipedia = 0\n",
    "    authors_with_alternate_names = 0\n",
    "    \n",
    "    birth_years = []\n",
    "    death_years = []\n",
    "    name_lengths = []\n",
    "    \n",
    "    for obj in objects:\n",
    "        json_obj = obj['json_object']\n",
    "        if isinstance(json_obj, dict):\n",
    "            for key in json_obj.keys():\n",
    "                all_keys.add(key)\n",
    "                key_frequency[key] = key_frequency.get(key, 0) + 1\n",
    "            \n",
    "            # Statistiques spécialisées\n",
    "            if 'bio' in json_obj:\n",
    "                authors_with_bio += 1\n",
    "            \n",
    "            if 'birth_date' in json_obj:\n",
    "                authors_with_birth_date += 1\n",
    "                try:\n",
    "                    birth_date = json_obj['birth_date']\n",
    "                    if isinstance(birth_date, str) and len(birth_date) >= 4:\n",
    "                        year = int(birth_date[:4])\n",
    "                        if 1000 <= year <= 2025:\n",
    "                            birth_years.append(year)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            if 'death_date' in json_obj:\n",
    "                authors_with_death_date += 1\n",
    "                try:\n",
    "                    death_date = json_obj['death_date']\n",
    "                    if isinstance(death_date, str) and len(death_date) >= 4:\n",
    "                        year = int(death_date[:4])\n",
    "                        if 1000 <= year <= 2025:\n",
    "                            death_years.append(year)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            if 'wikipedia' in json_obj:\n",
    "                authors_with_wikipedia += 1\n",
    "            \n",
    "            if 'alternate_names' in json_obj and json_obj['alternate_names']:\n",
    "                authors_with_alternate_names += 1\n",
    "            \n",
    "            if 'name' in json_obj:\n",
    "                name_lengths.append(len(json_obj['name']))\n",
    "    \n",
    "    # Affichage des statistiques\n",
    "    print(f\"📊 CHAMPS TROUVÉS DANS LES OBJETS AUTEURS :\")\n",
    "    sorted_keys = sorted(key_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for key, freq in sorted_keys:\n",
    "        percentage = (freq / len(objects)) * 100\n",
    "        print(f\"   • {key:<25} : {freq}/{len(objects)} auteurs ({percentage:.0f}%)\")\n",
    "    \n",
    "    print(f\"\\n📈 STATISTIQUES SPÉCIALISÉES :\")\n",
    "    print(f\"   📚 Auteurs avec biographie    : {authors_with_bio}/{len(objects)} ({(authors_with_bio/len(objects)*100):.0f}%)\")\n",
    "    print(f\"   🎂 Auteurs avec date naissance: {authors_with_birth_date}/{len(objects)} ({(authors_with_birth_date/len(objects)*100):.0f}%)\")\n",
    "    print(f\"   ⚰️ Auteurs avec date décès    : {authors_with_death_date}/{len(objects)} ({(authors_with_death_date/len(objects)*100):.0f}%)\")\n",
    "    print(f\"   🌐 Auteurs avec Wikipedia     : {authors_with_wikipedia}/{len(objects)} ({(authors_with_wikipedia/len(objects)*100):.0f}%)\")\n",
    "    print(f\"   🔄 Auteurs avec noms alternatifs: {authors_with_alternate_names}/{len(objects)} ({(authors_with_alternate_names/len(objects)*100):.0f}%)\")\n",
    "    \n",
    "    if birth_years:\n",
    "        print(f\"\\n📅 ANNÉES DE NAISSANCE :\")\n",
    "        print(f\"   • Plus ancienne : {min(birth_years)}\")\n",
    "        print(f\"   • Plus récente  : {max(birth_years)}\")\n",
    "        print(f\"   • Moyenne       : {sum(birth_years)/len(birth_years):.0f}\")\n",
    "    \n",
    "    if death_years:\n",
    "        print(f\"\\n⚰️ ANNÉES DE DÉCÈS :\")\n",
    "        print(f\"   • Plus ancienne : {min(death_years)}\")\n",
    "        print(f\"   • Plus récente  : {max(death_years)}\")\n",
    "        print(f\"   • Moyenne       : {sum(death_years)/len(death_years):.0f}\")\n",
    "    \n",
    "    if name_lengths:\n",
    "        print(f\"\\n📝 LONGUEUR DES NOMS :\")\n",
    "        print(f\"   • Plus court : {min(name_lengths)} caractères\")\n",
    "        print(f\"   • Plus long  : {max(name_lengths)} caractères\")\n",
    "        print(f\"   • Moyenne    : {sum(name_lengths)/len(name_lengths):.1f} caractères\")\n",
    "\n",
    "# RECHERCHE DU FICHIER AUTEURS DÉCOMPRESSÉ\n",
    "print(\"🔍 RECHERCHE DU FICHIER AUTEURS DÉCOMPRESSÉ\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Chemin direct vers le fichier des auteurs décompressé\n",
    "fichier_auteurs = r\"C:\\Users\\dd758\\Formation_IA_Greta\\Projet_possible certif\\Livre_analyse\\data_book\\databook\\data\\fichier_openlibrary\\ol_dump_authors_2025-05-31.txt\\ol_dump_authors_2025-05-31.txt\"\n",
    "\n",
    "# Vérifier que le fichier existe\n",
    "if not os.path.exists(fichier_auteurs):\n",
    "    print(f\"❌ Fichier non trouvé : {fichier_auteurs}\")\n",
    "    print(\"📂 Fichiers .txt disponibles dans le dossier :\")\n",
    "    try:\n",
    "        for f in os.listdir(base_path):\n",
    "            if f.endswith('.txt'):\n",
    "                print(f\"   • {f}\")\n",
    "    except:\n",
    "        print(\"   Impossible de lister les fichiers\")\n",
    "    fichier_auteurs = None\n",
    "\n",
    "if fichier_auteurs and os.path.exists(fichier_auteurs):\n",
    "    print(f\"✅ Fichier trouvé : {os.path.basename(fichier_auteurs)}\")\n",
    "    file_size = os.path.getsize(fichier_auteurs)\n",
    "    print(f\"📁 Taille du fichier : {file_size:,} octets ({file_size / (1024**3):.2f} GB)\")\n",
    "    \n",
    "    # Extraction des objets JSON d'auteurs\n",
    "    authors_objects = extract_authors_json_objects(fichier_auteurs, num_objects=5)\n",
    "    \n",
    "    if authors_objects:\n",
    "        display_authors_json_objects(authors_objects)\n",
    "        analyze_authors_structure(authors_objects)\n",
    "        \n",
    "        print(f\"\\n💡 INSIGHTS SUR LES DONNÉES D'AUTEURS :\")\n",
    "        print(f\"🔍 Les objets auteurs contiennent :\")\n",
    "        print(f\"   • Informations biographiques (nom, dates, bio)\")\n",
    "        print(f\"   • Liens externes (Wikipedia, sites web)\")\n",
    "        print(f\"   • Métadonnées de révision et timestamps\")\n",
    "        print(f\"   • Noms alternatifs et variantes\")\n",
    "        print(f\"   • Identifiants uniques OpenLibrary\")\n",
    "    else:\n",
    "        print(\"❌ Aucun objet JSON d'auteur valide trouvé\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Fichier auteurs décompressé non accessible\")\n",
    "    print(\"💡 Assurez-vous que le fichier a été décompressé et est accessible\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (1698817028.py, line 49)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mjson_data = json.loads(parts[4])\\n                        stats['total_authors'] += 1\u001b[39m\n                                     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "# RECHERCHE APPROFONDIE DES MÉTADONNÉES D'AUTEURS\n",
    "print(\"🔍 RECHERCHE APPROFONDIE DES MÉTADONNÉES D'AUTEURS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def search_author_metadata(filename, sample_size=10000):\n",
    "    \"\"\"Recherche spécifiquement les métadonnées riches d'auteurs\"\"\"\n",
    "    print(f\"🔎 Analyse de {sample_size:,} auteurs pour trouver les métadonnées...\")\n",
    "    \n",
    "    # Compteurs pour différents types de métadonnées\n",
    "    stats = {\n",
    "        'total_authors': 0,\n",
    "        'with_bio': 0,\n",
    "        'with_birth_date': 0,\n",
    "        'with_death_date': 0,\n",
    "        'with_wikipedia': 0,\n",
    "        'with_wikidata': 0,\n",
    "        'with_alternate_names': 0,\n",
    "        'with_personal_name': 0,\n",
    "        'with_photos': 0,\n",
    "        'with_links': 0,\n",
    "        'with_website': 0\n",
    "    }\n",
    "    \n",
    "    # Exemples d'auteurs avec métadonnées\n",
    "    examples = {\n",
    "        'bio_examples': [],\n",
    "        'birth_date_examples': [],\n",
    "        'wikipedia_examples': [],\n",
    "        'wikidata_examples': [],\n",
    "        'rich_profiles': []  # Auteurs avec beaucoup de métadonnées\n",
    "    }\n",
    "    \n",
    "    # Types de champs trouvés\n",
    "    all_fields = defaultdict(int)\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if stats['total_authors'] >= sample_size:\n",
    "                    break\n",
    "                \n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 5 and parts[0] == '/type/author':\n",
    "                    try:\n",
    "                        json_data = json.loads(parts[4])\\n                        stats['total_authors'] += 1\n",
    "                        \n",
    "                        # Compter tous les champs présents\n",
    "                        field_count = 0\n",
    "                        for key in json_data.keys():\n",
    "                            all_fields[key] += 1\n",
    "                            field_count += 1\n",
    "                        \n",
    "                        # Vérifier la biographie\n",
    "                        if 'bio' in json_data:\n",
    "                            stats['with_bio'] += 1\n",
    "                            bio_text = \\\"\\\"\\n                            if isinstance(json_data['bio'], dict) and 'value' in json_data['bio']:\n",
    "                                bio_text = json_data['bio']['value']\n",
    "                            elif isinstance(json_data['bio'], str):\n",
    "                                bio_text = json_data['bio']\n",
    "                            \n",
    "                            if bio_text and len(examples['bio_examples']) < 3:\n",
    "                                examples['bio_examples'].append({\n",
    "                                    'name': json_data.get('name', 'N/A'),\n",
    "                                    'id': parts[1],\n",
    "                                    'bio': bio_text[:200] + \\\"...\\\" if len(bio_text) > 200 else bio_text\n",
    "                                })\n",
    "                        \n",
    "                        # Vérifier les dates de naissance\n",
    "                        if 'birth_date' in json_data:\n",
    "                            stats['with_birth_date'] += 1\n",
    "                            if len(examples['birth_date_examples']) < 3:\n",
    "                                examples['birth_date_examples'].append({\n",
    "                                    'name': json_data.get('name', 'N/A'),\n",
    "                                    'id': parts[1],\n",
    "                                    'birth_date': json_data['birth_date']\n",
    "                                })\n",
    "                        \n",
    "                        # Vérifier les dates de décès\n",
    "                        if 'death_date' in json_data:\n",
    "                            stats['with_death_date'] += 1\n",
    "                        \n",
    "                        # Vérifier Wikipedia\n",
    "                        if 'wikipedia' in json_data:\n",
    "                            stats['with_wikipedia'] += 1\n",
    "                            if len(examples['wikipedia_examples']) < 3:\n",
    "                                examples['wikipedia_examples'].append({\n",
    "                                    'name': json_data.get('name', 'N/A'),\n",
    "                                    'id': parts[1],\n",
    "                                    'wikipedia': json_data['wikipedia']\n",
    "                                })\n",
    "                        \n",
    "                        # Vérifier Wikidata (peut être dans 'remote_ids' ou directement)\n",
    "                        wikidata_found = False\n",
    "                        if 'remote_ids' in json_data:\n",
    "                            remote_ids = json_data['remote_ids']\n",
    "                            if isinstance(remote_ids, dict) and 'wikidata' in remote_ids:\n",
    "                                stats['with_wikidata'] += 1\n",
    "                                wikidata_found = True\n",
    "                                if len(examples['wikidata_examples']) < 3:\n",
    "                                    examples['wikidata_examples'].append({\n",
    "                                        'name': json_data.get('name', 'N/A'),\n",
    "                                        'id': parts[1],\n",
    "                                        'wikidata': remote_ids['wikidata']\n",
    "                                    })\n",
    "                        \n",
    "                        # Autres champs intéressants\n",
    "                        if 'alternate_names' in json_data and json_data['alternate_names']:\n",
    "                            stats['with_alternate_names'] += 1\n",
    "                        \n",
    "                        if 'personal_name' in json_data:\n",
    "                            stats['with_personal_name'] += 1\n",
    "                        \n",
    "                        if 'photos' in json_data:\n",
    "                            stats['with_photos'] += 1\n",
    "                        \n",
    "                        if 'links' in json_data:\n",
    "                            stats['with_links'] += 1\n",
    "                        \n",
    "                        if 'website' in json_data:\n",
    "                            stats['with_website'] += 1\n",
    "                        \n",
    "                        # Identifier les profils riches (avec beaucoup de métadonnées)\n",
    "                        if field_count >= 8 and len(examples['rich_profiles']) < 5:\n",
    "                            examples['rich_profiles'].append({\n",
    "                                'name': json_data.get('name', 'N/A'),\n",
    "                                'id': parts[1],\n",
    "                                'field_count': field_count,\n",
    "                                'fields': list(json_data.keys()),\n",
    "                                'full_object': json_data\n",
    "                            })\n",
    "                        \n",
    "                        # Afficher le progrès\n",
    "                        if stats['total_authors'] % 1000 == 0:\n",
    "                            print(f\\\"   Analysé {stats['total_authors']:,} auteurs... (Bio: {stats['with_bio']}, Dates: {stats['with_birth_date']}, Wikipedia: {stats['with_wikipedia']})\\\")\\n                    \n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\\\"❌ Erreur lors de l'analyse : {e}\\\")\\n        return None, None\n",
    "    \n",
    "    return stats, examples, all_fields\n",
    "\n",
    "def display_metadata_analysis(stats, examples, all_fields):\n",
    "    \\\"\\\"\\\"Affiche les résultats de l'analyse des métadonnées\\\"\\\"\\\"\n",
    "    print(f\\\"\\\\n📊 RÉSULTATS DE L'ANALYSE DES MÉTADONNÉES\\\")\n",
    "    print(\\\"=\\\" * 60)\n",
    "    \n",
    "    total = stats['total_authors']\n",
    "    print(f\\\"👥 Total d'auteurs analysés : {total:,}\\\")\\n    print(f\\\"\\\\n📈 PRÉSENCE DES MÉTADONNÉES :\\\")\\n    print(f\\\"   📚 Auteurs avec biographie     : {stats['with_bio']:,} ({stats['with_bio']/total*100:.1f}%)\\\")\\n    print(f\\\"   🎂 Auteurs avec date naissance : {stats['with_birth_date']:,} ({stats['with_birth_date']/total*100:.1f}%)\\\")\\n    print(f\\\"   ⚰️ Auteurs avec date décès     : {stats['with_death_date']:,} ({stats['with_death_date']/total*100:.1f}%)\\\")\\n    print(f\\\"   🌐 Auteurs avec Wikipedia      : {stats['with_wikipedia']:,} ({stats['with_wikipedia']/total*100:.1f}%)\\\")\\n    print(f\\\"   🔗 Auteurs avec Wikidata       : {stats['with_wikidata']:,} ({stats['with_wikidata']/total*100:.1f}%)\\\")\\n    print(f\\\"   🔄 Auteurs avec noms alternatifs: {stats['with_alternate_names']:,} ({stats['with_alternate_names']/total*100:.1f}%)\\\")\\n    print(f\\\"   📝 Auteurs avec nom personnel  : {stats['with_personal_name']:,} ({stats['with_personal_name']/total*100:.1f}%)\\\")\\n    print(f\\\"   📸 Auteurs avec photos         : {stats['with_photos']:,} ({stats['with_photos']/total*100:.1f}%)\\\")\\n    print(f\\\"   🔗 Auteurs avec liens externes : {stats['with_links']:,} ({stats['with_links']/total*100:.1f}%)\\\")\\n    print(f\\\"   🌐 Auteurs avec site web       : {stats['with_website']:,} ({stats['with_website']/total*100:.1f}%)\\\")\\n    \\n    print(f\\\"\\\\n📋 CHAMPS LES PLUS FRÉQUENTS :\\\")\\n    sorted_fields = sorted(all_fields.items(), key=lambda x: x[1], reverse=True)\\n    for field, count in sorted_fields[:15]:\\n        percentage = (count / total) * 100\\n        print(f\\\"   • {field:<25} : {count:>6,} auteurs ({percentage:>5.1f}%)\\\")\\n    \\n    # Afficher des exemples\\n    if examples['bio_examples']:\\n        print(f\\\"\\\\n📚 EXEMPLES D'AUTEURS AVEC BIOGRAPHIES :\\\")\\n        for i, ex in enumerate(examples['bio_examples'], 1):\\n            print(f\\\"   {i}. {ex['name']} ({ex['id']})\\\")\\n            print(f\\\"      Bio: {ex['bio']}\\\")\\n    \\n    if examples['birth_date_examples']:\\n        print(f\\\"\\\\n🎂 EXEMPLES D'AUTEURS AVEC DATES DE NAISSANCE :\\\")\\n        for i, ex in enumerate(examples['birth_date_examples'], 1):\\n            print(f\\\"   {i}. {ex['name']} ({ex['id']})\\\")\\n            print(f\\\"      Né(e) le: {ex['birth_date']}\\\")\\n    \\n    if examples['wikipedia_examples']:\\n        print(f\\\"\\\\n🌐 EXEMPLES D'AUTEURS AVEC WIKIPEDIA :\\\")\\n        for i, ex in enumerate(examples['wikipedia_examples'], 1):\\n            print(f\\\"   {i}. {ex['name']} ({ex['id']})\\\")\\n            print(f\\\"      Wikipedia: {ex['wikipedia']}\\\")\\n    \\n    if examples['wikidata_examples']:\\n        print(f\\\"\\\\n🔗 EXEMPLES D'AUTEURS AVEC WIKIDATA :\\\")\\n        for i, ex in enumerate(examples['wikidata_examples'], 1):\\n            print(f\\\"   {i}. {ex['name']} ({ex['id']})\\\")\\n            print(f\\\"      Wikidata: {ex['wikidata']}\\\")\\n    \\n    if examples['rich_profiles']:\\n        print(f\\\"\\\\n⭐ EXEMPLES DE PROFILS RICHES (beaucoup de métadonnées) :\\\")\\n        for i, ex in enumerate(examples['rich_profiles'], 1):\\n            print(f\\\"   {i}. {ex['name']} ({ex['id']}) - {ex['field_count']} champs\\\")\\n            print(f\\\"      Champs: {', '.join(ex['fields'][:8])}{'...' if len(ex['fields']) > 8 else ''}\\\")\\n\\ndef display_rich_profile_details(examples):\\n    \\\"\\\"\\\"Affiche les détails complets d'un profil riche\\\"\\\"\\\"\\n    if examples['rich_profiles']:\\n        print(f\\\"\\\\n🔍 DÉTAIL D'UN PROFIL RICHE COMPLET :\\\")\\n        print(\\\"=\\\" * 60)\\n        \\n        rich_author = examples['rich_profiles'][0]  # Premier profil riche\\n        print(f\\\"👤 Auteur: {rich_author['name']}\\\")\\n        print(f\\\"🆔 ID: {rich_author['id']}\\\")\\n        print(f\\\"📊 Nombre de champs: {rich_author['field_count']}\\\")\\n        \\n        print(f\\\"\\\\n📋 OBJET JSON COMPLET :\\\")\\n        print(\\\"-\\\" * 50)\\n        try:\\n            formatted_json = json.dumps(rich_author['full_object'], indent=2, ensure_ascii=False)\\n            if len(formatted_json) > 2000:\\n                lines = formatted_json.split('\\\\n')\\n                print('\\\\n'.join(lines[:60]))\\n                print(f\\\"\\\\n... [TRONQUÉ - {len(lines)-60} lignes supplémentaires] ...\\\")\\n                print('\\\\n'.join(lines[-5:]))\\n            else:\\n                print(formatted_json)\\n        except:\\n            print(\\\"❌ Erreur d'affichage du JSON\\\")\\n        print(\\\"-\\\" * 50)\n",
    "\n",
    "# EXÉCUTION DE L'ANALYSE\n",
    "fichier_auteurs = r\\\"C:\\\\Users\\\\dd758\\\\Formation_IA_Greta\\\\Projet_possible certif\\\\Livre_analyse\\\\data_book\\\\databook\\\\data\\\\fichier_openlibrary\\\\ol_dump_authors_2025-05-31.txt\\\\ol_dump_authors_2025-05-31.txt\\\"\n",
    "\n",
    "if os.path.exists(fichier_auteurs):\n",
    "    print(f\\\"✅ Fichier trouvé : {os.path.basename(fichier_auteurs)}\\\")\\n    print(f\\\"📁 Analyse en cours sur un échantillon de 50,000 auteurs...\\\")\\n    \\n    # Analyser un échantillon plus large\\n    stats, examples, all_fields = search_author_metadata(fichier_auteurs, sample_size=50000)\\n    \\n    if stats:\\n        display_metadata_analysis(stats, examples, all_fields)\\n        display_rich_profile_details(examples)\\n        \\n        print(f\\\"\\\\n💡 CONCLUSIONS SUR LES MÉTADONNÉES D'AUTEURS :\\\")\\n        print(f\\\"\\\" * 60)\\n        \\n        bio_rate = stats['with_bio'] / stats['total_authors'] * 100\\n        date_rate = stats['with_birth_date'] / stats['total_authors'] * 100\\n        wiki_rate = stats['with_wikipedia'] / stats['total_authors'] * 100\\n        wikidata_rate = stats['with_wikidata'] / stats['total_authors'] * 100\\n        \\n        if bio_rate > 10:\\n            print(f\\\"✅ EXCELLENT : {bio_rate:.1f}% des auteurs ont une biographie\\\")\\n        elif bio_rate > 5:\\n            print(f\\\"✅ BON : {bio_rate:.1f}% des auteurs ont une biographie\\\")\\n        else:\\n            print(f\\\"⚠️ LIMITÉ : Seulement {bio_rate:.1f}% des auteurs ont une biographie\\\")\\n        \\n        if date_rate > 20:\\n            print(f\\\"✅ EXCELLENT : {date_rate:.1f}% des auteurs ont une date de naissance\\\")\\n        elif date_rate > 10:\\n            print(f\\\"✅ BON : {date_rate:.1f}% des auteurs ont une date de naissance\\\")\\n        else:\\n            print(f\\\"⚠️ LIMITÉ : Seulement {date_rate:.1f}% des auteurs ont une date de naissance\\\")\\n        \\n        total_external = wiki_rate + wikidata_rate\\n        if total_external > 30:\\n            print(f\\\"✅ EXCELLENT : {total_external:.1f}% des auteurs ont des liens externes (Wikipedia/Wikidata)\\\")\\n        elif total_external > 15:\\n            print(f\\\"✅ BON : {total_external:.1f}% des auteurs ont des liens externes\\\")\\n        else:\\n            print(f\\\"⚠️ LIMITÉ : Seulement {total_external:.1f}% des auteurs ont des liens externes\\\")\\n        \\n        print(f\\\"\\\\n🎯 RECOMMANDATIONS :\\\")\\n        rich_rate = len(examples['rich_profiles']) / stats['total_authors'] * 100\\n        if rich_rate > 0.1:\\n            print(f\\\"💡 Il existe des profils riches ({rich_rate:.2f}%) - concentrez-vous sur ceux-ci pour l'analyse\\\")\\n        \\n        if bio_rate > 5:\\n            print(f\\\"📚 Les biographies sont présentes - utilisez-les pour l'analyse de contenu\\\")\\n        \\n        if date_rate > 10:\\n            print(f\\\"📅 Les dates sont disponibles - possibilité d'analyse temporelle\\\")\\n        \\n        if wiki_rate > 5 or wikidata_rate > 5:\\n            print(f\\\"🔗 Liens externes disponibles - possibilité d'enrichissement des données\\\")\\n        \\n    else:\\n        print(\\\"❌ Échec de l'analyse des métadonnées\\\")\\nelse:\\n    print(\\\"❌ Fichier d'auteurs non trouvé\\\")\\n    print(f\\\"Chemin recherché : {fichier_auteurs}\\\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TXT Auteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 RECHERCHE APPROFONDIE DES MÉTADONNÉES D'AUTEURS\n",
      "======================================================================\n",
      "✅ Fichier trouvé : ol_dump_authors_2025-05-31.txt\n",
      "📁 Analyse en cours sur un échantillon de 50,000 auteurs...\n",
      "🔎 Analyse de 50,000 auteurs pour trouver les métadonnées...\n",
      "   Analysé 1,000 auteurs... (Bio: 1, Dates: 31, Wikipedia: 0)\n",
      "   Analysé 2,000 auteurs... (Bio: 1, Dates: 80, Wikipedia: 0)\n",
      "   Analysé 3,000 auteurs... (Bio: 2, Dates: 126, Wikipedia: 0)\n",
      "   Analysé 4,000 auteurs... (Bio: 5, Dates: 166, Wikipedia: 0)\n",
      "   Analysé 5,000 auteurs... (Bio: 5, Dates: 190, Wikipedia: 0)\n",
      "   Analysé 6,000 auteurs... (Bio: 6, Dates: 223, Wikipedia: 0)\n",
      "   Analysé 7,000 auteurs... (Bio: 7, Dates: 331, Wikipedia: 0)\n",
      "   Analysé 8,000 auteurs... (Bio: 7, Dates: 557, Wikipedia: 0)\n",
      "   Analysé 9,000 auteurs... (Bio: 7, Dates: 784, Wikipedia: 0)\n",
      "   Analysé 10,000 auteurs... (Bio: 11, Dates: 878, Wikipedia: 0)\n",
      "   Analysé 11,000 auteurs... (Bio: 11, Dates: 914, Wikipedia: 0)\n",
      "   Analysé 12,000 auteurs... (Bio: 11, Dates: 943, Wikipedia: 0)\n",
      "   Analysé 13,000 auteurs... (Bio: 11, Dates: 1005, Wikipedia: 0)\n",
      "   Analysé 14,000 auteurs... (Bio: 13, Dates: 1086, Wikipedia: 0)\n",
      "   Analysé 15,000 auteurs... (Bio: 14, Dates: 1240, Wikipedia: 0)\n",
      "   Analysé 16,000 auteurs... (Bio: 18, Dates: 1264, Wikipedia: 0)\n",
      "   Analysé 17,000 auteurs... (Bio: 23, Dates: 1445, Wikipedia: 0)\n",
      "   Analysé 18,000 auteurs... (Bio: 26, Dates: 1582, Wikipedia: 0)\n",
      "   Analysé 19,000 auteurs... (Bio: 28, Dates: 1630, Wikipedia: 0)\n",
      "   Analysé 20,000 auteurs... (Bio: 28, Dates: 1696, Wikipedia: 0)\n",
      "   Analysé 21,000 auteurs... (Bio: 31, Dates: 1851, Wikipedia: 0)\n",
      "   Analysé 22,000 auteurs... (Bio: 33, Dates: 2022, Wikipedia: 0)\n",
      "   Analysé 23,000 auteurs... (Bio: 33, Dates: 2095, Wikipedia: 0)\n",
      "   Analysé 24,000 auteurs... (Bio: 37, Dates: 2335, Wikipedia: 0)\n",
      "   Analysé 25,000 auteurs... (Bio: 42, Dates: 2600, Wikipedia: 0)\n",
      "   Analysé 26,000 auteurs... (Bio: 49, Dates: 2895, Wikipedia: 0)\n",
      "   Analysé 27,000 auteurs... (Bio: 57, Dates: 3294, Wikipedia: 0)\n",
      "   Analysé 28,000 auteurs... (Bio: 70, Dates: 3443, Wikipedia: 0)\n",
      "   Analysé 29,000 auteurs... (Bio: 77, Dates: 3487, Wikipedia: 0)\n",
      "   Analysé 30,000 auteurs... (Bio: 82, Dates: 3525, Wikipedia: 0)\n",
      "   Analysé 31,000 auteurs... (Bio: 87, Dates: 3562, Wikipedia: 0)\n",
      "   Analysé 32,000 auteurs... (Bio: 90, Dates: 3597, Wikipedia: 0)\n",
      "   Analysé 33,000 auteurs... (Bio: 97, Dates: 3633, Wikipedia: 0)\n",
      "   Analysé 34,000 auteurs... (Bio: 102, Dates: 3723, Wikipedia: 0)\n",
      "   Analysé 35,000 auteurs... (Bio: 104, Dates: 3843, Wikipedia: 0)\n",
      "   Analysé 36,000 auteurs... (Bio: 108, Dates: 4016, Wikipedia: 0)\n",
      "   Analysé 37,000 auteurs... (Bio: 109, Dates: 4237, Wikipedia: 0)\n",
      "   Analysé 38,000 auteurs... (Bio: 112, Dates: 4461, Wikipedia: 0)\n",
      "   Analysé 39,000 auteurs... (Bio: 112, Dates: 4669, Wikipedia: 0)\n",
      "   Analysé 40,000 auteurs... (Bio: 115, Dates: 4885, Wikipedia: 0)\n",
      "   Analysé 41,000 auteurs... (Bio: 116, Dates: 5013, Wikipedia: 0)\n",
      "   Analysé 42,000 auteurs... (Bio: 116, Dates: 5183, Wikipedia: 0)\n",
      "   Analysé 43,000 auteurs... (Bio: 117, Dates: 5396, Wikipedia: 0)\n",
      "   Analysé 44,000 auteurs... (Bio: 120, Dates: 5622, Wikipedia: 0)\n",
      "   Analysé 45,000 auteurs... (Bio: 125, Dates: 5855, Wikipedia: 0)\n",
      "   Analysé 46,000 auteurs... (Bio: 130, Dates: 6058, Wikipedia: 0)\n",
      "   Analysé 47,000 auteurs... (Bio: 137, Dates: 6206, Wikipedia: 0)\n",
      "   Analysé 48,000 auteurs... (Bio: 142, Dates: 6260, Wikipedia: 0)\n",
      "   Analysé 49,000 auteurs... (Bio: 142, Dates: 6305, Wikipedia: 0)\n",
      "   Analysé 50,000 auteurs... (Bio: 144, Dates: 6343, Wikipedia: 0)\n",
      "\n",
      "📊 RÉSULTATS DE L'ANALYSE DES MÉTADONNÉES\n",
      "============================================================\n",
      "👥 Total d'auteurs analysés : 50,000\n",
      "\n",
      "📈 PRÉSENCE DES MÉTADONNÉES :\n",
      "   📚 Auteurs avec biographie     : 144 (0.3%)\n",
      "   🎂 Auteurs avec date naissance : 6,343 (12.7%)\n",
      "   ⚰️ Auteurs avec date décès     : 1,847 (3.7%)\n",
      "   🌐 Auteurs avec Wikipedia      : 0 (0.0%)\n",
      "   🔗 Auteurs avec Wikidata       : 641 (1.3%)\n",
      "   🔄 Auteurs avec noms alternatifs: 308 (0.6%)\n",
      "   📝 Auteurs avec nom personnel  : 22,833 (45.7%)\n",
      "   📸 Auteurs avec photos         : 204 (0.4%)\n",
      "   🔗 Auteurs avec liens externes : 71 (0.1%)\n",
      "   🌐 Auteurs avec site web       : 0 (0.0%)\n",
      "\n",
      "📋 CHAMPS LES PLUS FRÉQUENTS :\n",
      "   • type                      : 50,000 auteurs (100.0%)\n",
      "   • key                       : 50,000 auteurs (100.0%)\n",
      "   • revision                  : 50,000 auteurs (100.0%)\n",
      "   • last_modified             : 50,000 auteurs (100.0%)\n",
      "   • name                      : 49,994 auteurs (100.0%)\n",
      "   • created                   : 32,913 auteurs ( 65.8%)\n",
      "   • latest_revision           : 28,475 auteurs ( 57.0%)\n",
      "   • personal_name             : 22,833 auteurs ( 45.7%)\n",
      "   • source_records            : 20,858 auteurs ( 41.7%)\n",
      "   • birth_date                :  6,343 auteurs ( 12.7%)\n",
      "   • death_date                :  1,847 auteurs (  3.7%)\n",
      "   • remote_ids                :    683 auteurs (  1.4%)\n",
      "   • title                     :    604 auteurs (  1.2%)\n",
      "   • alternate_names           :    308 auteurs (  0.6%)\n",
      "   • photos                    :    204 auteurs (  0.4%)\n",
      "\n",
      "📚 EXEMPLES D'AUTEURS AVEC BIOGRAPHIES :\n",
      "   1. C. J. Diederichs (/authors/OL10235616A)\n",
      "      Bio: Claus Jürgen Diederichs (* 14. Juni 1941 in Neustrelitz, Mecklenburg-Vorpommern) ist ein deutscher Bauingenieur. Von 1981 bis 2006 war er als Professor für Bauwirtschaft und Baumanagement an der Bergi...\n",
      "   2. Christoph Dolge (/authors/OL10534181A)\n",
      "      Bio: Christoph Dolge wurde 1985 in Dresden geboren, studierte in Zittau Umweltbiotechnologie und nahm von dort seinen Studienabschluss, eine Frau und zwei Söhne mit nach Leipzig, wo er sich heute phantasti...\n",
      "   3. Manuel P. Villatoro (/authors/OL10716410A)\n",
      "      Bio: Manuel P. Villatoro es licenciado en Periodismo por la Universidad Complutense de Madrid.\n",
      "\n",
      "🎂 EXEMPLES D'AUTEURS AVEC DATES DE NAISSANCE :\n",
      "   1. Dick Marr (/authors/OL1002294A)\n",
      "      Né(e) le: 1938\n",
      "   2. Ghosh, Arabinda (/authors/OL1002522A)\n",
      "      Né(e) le: 1937\n",
      "   3. Ching-yuan Lin (/authors/OL1002588A)\n",
      "      Né(e) le: 1932\n",
      "\n",
      "🔗 EXEMPLES D'AUTEURS AVEC WIKIDATA :\n",
      "   1. Zheng, Xie (/authors/OL1015594A)\n",
      "      Wikidata: Q712007\n",
      "   2. Domenico Pesenti (/authors/OL1019240A)\n",
      "      Wikidata: Q16059517\n",
      "   3. C. J. Diederichs (/authors/OL10235616A)\n",
      "      Wikidata: Q1098603\n",
      "\n",
      "⭐ EXEMPLES DE PROFILS RICHES (beaucoup de métadonnées) :\n",
      "   1. Jule Windgeflüster (/authors/OL10000073A) - 8 champs\n",
      "      Champs: source_records, name, type, key, latest_revision, revision, created, last_modified\n",
      "   2. Beth Wildman (/authors/OL10000596A) - 8 champs\n",
      "      Champs: type, name, key, source_records, latest_revision, revision, created, last_modified\n",
      "   3. Jaume Piquet Alcàzar (/authors/OL10000760A) - 8 champs\n",
      "      Champs: type, name, key, source_records, latest_revision, revision, created, last_modified\n",
      "   4. P. M. Gagey (/authors/OL10001743A) - 8 champs\n",
      "      Champs: type, name, key, source_records, latest_revision, revision, created, last_modified\n",
      "   5. Oxford Oxford Symposium (/authors/OL10001887A) - 8 champs\n",
      "      Champs: type, name, key, source_records, latest_revision, revision, created, last_modified\n",
      "\n",
      "🔍 DÉTAIL D'UN PROFIL RICHE COMPLET :\n",
      "============================================================\n",
      "👤 Auteur: Jule Windgeflüster\n",
      "🆔 ID: /authors/OL10000073A\n",
      "📊 Nombre de champs: 8\n",
      "\n",
      "📋 OBJET JSON COMPLET :\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"source_records\": [\n",
      "    \"bwb:9783850407960\"\n",
      "  ],\n",
      "  \"name\": \"Jule Windgeflüster\",\n",
      "  \"type\": {\n",
      "    \"key\": \"/type/author\"\n",
      "  },\n",
      "  \"key\": \"/authors/OL10000073A\",\n",
      "  \"latest_revision\": 3,\n",
      "  \"revision\": 3,\n",
      "  \"created\": {\n",
      "    \"type\": \"/type/datetime\",\n",
      "    \"value\": \"2021-12-26T21:23:27.331795\"\n",
      "  },\n",
      "  \"last_modified\": {\n",
      "    \"type\": \"/type/datetime\",\n",
      "    \"value\": \"2024-12-30T07:49:12.172071\"\n",
      "  }\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "💡 CONCLUSIONS SUR LES MÉTADONNÉES D'AUTEURS :\n",
      "============================================================\n",
      "⚠️ LIMITÉ : Seulement 0.3% des auteurs ont une biographie\n",
      "✅ BON : 12.7% des auteurs ont une date de naissance\n",
      "⚠️ LIMITÉ : Seulement 1.3% des auteurs ont des liens externes\n",
      "\n",
      "🎯 RECOMMANDATIONS :\n",
      "📅 Les dates sont disponibles - possibilité d'analyse temporelle\n"
     ]
    }
   ],
   "source": [
    "# RECHERCHE APPROFONDIE DES MÉTADONNÉES D'AUTEURS\n",
    "print(\"🔍 RECHERCHE APPROFONDIE DES MÉTADONNÉES D'AUTEURS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def search_author_metadata(filename, sample_size=10000):\n",
    "    \"\"\"Recherche spécifiquement les métadonnées riches d'auteurs\"\"\"\n",
    "    print(f\"🔎 Analyse de {sample_size:,} auteurs pour trouver les métadonnées...\")\n",
    "    \n",
    "    # Compteurs pour différents types de métadonnées\n",
    "    stats = {\n",
    "        'total_authors': 0,\n",
    "        'with_bio': 0,\n",
    "        'with_birth_date': 0,\n",
    "        'with_death_date': 0,\n",
    "        'with_wikipedia': 0,\n",
    "        'with_wikidata': 0,\n",
    "        'with_alternate_names': 0,\n",
    "        'with_personal_name': 0,\n",
    "        'with_photos': 0,\n",
    "        'with_links': 0,\n",
    "        'with_website': 0\n",
    "    }\n",
    "    \n",
    "    # Exemples d'auteurs avec métadonnées\n",
    "    examples = {\n",
    "        'bio_examples': [],\n",
    "        'birth_date_examples': [],\n",
    "        'wikipedia_examples': [],\n",
    "        'wikidata_examples': [],\n",
    "        'rich_profiles': []  # Auteurs avec beaucoup de métadonnées\n",
    "    }\n",
    "    \n",
    "    # Types de champs trouvés\n",
    "    all_fields = defaultdict(int)\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if stats['total_authors'] >= sample_size:\n",
    "                    break\n",
    "                \n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 5 and parts[0] == '/type/author':\n",
    "                    try:\n",
    "                        json_data = json.loads(parts[4])\n",
    "                        stats['total_authors'] += 1\n",
    "                        \n",
    "                        # Compter tous les champs présents\n",
    "                        field_count = 0\n",
    "                        for key in json_data.keys():\n",
    "                            all_fields[key] += 1\n",
    "                            field_count += 1\n",
    "                        \n",
    "                        # Vérifier la biographie\n",
    "                        if 'bio' in json_data:\n",
    "                            stats['with_bio'] += 1\n",
    "                            bio_text = \"\"\n",
    "                            if isinstance(json_data['bio'], dict) and 'value' in json_data['bio']:\n",
    "                                bio_text = json_data['bio']['value']\n",
    "                            elif isinstance(json_data['bio'], str):\n",
    "                                bio_text = json_data['bio']\n",
    "                            \n",
    "                            if bio_text and len(examples['bio_examples']) < 3:\n",
    "                                examples['bio_examples'].append({\n",
    "                                    'name': json_data.get('name', 'N/A'),\n",
    "                                    'id': parts[1],\n",
    "                                    'bio': bio_text[:200] + \"...\" if len(bio_text) > 200 else bio_text\n",
    "                                })\n",
    "                        \n",
    "                        # Vérifier les dates de naissance\n",
    "                        if 'birth_date' in json_data:\n",
    "                            stats['with_birth_date'] += 1\n",
    "                            if len(examples['birth_date_examples']) < 3:\n",
    "                                examples['birth_date_examples'].append({\n",
    "                                    'name': json_data.get('name', 'N/A'),\n",
    "                                    'id': parts[1],\n",
    "                                    'birth_date': json_data['birth_date']\n",
    "                                })\n",
    "                        \n",
    "                        # Vérifier les dates de décès\n",
    "                        if 'death_date' in json_data:\n",
    "                            stats['with_death_date'] += 1\n",
    "                        \n",
    "                        # Vérifier Wikipedia\n",
    "                        if 'wikipedia' in json_data:\n",
    "                            stats['with_wikipedia'] += 1\n",
    "                            if len(examples['wikipedia_examples']) < 3:\n",
    "                                examples['wikipedia_examples'].append({\n",
    "                                    'name': json_data.get('name', 'N/A'),\n",
    "                                    'id': parts[1],\n",
    "                                    'wikipedia': json_data['wikipedia']\n",
    "                                })\n",
    "                        \n",
    "                        # Vérifier Wikidata (peut être dans 'remote_ids' ou directement)\n",
    "                        wikidata_found = False\n",
    "                        if 'remote_ids' in json_data:\n",
    "                            remote_ids = json_data['remote_ids']\n",
    "                            if isinstance(remote_ids, dict) and 'wikidata' in remote_ids:\n",
    "                                stats['with_wikidata'] += 1\n",
    "                                wikidata_found = True\n",
    "                                if len(examples['wikidata_examples']) < 3:\n",
    "                                    examples['wikidata_examples'].append({\n",
    "                                        'name': json_data.get('name', 'N/A'),\n",
    "                                        'id': parts[1],\n",
    "                                        'wikidata': remote_ids['wikidata']\n",
    "                                    })\n",
    "                        \n",
    "                        # Autres champs intéressants\n",
    "                        if 'alternate_names' in json_data and json_data['alternate_names']:\n",
    "                            stats['with_alternate_names'] += 1\n",
    "                        \n",
    "                        if 'personal_name' in json_data:\n",
    "                            stats['with_personal_name'] += 1\n",
    "                        \n",
    "                        if 'photos' in json_data:\n",
    "                            stats['with_photos'] += 1\n",
    "                        \n",
    "                        if 'links' in json_data:\n",
    "                            stats['with_links'] += 1\n",
    "                        \n",
    "                        if 'website' in json_data:\n",
    "                            stats['with_website'] += 1\n",
    "                        \n",
    "                        # Identifier les profils riches (avec beaucoup de métadonnées)\n",
    "                        if field_count >= 8 and len(examples['rich_profiles']) < 5:\n",
    "                            examples['rich_profiles'].append({\n",
    "                                'name': json_data.get('name', 'N/A'),\n",
    "                                'id': parts[1],\n",
    "                                'field_count': field_count,\n",
    "                                'fields': list(json_data.keys()),\n",
    "                                'full_object': json_data\n",
    "                            })\n",
    "                        \n",
    "                        # Afficher le progrès\n",
    "                        if stats['total_authors'] % 1000 == 0:\n",
    "                            print(f\"   Analysé {stats['total_authors']:,} auteurs... (Bio: {stats['with_bio']}, Dates: {stats['with_birth_date']}, Wikipedia: {stats['with_wikipedia']})\")\n",
    "                    \n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'analyse : {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    return stats, examples, all_fields\n",
    "\n",
    "def display_metadata_analysis(stats, examples, all_fields):\n",
    "    \"\"\"Affiche les résultats de l'analyse des métadonnées\"\"\"\n",
    "    print(f\"\\n📊 RÉSULTATS DE L'ANALYSE DES MÉTADONNÉES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total = stats['total_authors']\n",
    "    print(f\"👥 Total d'auteurs analysés : {total:,}\")\n",
    "    print(f\"\\n📈 PRÉSENCE DES MÉTADONNÉES :\")\n",
    "    print(f\"   📚 Auteurs avec biographie     : {stats['with_bio']:,} ({stats['with_bio']/total*100:.1f}%)\")\n",
    "    print(f\"   🎂 Auteurs avec date naissance : {stats['with_birth_date']:,} ({stats['with_birth_date']/total*100:.1f}%)\")\n",
    "    print(f\"   ⚰️ Auteurs avec date décès     : {stats['with_death_date']:,} ({stats['with_death_date']/total*100:.1f}%)\")\n",
    "    print(f\"   🌐 Auteurs avec Wikipedia      : {stats['with_wikipedia']:,} ({stats['with_wikipedia']/total*100:.1f}%)\")\n",
    "    print(f\"   🔗 Auteurs avec Wikidata       : {stats['with_wikidata']:,} ({stats['with_wikidata']/total*100:.1f}%)\")\n",
    "    print(f\"   🔄 Auteurs avec noms alternatifs: {stats['with_alternate_names']:,} ({stats['with_alternate_names']/total*100:.1f}%)\")\n",
    "    print(f\"   📝 Auteurs avec nom personnel  : {stats['with_personal_name']:,} ({stats['with_personal_name']/total*100:.1f}%)\")\n",
    "    print(f\"   📸 Auteurs avec photos         : {stats['with_photos']:,} ({stats['with_photos']/total*100:.1f}%)\")\n",
    "    print(f\"   🔗 Auteurs avec liens externes : {stats['with_links']:,} ({stats['with_links']/total*100:.1f}%)\")\n",
    "    print(f\"   🌐 Auteurs avec site web       : {stats['with_website']:,} ({stats['with_website']/total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n📋 CHAMPS LES PLUS FRÉQUENTS :\")\n",
    "    sorted_fields = sorted(all_fields.items(), key=lambda x: x[1], reverse=True)\n",
    "    for field, count in sorted_fields[:15]:\n",
    "        percentage = (count / total) * 100\n",
    "        print(f\"   • {field:<25} : {count:>6,} auteurs ({percentage:>5.1f}%)\")\n",
    "    \n",
    "    # Afficher des exemples\n",
    "    if examples['bio_examples']:\n",
    "        print(f\"\\n📚 EXEMPLES D'AUTEURS AVEC BIOGRAPHIES :\")\n",
    "        for i, ex in enumerate(examples['bio_examples'], 1):\n",
    "            print(f\"   {i}. {ex['name']} ({ex['id']})\")\n",
    "            print(f\"      Bio: {ex['bio']}\")\n",
    "    \n",
    "    if examples['birth_date_examples']:\n",
    "        print(f\"\\n🎂 EXEMPLES D'AUTEURS AVEC DATES DE NAISSANCE :\")\n",
    "        for i, ex in enumerate(examples['birth_date_examples'], 1):\n",
    "            print(f\"   {i}. {ex['name']} ({ex['id']})\")\n",
    "            print(f\"      Né(e) le: {ex['birth_date']}\")\n",
    "    \n",
    "    if examples['wikipedia_examples']:\n",
    "        print(f\"\\n🌐 EXEMPLES D'AUTEURS AVEC WIKIPEDIA :\")\n",
    "        for i, ex in enumerate(examples['wikipedia_examples'], 1):\n",
    "            print(f\"   {i}. {ex['name']} ({ex['id']})\")\n",
    "            print(f\"      Wikipedia: {ex['wikipedia']}\")\n",
    "    \n",
    "    if examples['wikidata_examples']:\n",
    "        print(f\"\\n🔗 EXEMPLES D'AUTEURS AVEC WIKIDATA :\")\n",
    "        for i, ex in enumerate(examples['wikidata_examples'], 1):\n",
    "            print(f\"   {i}. {ex['name']} ({ex['id']})\")\n",
    "            print(f\"      Wikidata: {ex['wikidata']}\")\n",
    "    \n",
    "    if examples['rich_profiles']:\n",
    "        print(f\"\\n⭐ EXEMPLES DE PROFILS RICHES (beaucoup de métadonnées) :\")\n",
    "        for i, ex in enumerate(examples['rich_profiles'], 1):\n",
    "            print(f\"   {i}. {ex['name']} ({ex['id']}) - {ex['field_count']} champs\")\n",
    "            print(f\"      Champs: {', '.join(ex['fields'][:8])}{'...' if len(ex['fields']) > 8 else ''}\")\n",
    "\n",
    "def display_rich_profile_details(examples):\n",
    "    \"\"\"Affiche les détails complets d'un profil riche\"\"\"\n",
    "    if examples['rich_profiles']:\n",
    "        print(f\"\\n🔍 DÉTAIL D'UN PROFIL RICHE COMPLET :\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        rich_author = examples['rich_profiles'][0]  # Premier profil riche\n",
    "        print(f\"👤 Auteur: {rich_author['name']}\")\n",
    "        print(f\"🆔 ID: {rich_author['id']}\")\n",
    "        print(f\"📊 Nombre de champs: {rich_author['field_count']}\")\n",
    "        \n",
    "        print(f\"\\n📋 OBJET JSON COMPLET :\")\n",
    "        print(\"-\" * 50)\n",
    "        try:\n",
    "            formatted_json = json.dumps(rich_author['full_object'], indent=2, ensure_ascii=False)\n",
    "            if len(formatted_json) > 2000:\n",
    "                lines = formatted_json.split('\\n')\n",
    "                print('\\n'.join(lines[:60]))\n",
    "                print(f\"\\n... [TRONQUÉ - {len(lines)-60} lignes supplémentaires] ...\")\n",
    "                print('\\n'.join(lines[-5:]))\n",
    "            else:\n",
    "                print(formatted_json)\n",
    "        except:\n",
    "            print(\"❌ Erreur d'affichage du JSON\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# EXÉCUTION DE L'ANALYSE\n",
    "fichier_auteurs = r\"C:\\Users\\dd758\\Formation_IA_Greta\\Projet_possible certif\\Livre_analyse\\data_book\\databook\\data\\fichier_openlibrary\\ol_dump_authors_2025-05-31.txt\\ol_dump_authors_2025-05-31.txt\"\n",
    "\n",
    "if os.path.exists(fichier_auteurs):\n",
    "    print(f\"✅ Fichier trouvé : {os.path.basename(fichier_auteurs)}\")\n",
    "    print(f\"📁 Analyse en cours sur un échantillon de 50,000 auteurs...\")\n",
    "    \n",
    "    # Analyser un échantillon plus large\n",
    "    stats, examples, all_fields = search_author_metadata(fichier_auteurs, sample_size=50000)\n",
    "    \n",
    "    if stats:\n",
    "        display_metadata_analysis(stats, examples, all_fields)\n",
    "        display_rich_profile_details(examples)\n",
    "        \n",
    "        print(f\"\\n💡 CONCLUSIONS SUR LES MÉTADONNÉES D'AUTEURS :\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        bio_rate = stats['with_bio'] / stats['total_authors'] * 100\n",
    "        date_rate = stats['with_birth_date'] / stats['total_authors'] * 100\n",
    "        wiki_rate = stats['with_wikipedia'] / stats['total_authors'] * 100\n",
    "        wikidata_rate = stats['with_wikidata'] / stats['total_authors'] * 100\n",
    "        \n",
    "        if bio_rate > 10:\n",
    "            print(f\"✅ EXCELLENT : {bio_rate:.1f}% des auteurs ont une biographie\")\n",
    "        elif bio_rate > 5:\n",
    "            print(f\"✅ BON : {bio_rate:.1f}% des auteurs ont une biographie\")\n",
    "        else:\n",
    "            print(f\"⚠️ LIMITÉ : Seulement {bio_rate:.1f}% des auteurs ont une biographie\")\n",
    "        \n",
    "        if date_rate > 20:\n",
    "            print(f\"✅ EXCELLENT : {date_rate:.1f}% des auteurs ont une date de naissance\")\n",
    "        elif date_rate > 10:\n",
    "            print(f\"✅ BON : {date_rate:.1f}% des auteurs ont une date de naissance\")\n",
    "        else:\n",
    "            print(f\"⚠️ LIMITÉ : Seulement {date_rate:.1f}% des auteurs ont une date de naissance\")\n",
    "        \n",
    "        total_external = wiki_rate + wikidata_rate\n",
    "        if total_external > 30:\n",
    "            print(f\"✅ EXCELLENT : {total_external:.1f}% des auteurs ont des liens externes (Wikipedia/Wikidata)\")\n",
    "        elif total_external > 15:\n",
    "            print(f\"✅ BON : {total_external:.1f}% des auteurs ont des liens externes\")\n",
    "        else:\n",
    "            print(f\"⚠️ LIMITÉ : Seulement {total_external:.1f}% des auteurs ont des liens externes\")\n",
    "        \n",
    "        print(f\"\\n🎯 RECOMMANDATIONS :\")\n",
    "        rich_rate = len(examples['rich_profiles']) / stats['total_authors'] * 100\n",
    "        if rich_rate > 0.1:\n",
    "            print(f\"💡 Il existe des profils riches ({rich_rate:.2f}%) - concentrez-vous sur ceux-ci pour l'analyse\")\n",
    "        \n",
    "        if bio_rate > 5:\n",
    "            print(f\"📚 Les biographies sont présentes - utilisez-les pour l'analyse de contenu\")\n",
    "        \n",
    "        if date_rate > 10:\n",
    "            print(f\"📅 Les dates sont disponibles - possibilité d'analyse temporelle\")\n",
    "        \n",
    "        if wiki_rate > 5 or wikidata_rate > 5:\n",
    "            print(f\"🔗 Liens externes disponibles - possibilité d'enrichissement des données\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Échec de l'analyse des métadonnées\")\n",
    "else:\n",
    "    print(\"❌ Fichier d'auteurs non trouvé\")\n",
    "    print(f\"Chemin recherché : {fichier_auteurs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎂 EXTRACTION DES AUTEURS AVEC DATE DE NAISSANCE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTION DES AUTEURS AVEC DATE DE NAISSANCE\n",
    "print(\"🎂 EXTRACTION DES AUTEURS AVEC DATE DE NAISSANCE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def extract_authors_with_birth_date(filename, max_authors=None):\n",
    "    \"\"\"Extrait tous les auteurs ayant une date de naissance\"\"\"\n",
    "    print(f\"🔍 Recherche des auteurs avec date de naissance...\")\n",
    "    \n",
    "    authors_data = []\n",
    "    total_processed = 0\n",
    "    authors_found = 0\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if max_authors and authors_found >= max_authors:\n",
    "                    break\n",
    "                \n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 5 and parts[0] == '/type/author':\n",
    "                    total_processed += 1\n",
    "                    \n",
    "                    try:\n",
    "                        json_data = json.loads(parts[4])\n",
    "                        \n",
    "                        # Vérifier si l'auteur a une date de naissance\n",
    "                        if 'birth_date' in json_data:\n",
    "                            birth_date = json_data['birth_date']\n",
    "                            \n",
    "                            # Préparer les données de l'auteur\n",
    "                            author_info = {\n",
    "                                'author_id': parts[1],\n",
    "                                'name': json_data.get('name', ''),\n",
    "                                'birth_date': birth_date,\n",
    "                                'death_date': json_data.get('death_date', ''),\n",
    "                                'personal_name': json_data.get('personal_name', ''),\n",
    "                                'bio': '',\n",
    "                                'wikipedia': json_data.get('wikipedia', ''),\n",
    "                                'wikidata': '',\n",
    "                                'alternate_names': '',\n",
    "                                'photos': '',\n",
    "                                'website': json_data.get('website', ''),\n",
    "                                'created': parts[3],  # timestamp\n",
    "                                'revision': parts[2],\n",
    "                                'birth_year': None,\n",
    "                                'death_year': None,\n",
    "                                'age_at_death': None,\n",
    "                                'is_alive': None\n",
    "                            }\n",
    "                            \n",
    "                            # Extraire la biographie\n",
    "                            if 'bio' in json_data:\n",
    "                                bio = json_data['bio']\n",
    "                                if isinstance(bio, dict) and 'value' in bio:\n",
    "                                    author_info['bio'] = bio['value']\n",
    "                                elif isinstance(bio, str):\n",
    "                                    author_info['bio'] = bio\n",
    "                            \n",
    "                            # Extraire Wikidata depuis remote_ids\n",
    "                            if 'remote_ids' in json_data:\n",
    "                                remote_ids = json_data['remote_ids']\n",
    "                                if isinstance(remote_ids, dict) and 'wikidata' in remote_ids:\n",
    "                                    author_info['wikidata'] = remote_ids['wikidata']\n",
    "                            \n",
    "                            # Extraire les noms alternatifs\n",
    "                            if 'alternate_names' in json_data and json_data['alternate_names']:\n",
    "                                if isinstance(json_data['alternate_names'], list):\n",
    "                                    author_info['alternate_names'] = ' | '.join(json_data['alternate_names'])\n",
    "                            \n",
    "                            # Extraire les photos\n",
    "                            if 'photos' in json_data and json_data['photos']:\n",
    "                                if isinstance(json_data['photos'], list):\n",
    "                                    author_info['photos'] = ' | '.join([str(photo) for photo in json_data['photos']])\n",
    "                            \n",
    "                            # Traiter les dates pour extraire les années\n",
    "                            try:\n",
    "                                # Extraire l'année de naissance\n",
    "                                birth_match = re.search(r'\\b(\\d{4})\\b', str(birth_date))\n",
    "                                if birth_match:\n",
    "                                    birth_year = int(birth_match.group(1))\n",
    "                                    if 1000 <= birth_year <= datetime.now().year:\n",
    "                                        author_info['birth_year'] = birth_year\n",
    "                                \n",
    "                                # Extraire l'année de décès si présente\n",
    "                                if author_info['death_date']:\n",
    "                                    death_match = re.search(r'\\b(\\d{4})\\b', str(author_info['death_date']))\n",
    "                                    if death_match:\n",
    "                                        death_year = int(death_match.group(1))\n",
    "                                        if 1000 <= death_year <= datetime.now().year:\n",
    "                                            author_info['death_year'] = death_year\n",
    "                                            \n",
    "                                            # Calculer l'âge au décès\n",
    "                                            if author_info['birth_year']:\n",
    "                                                author_info['age_at_death'] = death_year - author_info['birth_year']\n",
    "                                                author_info['is_alive'] = False\n",
    "                                        else:\n",
    "                                            author_info['is_alive'] = True\n",
    "                                else:\n",
    "                                    # Pas de date de décès = probablement vivant\n",
    "                                    if author_info['birth_year']:\n",
    "                                        current_year = datetime.now().year\n",
    "                                        age_now = current_year - author_info['birth_year']\n",
    "                                        # Si la personne aurait plus de 120 ans, elle est probablement décédée\n",
    "                                        author_info['is_alive'] = age_now <= 120\n",
    "                            \n",
    "                            except Exception:\n",
    "                                pass  # Ignorer les erreurs de parsing de dates\n",
    "                            \n",
    "                            authors_data.append(author_info)\n",
    "                            authors_found += 1\n",
    "                    \n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "                \n",
    "                # Afficher le progrès\n",
    "                if total_processed % 10000 == 0:\n",
    "                    print(f\"   Traité {total_processed:,} auteurs, trouvé {authors_found:,} avec date de naissance...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'extraction : {e}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"✅ Extraction terminée : {authors_found:,} auteurs avec date de naissance trouvés sur {total_processed:,} auteurs traités\")\n",
    "    return authors_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_authors_dataframe(authors_data):\n",
    "    \"\"\"Crée un DataFrame pandas à partir des données d'auteurs\"\"\"\n",
    "    print(f\"📊 Création du DataFrame avec {len(authors_data):,} auteurs...\")\n",
    "    \n",
    "    df = pd.DataFrame(authors_data)\n",
    "    \n",
    "    # Statistiques sur le DataFrame\n",
    "    print(f\"\\n📈 STATISTIQUES DU DATAFRAME :\")\n",
    "    print(f\"   📏 Dimensions : {df.shape[0]:,} lignes × {df.shape[1]} colonnes\")\n",
    "    print(f\"   🎂 Années de naissance : {df['birth_year'].min()} - {df['birth_year'].max()}\")\n",
    "    \n",
    "    # Répartition par siècle\n",
    "    if 'birth_year' in df.columns and df['birth_year'].notna().sum() > 0:\n",
    "        birth_years = df['birth_year'].dropna()\n",
    "        print(f\"\\n🏛️ RÉPARTITION PAR SIÈCLE :\")\n",
    "        for century in range(15, 22):  # 15ème au 21ème siècle\n",
    "            start_year = (century - 1) * 100 + 1\n",
    "            end_year = century * 100\n",
    "            count = birth_years[(birth_years >= start_year) & (birth_years <= end_year)].count()\n",
    "            if count > 0:\n",
    "                print(f\"   • {century}ème siècle ({start_year}-{end_year}) : {count:,} auteurs\")\n",
    "    \n",
    "    # Taux de remplissage des champs\n",
    "    print(f\"\\n📋 TAUX DE REMPLISSAGE DES CHAMPS :\")\n",
    "    for col in df.columns:\n",
    "        if col in ['bio', 'wikipedia', 'wikidata', 'alternate_names', 'death_date', 'photos', 'website']:\n",
    "            non_empty = df[col].notna() & (df[col] != '')\n",
    "            percentage = (non_empty.sum() / len(df)) * 100\n",
    "            print(f\"   • {col:<20} : {non_empty.sum():>6,} ({percentage:>5.1f}%)\")\n",
    "    \n",
    "    # Auteurs vivants vs décédés\n",
    "    if 'is_alive' in df.columns:\n",
    "        alive_count = df['is_alive'].sum()\n",
    "        dead_count = (df['is_alive'] == False).sum()\n",
    "        unknown_count = df['is_alive'].isna().sum()\n",
    "        print(f\"\\n👥 STATUT VITAL :\")\n",
    "        print(f\"   🟢 Probablement vivants : {alive_count:,}\")\n",
    "        print(f\"   🔴 Probablement décédés : {dead_count:,}\")\n",
    "        print(f\"   ❓ Statut inconnu       : {unknown_count:,}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def display_dataframe_sample(df, n=10):\n",
    "    \"\"\"Affiche un échantillon du DataFrame\"\"\"\n",
    "    print(f\"\\n📋 APERÇU DU DATAFRAME (premiers {n} auteurs) :\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Sélectionner les colonnes les plus importantes pour l'affichage\n",
    "    display_cols = ['name', 'birth_year', 'death_year', 'age_at_death', 'is_alive']\n",
    "    available_cols = [col for col in display_cols if col in df.columns]\n",
    "    \n",
    "    print(df[available_cols].head(n).to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n🔍 QUELQUES EXEMPLES INTÉRESSANTS :\")\n",
    "    \n",
    "    # Auteurs les plus anciens\n",
    "    if 'birth_year' in df.columns:\n",
    "        oldest = df.nsmallest(3, 'birth_year')[['name', 'birth_year', 'death_year']]\n",
    "        print(f\"\\n👴 AUTEURS LES PLUS ANCIENS :\")\n",
    "        for _, author in oldest.iterrows():\n",
    "            death_info = f\" (mort en {author['death_year']:.0f})\" if pd.notna(author['death_year']) else \" (date de décès inconnue)\"\n",
    "            print(f\"   • {author['name']} - né en {author['birth_year']:.0f}{death_info}\")\n",
    "    \n",
    "    # Auteurs les plus récents\n",
    "    if 'birth_year' in df.columns:\n",
    "        youngest = df.nlargest(3, 'birth_year')[['name', 'birth_year', 'is_alive']]\n",
    "        print(f\"\\n👶 AUTEURS LES PLUS RÉCENTS :\")\n",
    "        for _, author in youngest.iterrows():\n",
    "            status = \" (probablement vivant)\" if author['is_alive'] else \" (statut inconnu)\"\n",
    "            print(f\"   • {author['name']} - né en {author['birth_year']:.0f}{status}\")\n",
    "    \n",
    "    # Auteurs avec biographie\n",
    "    if 'bio' in df.columns:\n",
    "        with_bio = df[df['bio'].str.len() > 50].head(3)\n",
    "        if not with_bio.empty:\n",
    "            print(f\"\\n📚 AUTEURS AVEC BIOGRAPHIE :\")\n",
    "            for _, author in with_bio.iterrows():\n",
    "                bio_preview = author['bio'][:100] + \"...\" if len(author['bio']) > 100 else author['bio']\n",
    "                print(f\"   • {author['name']} : {bio_preview}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier trouvé : ol_dump_authors_2025-05-31.txt\n",
      "\n",
      "⚠️ ATTENTION : Le fichier complet peut contenir des millions d'auteurs.\n",
      "Pour un test rapide, vous pouvez limiter à un échantillon.\n",
      "\n",
      "Options :\n",
      "  1. Échantillon rapide (10,000 premiers auteurs avec date de naissance)\n",
      "  2. Échantillon moyen (50,000 premiers auteurs avec date de naissance)\n",
      "  3. Extraction complète (TOUS les auteurs - peut prendre du temps)\n",
      "\n",
      "🚀 Extraction complète (TOUS les auteurs avec date de naissance)...\n",
      "🔍 Recherche des auteurs avec date de naissance...\n",
      "   Traité 10,000 auteurs, trouvé 878 avec date de naissance...\n",
      "   Traité 20,000 auteurs, trouvé 1,696 avec date de naissance...\n",
      "   Traité 30,000 auteurs, trouvé 3,525 avec date de naissance...\n",
      "   Traité 40,000 auteurs, trouvé 4,885 avec date de naissance...\n",
      "   Traité 50,000 auteurs, trouvé 6,343 avec date de naissance...\n",
      "   Traité 60,000 auteurs, trouvé 7,226 avec date de naissance...\n",
      "   Traité 70,000 auteurs, trouvé 8,030 avec date de naissance...\n",
      "   Traité 80,000 auteurs, trouvé 9,179 avec date de naissance...\n",
      "   Traité 90,000 auteurs, trouvé 10,628 avec date de naissance...\n",
      "   Traité 100,000 auteurs, trouvé 12,465 avec date de naissance...\n",
      "   Traité 110,000 auteurs, trouvé 14,043 avec date de naissance...\n",
      "   Traité 120,000 auteurs, trouvé 14,525 avec date de naissance...\n",
      "   Traité 130,000 auteurs, trouvé 15,619 avec date de naissance...\n",
      "   Traité 140,000 auteurs, trouvé 17,373 avec date de naissance...\n",
      "   Traité 150,000 auteurs, trouvé 18,369 avec date de naissance...\n",
      "   Traité 160,000 auteurs, trouvé 20,375 avec date de naissance...\n",
      "   Traité 170,000 auteurs, trouvé 21,343 avec date de naissance...\n",
      "   Traité 180,000 auteurs, trouvé 22,241 avec date de naissance...\n",
      "   Traité 190,000 auteurs, trouvé 23,050 avec date de naissance...\n",
      "   Traité 200,000 auteurs, trouvé 24,767 avec date de naissance...\n",
      "   Traité 210,000 auteurs, trouvé 26,127 avec date de naissance...\n",
      "   Traité 220,000 auteurs, trouvé 27,554 avec date de naissance...\n",
      "   Traité 230,000 auteurs, trouvé 28,483 avec date de naissance...\n",
      "   Traité 240,000 auteurs, trouvé 29,372 avec date de naissance...\n",
      "   Traité 250,000 auteurs, trouvé 30,481 avec date de naissance...\n",
      "   Traité 260,000 auteurs, trouvé 31,875 avec date de naissance...\n",
      "   Traité 270,000 auteurs, trouvé 33,668 avec date de naissance...\n",
      "   Traité 280,000 auteurs, trouvé 35,269 avec date de naissance...\n",
      "   Traité 290,000 auteurs, trouvé 35,818 avec date de naissance...\n",
      "   Traité 300,000 auteurs, trouvé 36,897 avec date de naissance...\n",
      "   Traité 310,000 auteurs, trouvé 38,720 avec date de naissance...\n",
      "   Traité 320,000 auteurs, trouvé 39,703 avec date de naissance...\n",
      "   Traité 330,000 auteurs, trouvé 41,714 avec date de naissance...\n",
      "   Traité 340,000 auteurs, trouvé 42,623 avec date de naissance...\n",
      "   Traité 350,000 auteurs, trouvé 43,511 avec date de naissance...\n",
      "   Traité 360,000 auteurs, trouvé 44,364 avec date de naissance...\n",
      "   Traité 370,000 auteurs, trouvé 46,111 avec date de naissance...\n",
      "   Traité 380,000 auteurs, trouvé 47,488 avec date de naissance...\n",
      "   Traité 390,000 auteurs, trouvé 48,910 avec date de naissance...\n",
      "   Traité 400,000 auteurs, trouvé 49,813 avec date de naissance...\n",
      "   Traité 410,000 auteurs, trouvé 50,710 avec date de naissance...\n",
      "   Traité 420,000 auteurs, trouvé 51,905 avec date de naissance...\n",
      "   Traité 430,000 auteurs, trouvé 53,263 avec date de naissance...\n",
      "   Traité 440,000 auteurs, trouvé 55,194 avec date de naissance...\n",
      "   Traité 450,000 auteurs, trouvé 56,561 avec date de naissance...\n",
      "   Traité 460,000 auteurs, trouvé 57,153 avec date de naissance...\n",
      "   Traité 470,000 auteurs, trouvé 58,137 avec date de naissance...\n",
      "   Traité 480,000 auteurs, trouvé 60,085 avec date de naissance...\n",
      "   Traité 490,000 auteurs, trouvé 61,011 avec date de naissance...\n",
      "   Traité 500,000 auteurs, trouvé 62,891 avec date de naissance...\n",
      "   Traité 510,000 auteurs, trouvé 63,831 avec date de naissance...\n",
      "   Traité 520,000 auteurs, trouvé 64,737 avec date de naissance...\n",
      "   Traité 530,000 auteurs, trouvé 65,631 avec date de naissance...\n",
      "   Traité 540,000 auteurs, trouvé 67,391 avec date de naissance...\n",
      "   Traité 550,000 auteurs, trouvé 68,862 avec date de naissance...\n",
      "   Traité 560,000 auteurs, trouvé 70,441 avec date de naissance...\n",
      "   Traité 570,000 auteurs, trouvé 71,238 avec date de naissance...\n",
      "   Traité 580,000 auteurs, trouvé 72,186 avec date de naissance...\n",
      "   Traité 590,000 auteurs, trouvé 73,498 avec date de naissance...\n",
      "   Traité 600,000 auteurs, trouvé 74,742 avec date de naissance...\n",
      "   Traité 610,000 auteurs, trouvé 76,726 avec date de naissance...\n",
      "   Traité 620,000 auteurs, trouvé 78,060 avec date de naissance...\n",
      "   Traité 630,000 auteurs, trouvé 78,760 avec date de naissance...\n",
      "   Traité 640,000 auteurs, trouvé 79,672 avec date de naissance...\n",
      "   Traité 650,000 auteurs, trouvé 81,567 avec date de naissance...\n",
      "   Traité 660,000 auteurs, trouvé 82,571 avec date de naissance...\n",
      "   Traité 670,000 auteurs, trouvé 84,448 avec date de naissance...\n",
      "   Traité 680,000 auteurs, trouvé 85,371 avec date de naissance...\n",
      "   Traité 690,000 auteurs, trouvé 86,217 avec date de naissance...\n",
      "   Traité 700,000 auteurs, trouvé 87,229 avec date de naissance...\n",
      "   Traité 710,000 auteurs, trouvé 88,881 avec date de naissance...\n",
      "   Traité 720,000 auteurs, trouvé 90,445 avec date de naissance...\n",
      "   Traité 730,000 auteurs, trouvé 92,025 avec date de naissance...\n",
      "   Traité 740,000 auteurs, trouvé 92,672 avec date de naissance...\n",
      "   Traité 750,000 auteurs, trouvé 93,714 avec date de naissance...\n",
      "   Traité 760,000 auteurs, trouvé 95,044 avec date de naissance...\n",
      "   Traité 770,000 auteurs, trouvé 96,232 avec date de naissance...\n",
      "   Traité 780,000 auteurs, trouvé 98,224 avec date de naissance...\n",
      "   Traité 790,000 auteurs, trouvé 99,444 avec date de naissance...\n",
      "   Traité 800,000 auteurs, trouvé 100,260 avec date de naissance...\n",
      "   Traité 810,000 auteurs, trouvé 101,097 avec date de naissance...\n",
      "   Traité 820,000 auteurs, trouvé 102,928 avec date de naissance...\n",
      "   Traité 830,000 auteurs, trouvé 104,073 avec date de naissance...\n",
      "   Traité 840,000 auteurs, trouvé 105,791 avec date de naissance...\n",
      "   Traité 850,000 auteurs, trouvé 106,745 avec date de naissance...\n",
      "   Traité 860,000 auteurs, trouvé 107,602 avec date de naissance...\n",
      "   Traité 870,000 auteurs, trouvé 108,622 avec date de naissance...\n",
      "   Traité 880,000 auteurs, trouvé 110,313 avec date de naissance...\n",
      "   Traité 890,000 auteurs, trouvé 111,799 avec date de naissance...\n",
      "   Traité 900,000 auteurs, trouvé 113,403 avec date de naissance...\n",
      "   Traité 910,000 auteurs, trouvé 114,016 avec date de naissance...\n",
      "   Traité 920,000 auteurs, trouvé 115,007 avec date de naissance...\n",
      "   Traité 930,000 auteurs, trouvé 116,435 avec date de naissance...\n",
      "   Traité 940,000 auteurs, trouvé 117,711 avec date de naissance...\n",
      "   Traité 950,000 auteurs, trouvé 119,710 avec date de naissance...\n",
      "   Traité 960,000 auteurs, trouvé 120,829 avec date de naissance...\n",
      "   Traité 970,000 auteurs, trouvé 121,669 avec date de naissance...\n",
      "   Traité 980,000 auteurs, trouvé 122,443 avec date de naissance...\n",
      "   Traité 990,000 auteurs, trouvé 124,269 avec date de naissance...\n",
      "   Traité 1,000,000 auteurs, trouvé 125,564 avec date de naissance...\n",
      "   Traité 1,010,000 auteurs, trouvé 127,231 avec date de naissance...\n",
      "   Traité 1,020,000 auteurs, trouvé 128,203 avec date de naissance...\n",
      "   Traité 1,030,000 auteurs, trouvé 129,088 avec date de naissance...\n",
      "   Traité 1,040,000 auteurs, trouvé 130,195 avec date de naissance...\n",
      "   Traité 1,050,000 auteurs, trouvé 131,674 avec date de naissance...\n",
      "   Traité 1,060,000 auteurs, trouvé 133,363 avec date de naissance...\n",
      "   Traité 1,070,000 auteurs, trouvé 134,976 avec date de naissance...\n",
      "   Traité 1,080,000 auteurs, trouvé 135,457 avec date de naissance...\n",
      "   Traité 1,090,000 auteurs, trouvé 136,480 avec date de naissance...\n",
      "   Traité 1,100,000 auteurs, trouvé 138,090 avec date de naissance...\n",
      "   Traité 1,110,000 auteurs, trouvé 139,241 avec date de naissance...\n",
      "   Traité 1,120,000 auteurs, trouvé 141,247 avec date de naissance...\n",
      "   Traité 1,130,000 auteurs, trouvé 142,291 avec date de naissance...\n",
      "   Traité 1,140,000 auteurs, trouvé 143,138 avec date de naissance...\n",
      "   Traité 1,150,000 auteurs, trouvé 143,908 avec date de naissance...\n",
      "   Traité 1,160,000 auteurs, trouvé 145,788 avec date de naissance...\n",
      "   Traité 1,170,000 auteurs, trouvé 147,109 avec date de naissance...\n",
      "   Traité 1,180,000 auteurs, trouvé 148,642 avec date de naissance...\n",
      "   Traité 1,190,000 auteurs, trouvé 149,642 avec date de naissance...\n",
      "   Traité 1,200,000 auteurs, trouvé 150,483 avec date de naissance...\n",
      "   Traité 1,210,000 auteurs, trouvé 151,627 avec date de naissance...\n",
      "   Traité 1,220,000 auteurs, trouvé 153,141 avec date de naissance...\n",
      "   Traité 1,230,000 auteurs, trouvé 154,939 avec date de naissance...\n",
      "   Traité 1,240,000 auteurs, trouvé 156,418 avec date de naissance...\n",
      "   Traité 1,250,000 auteurs, trouvé 156,957 avec date de naissance...\n",
      "   Traité 1,260,000 auteurs, trouvé 158,021 avec date de naissance...\n",
      "   Traité 1,270,000 auteurs, trouvé 159,798 avec date de naissance...\n",
      "   Traité 1,280,000 auteurs, trouvé 160,723 avec date de naissance...\n",
      "   Traité 1,290,000 auteurs, trouvé 162,728 avec date de naissance...\n",
      "   Traité 1,300,000 auteurs, trouvé 163,802 avec date de naissance...\n",
      "   Traité 1,310,000 auteurs, trouvé 164,664 avec date de naissance...\n",
      "   Traité 1,320,000 auteurs, trouvé 165,459 avec date de naissance...\n",
      "   Traité 1,330,000 auteurs, trouvé 167,355 avec date de naissance...\n",
      "   Traité 1,340,000 auteurs, trouvé 168,728 avec date de naissance...\n",
      "   Traité 1,350,000 auteurs, trouvé 170,266 avec date de naissance...\n",
      "   Traité 1,360,000 auteurs, trouvé 171,222 avec date de naissance...\n",
      "   Traité 1,370,000 auteurs, trouvé 172,064 avec date de naissance...\n",
      "   Traité 1,380,000 auteurs, trouvé 173,111 avec date de naissance...\n",
      "   Traité 1,390,000 auteurs, trouvé 174,630 avec date de naissance...\n",
      "   Traité 1,400,000 auteurs, trouvé 176,289 avec date de naissance...\n",
      "   Traité 1,410,000 auteurs, trouvé 177,849 avec date de naissance...\n",
      "   Traité 1,420,000 auteurs, trouvé 178,324 avec date de naissance...\n",
      "   Traité 1,430,000 auteurs, trouvé 179,381 avec date de naissance...\n",
      "   Traité 1,440,000 auteurs, trouvé 180,977 avec date de naissance...\n",
      "   Traité 1,450,000 auteurs, trouvé 182,045 avec date de naissance...\n",
      "   Traité 1,460,000 auteurs, trouvé 184,123 avec date de naissance...\n",
      "   Traité 1,470,000 auteurs, trouvé 185,160 avec date de naissance...\n",
      "   Traité 1,480,000 auteurs, trouvé 186,048 avec date de naissance...\n",
      "   Traité 1,490,000 auteurs, trouvé 186,799 avec date de naissance...\n",
      "   Traité 1,500,000 auteurs, trouvé 188,698 avec date de naissance...\n",
      "   Traité 1,510,000 auteurs, trouvé 190,076 avec date de naissance...\n",
      "   Traité 1,520,000 auteurs, trouvé 191,552 avec date de naissance...\n",
      "   Traité 1,530,000 auteurs, trouvé 192,526 avec date de naissance...\n",
      "   Traité 1,540,000 auteurs, trouvé 193,401 avec date de naissance...\n",
      "   Traité 1,550,000 auteurs, trouvé 194,499 avec date de naissance...\n",
      "   Traité 1,560,000 auteurs, trouvé 196,045 avec date de naissance...\n",
      "   Traité 1,570,000 auteurs, trouvé 197,755 avec date de naissance...\n",
      "   Traité 1,580,000 auteurs, trouvé 199,297 avec date de naissance...\n",
      "   Traité 1,590,000 auteurs, trouvé 199,771 avec date de naissance...\n",
      "   Traité 1,600,000 auteurs, trouvé 200,833 avec date de naissance...\n",
      "   Traité 1,610,000 auteurs, trouvé 202,483 avec date de naissance...\n",
      "   Traité 1,620,000 auteurs, trouvé 203,526 avec date de naissance...\n",
      "   Traité 1,630,000 auteurs, trouvé 205,566 avec date de naissance...\n",
      "   Traité 1,640,000 auteurs, trouvé 206,540 avec date de naissance...\n",
      "   Traité 1,650,000 auteurs, trouvé 207,430 avec date de naissance...\n",
      "   Traité 1,660,000 auteurs, trouvé 208,231 avec date de naissance...\n",
      "   Traité 1,670,000 auteurs, trouvé 210,094 avec date de naissance...\n",
      "   Traité 1,680,000 auteurs, trouvé 211,463 avec date de naissance...\n",
      "   Traité 1,690,000 auteurs, trouvé 212,988 avec date de naissance...\n",
      "   Traité 1,700,000 auteurs, trouvé 213,904 avec date de naissance...\n",
      "   Traité 1,710,000 auteurs, trouvé 214,817 avec date de naissance...\n",
      "   Traité 1,720,000 auteurs, trouvé 216,002 avec date de naissance...\n",
      "   Traité 1,730,000 auteurs, trouvé 217,416 avec date de naissance...\n",
      "   Traité 1,740,000 auteurs, trouvé 219,245 avec date de naissance...\n",
      "   Traité 1,750,000 auteurs, trouvé 220,785 avec date de naissance...\n",
      "   Traité 1,760,000 auteurs, trouvé 221,278 avec date de naissance...\n",
      "   Traité 1,770,000 auteurs, trouvé 222,305 avec date de naissance...\n",
      "   Traité 1,780,000 auteurs, trouvé 224,144 avec date de naissance...\n",
      "   Traité 1,790,000 auteurs, trouvé 225,114 avec date de naissance...\n",
      "   Traité 1,800,000 auteurs, trouvé 227,073 avec date de naissance...\n",
      "   Traité 1,810,000 auteurs, trouvé 228,040 avec date de naissance...\n",
      "   Traité 1,820,000 auteurs, trouvé 228,902 avec date de naissance...\n",
      "   Traité 1,830,000 auteurs, trouvé 229,722 avec date de naissance...\n",
      "   Traité 1,840,000 auteurs, trouvé 231,480 avec date de naissance...\n",
      "   Traité 1,850,000 auteurs, trouvé 232,886 avec date de naissance...\n",
      "   Traité 1,860,000 auteurs, trouvé 234,317 avec date de naissance...\n",
      "   Traité 1,870,000 auteurs, trouvé 235,186 avec date de naissance...\n",
      "   Traité 1,880,000 auteurs, trouvé 236,072 avec date de naissance...\n",
      "   Traité 1,890,000 auteurs, trouvé 237,218 avec date de naissance...\n",
      "   Traité 1,900,000 auteurs, trouvé 238,599 avec date de naissance...\n",
      "   Traité 1,910,000 auteurs, trouvé 240,501 avec date de naissance...\n",
      "   Traité 1,920,000 auteurs, trouvé 241,965 avec date de naissance...\n",
      "   Traité 1,930,000 auteurs, trouvé 242,561 avec date de naissance...\n",
      "   Traité 1,940,000 auteurs, trouvé 243,631 avec date de naissance...\n",
      "   Traité 1,950,000 auteurs, trouvé 245,508 avec date de naissance...\n",
      "   Traité 1,960,000 auteurs, trouvé 246,409 avec date de naissance...\n",
      "   Traité 1,970,000 auteurs, trouvé 248,305 avec date de naissance...\n",
      "   Traité 1,980,000 auteurs, trouvé 249,267 avec date de naissance...\n",
      "   Traité 1,990,000 auteurs, trouvé 250,093 avec date de naissance...\n",
      "   Traité 2,000,000 auteurs, trouvé 250,979 avec date de naissance...\n",
      "   Traité 2,010,000 auteurs, trouvé 252,678 avec date de naissance...\n",
      "   Traité 2,020,000 auteurs, trouvé 254,128 avec date de naissance...\n",
      "   Traité 2,030,000 auteurs, trouvé 255,623 avec date de naissance...\n",
      "   Traité 2,040,000 auteurs, trouvé 256,500 avec date de naissance...\n",
      "   Traité 2,050,000 auteurs, trouvé 257,500 avec date de naissance...\n",
      "   Traité 2,060,000 auteurs, trouvé 258,641 avec date de naissance...\n",
      "   Traité 2,070,000 auteurs, trouvé 259,978 avec date de naissance...\n",
      "   Traité 2,080,000 auteurs, trouvé 261,896 avec date de naissance...\n",
      "   Traité 2,090,000 auteurs, trouvé 263,333 avec date de naissance...\n",
      "   Traité 2,100,000 auteurs, trouvé 263,910 avec date de naissance...\n",
      "   Traité 2,110,000 auteurs, trouvé 264,944 avec date de naissance...\n",
      "   Traité 2,120,000 auteurs, trouvé 266,811 avec date de naissance...\n",
      "   Traité 2,130,000 auteurs, trouvé 267,692 avec date de naissance...\n",
      "   Traité 2,140,000 auteurs, trouvé 269,633 avec date de naissance...\n",
      "   Traité 2,150,000 auteurs, trouvé 270,578 avec date de naissance...\n",
      "   Traité 2,160,000 auteurs, trouvé 271,439 avec date de naissance...\n",
      "   Traité 2,170,000 auteurs, trouvé 272,302 avec date de naissance...\n",
      "   Traité 2,180,000 auteurs, trouvé 274,053 avec date de naissance...\n",
      "   Traité 2,190,000 auteurs, trouvé 275,434 avec date de naissance...\n",
      "   Traité 2,200,000 auteurs, trouvé 276,923 avec date de naissance...\n",
      "   Traité 2,210,000 auteurs, trouvé 277,815 avec date de naissance...\n",
      "   Traité 2,220,000 auteurs, trouvé 278,746 avec date de naissance...\n",
      "   Traité 2,230,000 auteurs, trouvé 279,960 avec date de naissance...\n",
      "   Traité 2,240,000 auteurs, trouvé 281,343 avec date de naissance...\n",
      "   Traité 2,250,000 auteurs, trouvé 283,213 avec date de naissance...\n",
      "   Traité 2,260,000 auteurs, trouvé 284,640 avec date de naissance...\n",
      "   Traité 2,270,000 auteurs, trouvé 285,238 avec date de naissance...\n",
      "   Traité 2,280,000 auteurs, trouvé 286,296 avec date de naissance...\n",
      "   Traité 2,290,000 auteurs, trouvé 288,165 avec date de naissance...\n",
      "   Traité 2,300,000 auteurs, trouvé 289,124 avec date de naissance...\n",
      "   Traité 2,310,000 auteurs, trouvé 290,924 avec date de naissance...\n",
      "   Traité 2,320,000 auteurs, trouvé 291,827 avec date de naissance...\n",
      "   Traité 2,330,000 auteurs, trouvé 292,713 avec date de naissance...\n",
      "   Traité 2,340,000 auteurs, trouvé 293,671 avec date de naissance...\n",
      "   Traité 2,350,000 auteurs, trouvé 295,279 avec date de naissance...\n",
      "   Traité 2,360,000 auteurs, trouvé 296,692 avec date de naissance...\n",
      "   Traité 2,370,000 auteurs, trouvé 298,226 avec date de naissance...\n",
      "   Traité 2,380,000 auteurs, trouvé 298,989 avec date de naissance...\n",
      "   Traité 2,390,000 auteurs, trouvé 299,975 avec date de naissance...\n",
      "   Traité 2,400,000 auteurs, trouvé 301,275 avec date de naissance...\n",
      "   Traité 2,410,000 auteurs, trouvé 302,581 avec date de naissance...\n",
      "   Traité 2,420,000 auteurs, trouvé 304,576 avec date de naissance...\n",
      "   Traité 2,430,000 auteurs, trouvé 305,910 avec date de naissance...\n",
      "   Traité 2,440,000 auteurs, trouvé 306,608 avec date de naissance...\n",
      "   Traité 2,450,000 auteurs, trouvé 307,554 avec date de naissance...\n",
      "   Traité 2,460,000 auteurs, trouvé 309,383 avec date de naissance...\n",
      "   Traité 2,470,000 auteurs, trouvé 310,448 avec date de naissance...\n",
      "   Traité 2,480,000 auteurs, trouvé 312,205 avec date de naissance...\n",
      "   Traité 2,490,000 auteurs, trouvé 313,149 avec date de naissance...\n",
      "   Traité 2,500,000 auteurs, trouvé 314,000 avec date de naissance...\n",
      "   Traité 2,510,000 auteurs, trouvé 315,003 avec date de naissance...\n",
      "   Traité 2,520,000 auteurs, trouvé 316,596 avec date de naissance...\n",
      "   Traité 2,530,000 auteurs, trouvé 318,114 avec date de naissance...\n",
      "   Traité 2,540,000 auteurs, trouvé 319,666 avec date de naissance...\n",
      "   Traité 2,550,000 auteurs, trouvé 320,254 avec date de naissance...\n",
      "   Traité 2,560,000 auteurs, trouvé 321,265 avec date de naissance...\n",
      "   Traité 2,570,000 auteurs, trouvé 322,639 avec date de naissance...\n",
      "   Traité 2,580,000 auteurs, trouvé 323,837 avec date de naissance...\n",
      "   Traité 2,590,000 auteurs, trouvé 325,892 avec date de naissance...\n",
      "   Traité 2,600,000 auteurs, trouvé 327,026 avec date de naissance...\n",
      "   Traité 2,610,000 auteurs, trouvé 327,883 avec date de naissance...\n",
      "   Traité 2,620,000 auteurs, trouvé 328,679 avec date de naissance...\n",
      "   Traité 2,630,000 auteurs, trouvé 330,521 avec date de naissance...\n",
      "   Traité 2,640,000 auteurs, trouvé 331,694 avec date de naissance...\n",
      "   Traité 2,650,000 auteurs, trouvé 333,364 avec date de naissance...\n",
      "   Traité 2,660,000 auteurs, trouvé 334,311 avec date de naissance...\n",
      "   Traité 2,670,000 auteurs, trouvé 335,174 avec date de naissance...\n",
      "   Traité 2,680,000 auteurs, trouvé 336,187 avec date de naissance...\n",
      "   Traité 2,690,000 auteurs, trouvé 337,822 avec date de naissance...\n",
      "   Traité 2,700,000 auteurs, trouvé 339,512 avec date de naissance...\n",
      "   Traité 2,710,000 auteurs, trouvé 341,120 avec date de naissance...\n",
      "   Traité 2,720,000 auteurs, trouvé 341,625 avec date de naissance...\n",
      "   Traité 2,730,000 auteurs, trouvé 342,603 avec date de naissance...\n",
      "   Traité 2,740,000 auteurs, trouvé 344,178 avec date de naissance...\n",
      "   Traité 2,750,000 auteurs, trouvé 345,387 avec date de naissance...\n",
      "   Traité 2,760,000 auteurs, trouvé 347,381 avec date de naissance...\n",
      "   Traité 2,770,000 auteurs, trouvé 348,483 avec date de naissance...\n",
      "   Traité 2,780,000 auteurs, trouvé 349,337 avec date de naissance...\n",
      "   Traité 2,790,000 auteurs, trouvé 350,109 avec date de naissance...\n",
      "   Traité 2,800,000 auteurs, trouvé 352,015 avec date de naissance...\n",
      "   Traité 2,810,000 auteurs, trouvé 353,258 avec date de naissance...\n",
      "   Traité 2,820,000 auteurs, trouvé 354,879 avec date de naissance...\n",
      "   Traité 2,830,000 auteurs, trouvé 355,821 avec date de naissance...\n",
      "   Traité 2,840,000 auteurs, trouvé 356,720 avec date de naissance...\n",
      "   Traité 2,850,000 auteurs, trouvé 357,747 avec date de naissance...\n",
      "   Traité 2,860,000 auteurs, trouvé 359,354 avec date de naissance...\n",
      "   Traité 2,870,000 auteurs, trouvé 361,017 avec date de naissance...\n",
      "   Traité 2,880,000 auteurs, trouvé 362,609 avec date de naissance...\n",
      "   Traité 2,890,000 auteurs, trouvé 363,175 avec date de naissance...\n",
      "   Traité 2,900,000 auteurs, trouvé 364,150 avec date de naissance...\n",
      "   Traité 2,910,000 auteurs, trouvé 365,658 avec date de naissance...\n",
      "   Traité 2,920,000 auteurs, trouvé 366,883 avec date de naissance...\n",
      "   Traité 2,930,000 auteurs, trouvé 368,961 avec date de naissance...\n",
      "   Traité 2,940,000 auteurs, trouvé 370,103 avec date de naissance...\n",
      "   Traité 2,950,000 auteurs, trouvé 370,938 avec date de naissance...\n",
      "   Traité 2,960,000 auteurs, trouvé 371,737 avec date de naissance...\n",
      "   Traité 2,970,000 auteurs, trouvé 373,576 avec date de naissance...\n",
      "   Traité 2,980,000 auteurs, trouvé 374,743 avec date de naissance...\n",
      "   Traité 2,990,000 auteurs, trouvé 376,384 avec date de naissance...\n",
      "   Traité 3,000,000 auteurs, trouvé 377,298 avec date de naissance...\n",
      "   Traité 3,010,000 auteurs, trouvé 378,128 avec date de naissance...\n",
      "   Traité 3,020,000 auteurs, trouvé 379,160 avec date de naissance...\n",
      "   Traité 3,030,000 auteurs, trouvé 380,687 avec date de naissance...\n",
      "   Traité 3,040,000 auteurs, trouvé 382,255 avec date de naissance...\n",
      "   Traité 3,050,000 auteurs, trouvé 383,871 avec date de naissance...\n",
      "   Traité 3,060,000 auteurs, trouvé 384,438 avec date de naissance...\n",
      "   Traité 3,070,000 auteurs, trouvé 385,401 avec date de naissance...\n",
      "   Traité 3,080,000 auteurs, trouvé 386,914 avec date de naissance...\n",
      "   Traité 3,090,000 auteurs, trouvé 388,143 avec date de naissance...\n",
      "   Traité 3,100,000 auteurs, trouvé 390,158 avec date de naissance...\n",
      "   Traité 3,110,000 auteurs, trouvé 391,242 avec date de naissance...\n",
      "   Traité 3,120,000 auteurs, trouvé 392,127 avec date de naissance...\n",
      "   Traité 3,130,000 auteurs, trouvé 392,925 avec date de naissance...\n",
      "   Traité 3,140,000 auteurs, trouvé 394,825 avec date de naissance...\n",
      "   Traité 3,150,000 auteurs, trouvé 396,040 avec date de naissance...\n",
      "   Traité 3,160,000 auteurs, trouvé 397,572 avec date de naissance...\n",
      "   Traité 3,170,000 auteurs, trouvé 398,503 avec date de naissance...\n",
      "   Traité 3,180,000 auteurs, trouvé 399,328 avec date de naissance...\n",
      "   Traité 3,190,000 auteurs, trouvé 400,409 avec date de naissance...\n",
      "   Traité 3,200,000 auteurs, trouvé 402,043 avec date de naissance...\n",
      "   Traité 3,210,000 auteurs, trouvé 403,658 avec date de naissance...\n",
      "   Traité 3,220,000 auteurs, trouvé 405,287 avec date de naissance...\n",
      "   Traité 3,230,000 auteurs, trouvé 405,763 avec date de naissance...\n",
      "   Traité 3,240,000 auteurs, trouvé 406,762 avec date de naissance...\n",
      "   Traité 3,250,000 auteurs, trouvé 408,328 avec date de naissance...\n",
      "   Traité 3,260,000 auteurs, trouvé 409,403 avec date de naissance...\n",
      "   Traité 3,270,000 auteurs, trouvé 411,480 avec date de naissance...\n",
      "   Traité 3,280,000 auteurs, trouvé 412,552 avec date de naissance...\n",
      "   Traité 3,290,000 auteurs, trouvé 413,491 avec date de naissance...\n",
      "   Traité 3,300,000 auteurs, trouvé 414,200 avec date de naissance...\n",
      "   Traité 3,310,000 auteurs, trouvé 416,049 avec date de naissance...\n",
      "   Traité 3,320,000 auteurs, trouvé 417,363 avec date de naissance...\n",
      "   Traité 3,330,000 auteurs, trouvé 418,904 avec date de naissance...\n",
      "   Traité 3,340,000 auteurs, trouvé 419,847 avec date de naissance...\n",
      "   Traité 3,350,000 auteurs, trouvé 420,694 avec date de naissance...\n",
      "   Traité 3,360,000 auteurs, trouvé 421,760 avec date de naissance...\n",
      "   Traité 3,370,000 auteurs, trouvé 423,325 avec date de naissance...\n",
      "   Traité 3,380,000 auteurs, trouvé 425,014 avec date de naissance...\n",
      "   Traité 3,390,000 auteurs, trouvé 426,619 avec date de naissance...\n",
      "   Traité 3,400,000 auteurs, trouvé 427,104 avec date de naissance...\n",
      "   Traité 3,410,000 auteurs, trouvé 428,131 avec date de naissance...\n",
      "   Traité 3,420,000 auteurs, trouvé 429,780 avec date de naissance...\n",
      "   Traité 3,430,000 auteurs, trouvé 430,874 avec date de naissance...\n",
      "   Traité 3,440,000 auteurs, trouvé 432,888 avec date de naissance...\n",
      "   Traité 3,450,000 auteurs, trouvé 433,918 avec date de naissance...\n",
      "   Traité 3,460,000 auteurs, trouvé 434,764 avec date de naissance...\n",
      "   Traité 3,470,000 auteurs, trouvé 435,540 avec date de naissance...\n",
      "   Traité 3,480,000 auteurs, trouvé 437,409 avec date de naissance...\n",
      "   Traité 3,490,000 auteurs, trouvé 438,709 avec date de naissance...\n",
      "   Traité 3,500,000 auteurs, trouvé 440,178 avec date de naissance...\n",
      "   Traité 3,510,000 auteurs, trouvé 441,147 avec date de naissance...\n",
      "   Traité 3,520,000 auteurs, trouvé 441,998 avec date de naissance...\n",
      "   Traité 3,530,000 auteurs, trouvé 443,096 avec date de naissance...\n",
      "   Traité 3,540,000 auteurs, trouvé 444,575 avec date de naissance...\n",
      "   Traité 3,550,000 auteurs, trouvé 446,303 avec date de naissance...\n",
      "   Traité 3,560,000 auteurs, trouvé 447,859 avec date de naissance...\n",
      "   Traité 3,570,000 auteurs, trouvé 448,282 avec date de naissance...\n",
      "   Traité 3,580,000 auteurs, trouvé 449,338 avec date de naissance...\n",
      "   Traité 3,590,000 auteurs, trouvé 451,047 avec date de naissance...\n",
      "   Traité 3,600,000 auteurs, trouvé 452,152 avec date de naissance...\n",
      "   Traité 3,610,000 auteurs, trouvé 454,140 avec date de naissance...\n",
      "   Traité 3,620,000 auteurs, trouvé 455,173 avec date de naissance...\n",
      "   Traité 3,630,000 auteurs, trouvé 456,004 avec date de naissance...\n",
      "   Traité 3,640,000 auteurs, trouvé 456,839 avec date de naissance...\n",
      "   Traité 3,650,000 auteurs, trouvé 458,672 avec date de naissance...\n",
      "   Traité 3,660,000 auteurs, trouvé 460,025 avec date de naissance...\n",
      "   Traité 3,670,000 auteurs, trouvé 461,478 avec date de naissance...\n",
      "   Traité 3,680,000 auteurs, trouvé 462,452 avec date de naissance...\n",
      "   Traité 3,690,000 auteurs, trouvé 463,327 avec date de naissance...\n",
      "   Traité 3,700,000 auteurs, trouvé 464,494 avec date de naissance...\n",
      "   Traité 3,710,000 auteurs, trouvé 465,973 avec date de naissance...\n",
      "   Traité 3,720,000 auteurs, trouvé 467,755 avec date de naissance...\n",
      "   Traité 3,730,000 auteurs, trouvé 469,257 avec date de naissance...\n",
      "   Traité 3,740,000 auteurs, trouvé 469,811 avec date de naissance...\n",
      "   Traité 3,750,000 auteurs, trouvé 470,911 avec date de naissance...\n",
      "   Traité 3,760,000 auteurs, trouvé 472,667 avec date de naissance...\n",
      "   Traité 3,770,000 auteurs, trouvé 473,656 avec date de naissance...\n",
      "   Traité 3,780,000 auteurs, trouvé 475,586 avec date de naissance...\n",
      "   Traité 3,790,000 auteurs, trouvé 476,554 avec date de naissance...\n",
      "   Traité 3,800,000 auteurs, trouvé 477,427 avec date de naissance...\n",
      "   Traité 3,810,000 auteurs, trouvé 478,340 avec date de naissance...\n",
      "   Traité 3,820,000 auteurs, trouvé 480,132 avec date de naissance...\n",
      "   Traité 3,830,000 auteurs, trouvé 481,554 avec date de naissance...\n",
      "   Traité 3,840,000 auteurs, trouvé 483,062 avec date de naissance...\n",
      "   Traité 3,850,000 auteurs, trouvé 483,941 avec date de naissance...\n",
      "   Traité 3,860,000 auteurs, trouvé 484,877 avec date de naissance...\n",
      "   Traité 3,870,000 auteurs, trouvé 486,084 avec date de naissance...\n",
      "   Traité 3,880,000 auteurs, trouvé 487,481 avec date de naissance...\n",
      "   Traité 3,890,000 auteurs, trouvé 489,385 avec date de naissance...\n",
      "   Traité 3,900,000 auteurs, trouvé 490,795 avec date de naissance...\n",
      "   Traité 3,910,000 auteurs, trouvé 491,398 avec date de naissance...\n",
      "   Traité 3,920,000 auteurs, trouvé 492,480 avec date de naissance...\n",
      "   Traité 3,930,000 auteurs, trouvé 494,406 avec date de naissance...\n",
      "   Traité 3,940,000 auteurs, trouvé 495,259 avec date de naissance...\n",
      "   Traité 3,950,000 auteurs, trouvé 497,227 avec date de naissance...\n",
      "   Traité 3,960,000 auteurs, trouvé 498,124 avec date de naissance...\n",
      "   Traité 3,970,000 auteurs, trouvé 498,981 avec date de naissance...\n",
      "   Traité 3,980,000 auteurs, trouvé 499,904 avec date de naissance...\n",
      "   Traité 3,990,000 auteurs, trouvé 501,635 avec date de naissance...\n",
      "   Traité 4,000,000 auteurs, trouvé 503,147 avec date de naissance...\n",
      "   Traité 4,010,000 auteurs, trouvé 504,674 avec date de naissance...\n",
      "   Traité 4,020,000 auteurs, trouvé 505,510 avec date de naissance...\n",
      "   Traité 4,030,000 auteurs, trouvé 506,452 avec date de naissance...\n",
      "   Traité 4,040,000 auteurs, trouvé 507,648 avec date de naissance...\n",
      "   Traité 4,050,000 auteurs, trouvé 508,999 avec date de naissance...\n",
      "   Traité 4,060,000 auteurs, trouvé 510,843 avec date de naissance...\n",
      "   Traité 4,070,000 auteurs, trouvé 512,255 avec date de naissance...\n",
      "   Traité 4,080,000 auteurs, trouvé 512,867 avec date de naissance...\n",
      "   Traité 4,090,000 auteurs, trouvé 513,934 avec date de naissance...\n",
      "   Traité 4,100,000 auteurs, trouvé 515,804 avec date de naissance...\n",
      "   Traité 4,110,000 auteurs, trouvé 516,747 avec date de naissance...\n",
      "   Traité 4,120,000 auteurs, trouvé 518,586 avec date de naissance...\n",
      "   Traité 4,130,000 auteurs, trouvé 519,571 avec date de naissance...\n",
      "   Traité 4,140,000 auteurs, trouvé 520,393 avec date de naissance...\n",
      "   Traité 4,150,000 auteurs, trouvé 521,348 avec date de naissance...\n",
      "   Traité 4,160,000 auteurs, trouvé 523,059 avec date de naissance...\n",
      "   Traité 4,170,000 auteurs, trouvé 524,544 avec date de naissance...\n",
      "   Traité 4,180,000 auteurs, trouvé 526,095 avec date de naissance...\n",
      "   Traité 4,190,000 auteurs, trouvé 526,770 avec date de naissance...\n",
      "   Traité 4,200,000 auteurs, trouvé 527,823 avec date de naissance...\n",
      "   Traité 4,210,000 auteurs, trouvé 529,080 avec date de naissance...\n",
      "   Traité 4,220,000 auteurs, trouvé 530,370 avec date de naissance...\n",
      "   Traité 4,230,000 auteurs, trouvé 532,379 avec date de naissance...\n",
      "   Traité 4,240,000 auteurs, trouvé 533,755 avec date de naissance...\n",
      "   Traité 4,250,000 auteurs, trouvé 534,476 avec date de naissance...\n",
      "   Traité 4,260,000 auteurs, trouvé 535,348 avec date de naissance...\n",
      "   Traité 4,270,000 auteurs, trouvé 537,204 avec date de naissance...\n",
      "   Traité 4,280,000 auteurs, trouvé 538,221 avec date de naissance...\n",
      "   Traité 4,290,000 auteurs, trouvé 540,058 avec date de naissance...\n",
      "   Traité 4,300,000 auteurs, trouvé 540,971 avec date de naissance...\n",
      "   Traité 4,310,000 auteurs, trouvé 541,862 avec date de naissance...\n",
      "   Traité 4,320,000 auteurs, trouvé 542,757 avec date de naissance...\n",
      "   Traité 4,330,000 auteurs, trouvé 544,433 avec date de naissance...\n",
      "   Traité 4,340,000 auteurs, trouvé 545,919 avec date de naissance...\n",
      "   Traité 4,350,000 auteurs, trouvé 547,523 avec date de naissance...\n",
      "   Traité 4,360,000 auteurs, trouvé 548,232 avec date de naissance...\n",
      "   Traité 4,370,000 auteurs, trouvé 549,220 avec date de naissance...\n",
      "   Traité 4,380,000 auteurs, trouvé 550,602 avec date de naissance...\n",
      "   Traité 4,390,000 auteurs, trouvé 551,851 avec date de naissance...\n",
      "   Traité 4,400,000 auteurs, trouvé 553,883 avec date de naissance...\n",
      "   Traité 4,410,000 auteurs, trouvé 555,150 avec date de naissance...\n",
      "   Traité 4,420,000 auteurs, trouvé 555,873 avec date de naissance...\n",
      "   Traité 4,430,000 auteurs, trouvé 556,732 avec date de naissance...\n",
      "   Traité 4,440,000 auteurs, trouvé 558,643 avec date de naissance...\n",
      "   Traité 4,450,000 auteurs, trouvé 559,690 avec date de naissance...\n",
      "   Traité 4,460,000 auteurs, trouvé 561,501 avec date de naissance...\n",
      "   Traité 4,470,000 auteurs, trouvé 562,412 avec date de naissance...\n",
      "   Traité 4,480,000 auteurs, trouvé 563,225 avec date de naissance...\n",
      "   Traité 4,490,000 auteurs, trouvé 564,235 avec date de naissance...\n",
      "   Traité 4,500,000 auteurs, trouvé 565,837 avec date de naissance...\n",
      "   Traité 4,510,000 auteurs, trouvé 567,303 avec date de naissance...\n",
      "   Traité 4,520,000 auteurs, trouvé 568,908 avec date de naissance...\n",
      "   Traité 4,530,000 auteurs, trouvé 569,604 avec date de naissance...\n",
      "   Traité 4,540,000 auteurs, trouvé 570,630 avec date de naissance...\n",
      "   Traité 4,550,000 auteurs, trouvé 571,985 avec date de naissance...\n",
      "   Traité 4,560,000 auteurs, trouvé 573,242 avec date de naissance...\n",
      "   Traité 4,570,000 auteurs, trouvé 575,186 avec date de naissance...\n",
      "   Traité 4,580,000 auteurs, trouvé 576,544 avec date de naissance...\n",
      "   Traité 4,590,000 auteurs, trouvé 577,181 avec date de naissance...\n",
      "   Traité 4,600,000 auteurs, trouvé 578,186 avec date de naissance...\n",
      "   Traité 4,610,000 auteurs, trouvé 580,062 avec date de naissance...\n",
      "   Traité 4,620,000 auteurs, trouvé 581,039 avec date de naissance...\n",
      "   Traité 4,630,000 auteurs, trouvé 582,886 avec date de naissance...\n",
      "   Traité 4,640,000 auteurs, trouvé 583,808 avec date de naissance...\n",
      "   Traité 4,650,000 auteurs, trouvé 584,648 avec date de naissance...\n",
      "   Traité 4,660,000 auteurs, trouvé 585,516 avec date de naissance...\n",
      "   Traité 4,670,000 auteurs, trouvé 587,264 avec date de naissance...\n",
      "   Traité 4,680,000 auteurs, trouvé 588,753 avec date de naissance...\n",
      "   Traité 4,690,000 auteurs, trouvé 590,211 avec date de naissance...\n",
      "   Traité 4,700,000 auteurs, trouvé 591,119 avec date de naissance...\n",
      "   Traité 4,710,000 auteurs, trouvé 591,993 avec date de naissance...\n",
      "   Traité 4,720,000 auteurs, trouvé 593,165 avec date de naissance...\n",
      "   Traité 4,730,000 auteurs, trouvé 594,619 avec date de naissance...\n",
      "   Traité 4,740,000 auteurs, trouvé 596,476 avec date de naissance...\n",
      "   Traité 4,750,000 auteurs, trouvé 597,941 avec date de naissance...\n",
      "   Traité 4,760,000 auteurs, trouvé 598,464 avec date de naissance...\n",
      "   Traité 4,770,000 auteurs, trouvé 599,513 avec date de naissance...\n",
      "   Traité 4,780,000 auteurs, trouvé 601,382 avec date de naissance...\n",
      "   Traité 4,790,000 auteurs, trouvé 602,373 avec date de naissance...\n",
      "   Traité 4,800,000 auteurs, trouvé 604,366 avec date de naissance...\n",
      "   Traité 4,810,000 auteurs, trouvé 605,351 avec date de naissance...\n",
      "   Traité 4,820,000 auteurs, trouvé 606,201 avec date de naissance...\n",
      "   Traité 4,830,000 auteurs, trouvé 607,068 avec date de naissance...\n",
      "   Traité 4,840,000 auteurs, trouvé 608,870 avec date de naissance...\n",
      "   Traité 4,850,000 auteurs, trouvé 610,254 avec date de naissance...\n",
      "   Traité 4,860,000 auteurs, trouvé 611,694 avec date de naissance...\n",
      "   Traité 4,870,000 auteurs, trouvé 612,571 avec date de naissance...\n",
      "   Traité 4,880,000 auteurs, trouvé 613,522 avec date de naissance...\n",
      "   Traité 4,890,000 auteurs, trouvé 614,761 avec date de naissance...\n",
      "   Traité 4,900,000 auteurs, trouvé 616,132 avec date de naissance...\n",
      "   Traité 4,910,000 auteurs, trouvé 618,051 avec date de naissance...\n",
      "   Traité 4,920,000 auteurs, trouvé 619,446 avec date de naissance...\n",
      "   Traité 4,930,000 auteurs, trouvé 620,066 avec date de naissance...\n",
      "   Traité 4,940,000 auteurs, trouvé 621,073 avec date de naissance...\n",
      "   Traité 4,950,000 auteurs, trouvé 622,937 avec date de naissance...\n",
      "   Traité 4,960,000 auteurs, trouvé 623,893 avec date de naissance...\n",
      "   Traité 4,970,000 auteurs, trouvé 625,772 avec date de naissance...\n",
      "   Traité 4,980,000 auteurs, trouvé 626,742 avec date de naissance...\n",
      "   Traité 4,990,000 auteurs, trouvé 627,599 avec date de naissance...\n",
      "   Traité 5,000,000 auteurs, trouvé 628,450 avec date de naissance...\n",
      "   Traité 5,010,000 auteurs, trouvé 630,115 avec date de naissance...\n",
      "   Traité 5,020,000 auteurs, trouvé 631,554 avec date de naissance...\n",
      "   Traité 5,030,000 auteurs, trouvé 633,033 avec date de naissance...\n",
      "   Traité 5,040,000 auteurs, trouvé 633,843 avec date de naissance...\n",
      "   Traité 5,050,000 auteurs, trouvé 634,799 avec date de naissance...\n",
      "   Traité 5,060,000 auteurs, trouvé 636,014 avec date de naissance...\n",
      "   Traité 5,070,000 auteurs, trouvé 637,403 avec date de naissance...\n",
      "   Traité 5,080,000 auteurs, trouvé 639,319 avec date de naissance...\n",
      "   Traité 5,090,000 auteurs, trouvé 640,713 avec date de naissance...\n",
      "   Traité 5,100,000 auteurs, trouvé 641,304 avec date de naissance...\n",
      "   Traité 5,110,000 auteurs, trouvé 642,327 avec date de naissance...\n",
      "   Traité 5,120,000 auteurs, trouvé 644,142 avec date de naissance...\n",
      "   Traité 5,130,000 auteurs, trouvé 645,124 avec date de naissance...\n",
      "   Traité 5,140,000 auteurs, trouvé 646,963 avec date de naissance...\n",
      "   Traité 5,150,000 auteurs, trouvé 647,921 avec date de naissance...\n",
      "   Traité 5,160,000 auteurs, trouvé 648,751 avec date de naissance...\n",
      "   Traité 5,170,000 auteurs, trouvé 649,720 avec date de naissance...\n",
      "   Traité 5,180,000 auteurs, trouvé 651,376 avec date de naissance...\n",
      "   Traité 5,190,000 auteurs, trouvé 652,848 avec date de naissance...\n",
      "   Traité 5,200,000 auteurs, trouvé 654,410 avec date de naissance...\n",
      "   Traité 5,210,000 auteurs, trouvé 655,143 avec date de naissance...\n",
      "   Traité 5,220,000 auteurs, trouvé 656,127 avec date de naissance...\n",
      "   Traité 5,230,000 auteurs, trouvé 657,516 avec date de naissance...\n",
      "   Traité 5,240,000 auteurs, trouvé 658,775 avec date de naissance...\n",
      "   Traité 5,250,000 auteurs, trouvé 660,813 avec date de naissance...\n",
      "   Traité 5,260,000 auteurs, trouvé 662,019 avec date de naissance...\n",
      "   Traité 5,270,000 auteurs, trouvé 662,802 avec date de naissance...\n",
      "   Traité 5,280,000 auteurs, trouvé 663,649 avec date de naissance...\n",
      "   Traité 5,290,000 auteurs, trouvé 665,508 avec date de naissance...\n",
      "   Traité 5,300,000 auteurs, trouvé 666,607 avec date de naissance...\n",
      "   Traité 5,310,000 auteurs, trouvé 668,301 avec date de naissance...\n",
      "   Traité 5,320,000 auteurs, trouvé 669,182 avec date de naissance...\n",
      "   Traité 5,330,000 auteurs, trouvé 670,005 avec date de naissance...\n",
      "   Traité 5,340,000 auteurs, trouvé 671,043 avec date de naissance...\n",
      "   Traité 5,350,000 auteurs, trouvé 672,540 avec date de naissance...\n",
      "   Traité 5,360,000 auteurs, trouvé 674,123 avec date de naissance...\n",
      "   Traité 5,370,000 auteurs, trouvé 675,737 avec date de naissance...\n",
      "   Traité 5,380,000 auteurs, trouvé 676,234 avec date de naissance...\n",
      "   Traité 5,390,000 auteurs, trouvé 677,201 avec date de naissance...\n",
      "   Traité 5,400,000 auteurs, trouvé 678,680 avec date de naissance...\n",
      "   Traité 5,410,000 auteurs, trouvé 679,861 avec date de naissance...\n",
      "   Traité 5,420,000 auteurs, trouvé 681,903 avec date de naissance...\n",
      "   Traité 5,430,000 auteurs, trouvé 682,921 avec date de naissance...\n",
      "   Traité 5,440,000 auteurs, trouvé 683,777 avec date de naissance...\n",
      "   Traité 5,450,000 auteurs, trouvé 684,532 avec date de naissance...\n",
      "   Traité 5,460,000 auteurs, trouvé 686,365 avec date de naissance...\n",
      "   Traité 5,470,000 auteurs, trouvé 687,612 avec date de naissance...\n",
      "   Traité 5,480,000 auteurs, trouvé 689,187 avec date de naissance...\n",
      "   Traité 5,490,000 auteurs, trouvé 690,111 avec date de naissance...\n",
      "   Traité 5,500,000 auteurs, trouvé 690,956 avec date de naissance...\n",
      "   Traité 5,510,000 auteurs, trouvé 692,046 avec date de naissance...\n",
      "   Traité 5,520,000 auteurs, trouvé 693,566 avec date de naissance...\n",
      "   Traité 5,530,000 auteurs, trouvé 695,382 avec date de naissance...\n",
      "   Traité 5,540,000 auteurs, trouvé 696,945 avec date de naissance...\n",
      "   Traité 5,550,000 auteurs, trouvé 697,409 avec date de naissance...\n",
      "   Traité 5,560,000 auteurs, trouvé 698,492 avec date de naissance...\n",
      "   Traité 5,570,000 auteurs, trouvé 700,172 avec date de naissance...\n",
      "   Traité 5,580,000 auteurs, trouvé 701,228 avec date de naissance...\n",
      "   Traité 5,590,000 auteurs, trouvé 703,209 avec date de naissance...\n",
      "   Traité 5,600,000 auteurs, trouvé 704,223 avec date de naissance...\n",
      "   Traité 5,610,000 auteurs, trouvé 705,060 avec date de naissance...\n",
      "   Traité 5,620,000 auteurs, trouvé 705,890 avec date de naissance...\n",
      "   Traité 5,630,000 auteurs, trouvé 707,699 avec date de naissance...\n",
      "   Traité 5,640,000 auteurs, trouvé 709,083 avec date de naissance...\n",
      "   Traité 5,650,000 auteurs, trouvé 710,563 avec date de naissance...\n",
      "   Traité 5,660,000 auteurs, trouvé 711,432 avec date de naissance...\n",
      "   Traité 5,670,000 auteurs, trouvé 712,361 avec date de naissance...\n",
      "   Traité 5,680,000 auteurs, trouvé 713,565 avec date de naissance...\n",
      "   Traité 5,690,000 auteurs, trouvé 714,929 avec date de naissance...\n",
      "   Traité 5,700,000 auteurs, trouvé 716,842 avec date de naissance...\n",
      "   Traité 5,710,000 auteurs, trouvé 718,261 avec date de naissance...\n",
      "   Traité 5,720,000 auteurs, trouvé 718,842 avec date de naissance...\n",
      "   Traité 5,730,000 auteurs, trouvé 719,824 avec date de naissance...\n",
      "   Traité 5,740,000 auteurs, trouvé 721,693 avec date de naissance...\n",
      "   Traité 5,750,000 auteurs, trouvé 722,663 avec date de naissance...\n",
      "   Traité 5,760,000 auteurs, trouvé 724,562 avec date de naissance...\n",
      "   Traité 5,770,000 auteurs, trouvé 725,546 avec date de naissance...\n",
      "   Traité 5,780,000 auteurs, trouvé 726,376 avec date de naissance...\n",
      "   Traité 5,790,000 auteurs, trouvé 727,264 avec date de naissance...\n",
      "   Traité 5,800,000 auteurs, trouvé 728,987 avec date de naissance...\n",
      "   Traité 5,810,000 auteurs, trouvé 730,413 avec date de naissance...\n",
      "   Traité 5,820,000 auteurs, trouvé 731,968 avec date de naissance...\n",
      "   Traité 5,830,000 auteurs, trouvé 732,701 avec date de naissance...\n",
      "   Traité 5,840,000 auteurs, trouvé 733,718 avec date de naissance...\n",
      "   Traité 5,850,000 auteurs, trouvé 734,922 avec date de naissance...\n",
      "   Traité 5,860,000 auteurs, trouvé 736,315 avec date de naissance...\n",
      "   Traité 5,870,000 auteurs, trouvé 738,249 avec date de naissance...\n",
      "   Traité 5,880,000 auteurs, trouvé 739,625 avec date de naissance...\n",
      "   Traité 5,890,000 auteurs, trouvé 740,271 avec date de naissance...\n",
      "   Traité 5,900,000 auteurs, trouvé 741,273 avec date de naissance...\n",
      "   Traité 5,910,000 auteurs, trouvé 743,179 avec date de naissance...\n",
      "   Traité 5,920,000 auteurs, trouvé 744,135 avec date de naissance...\n",
      "   Traité 5,930,000 auteurs, trouvé 745,994 avec date de naissance...\n",
      "   Traité 5,940,000 auteurs, trouvé 746,923 avec date de naissance...\n",
      "   Traité 5,950,000 auteurs, trouvé 747,813 avec date de naissance...\n",
      "   Traité 5,960,000 auteurs, trouvé 748,759 avec date de naissance...\n",
      "   Traité 5,970,000 auteurs, trouvé 750,493 avec date de naissance...\n",
      "   Traité 5,980,000 auteurs, trouvé 751,984 avec date de naissance...\n",
      "   Traité 5,990,000 auteurs, trouvé 753,430 avec date de naissance...\n",
      "   Traité 6,000,000 auteurs, trouvé 754,379 avec date de naissance...\n",
      "   Traité 6,010,000 auteurs, trouvé 755,249 avec date de naissance...\n",
      "   Traité 6,020,000 auteurs, trouvé 756,347 avec date de naissance...\n",
      "   Traité 6,030,000 auteurs, trouvé 757,773 avec date de naissance...\n",
      "   Traité 6,040,000 auteurs, trouvé 759,645 avec date de naissance...\n",
      "   Traité 6,050,000 auteurs, trouvé 761,103 avec date de naissance...\n",
      "   Traité 6,060,000 auteurs, trouvé 761,614 avec date de naissance...\n",
      "   Traité 6,070,000 auteurs, trouvé 762,706 avec date de naissance...\n",
      "   Traité 6,080,000 auteurs, trouvé 764,628 avec date de naissance...\n",
      "   Traité 6,090,000 auteurs, trouvé 765,606 avec date de naissance...\n",
      "   Traité 6,100,000 auteurs, trouvé 767,645 avec date de naissance...\n",
      "   Traité 6,110,000 auteurs, trouvé 768,598 avec date de naissance...\n",
      "   Traité 6,120,000 auteurs, trouvé 769,466 avec date de naissance...\n",
      "   Traité 6,130,000 auteurs, trouvé 770,290 avec date de naissance...\n",
      "   Traité 6,140,000 auteurs, trouvé 772,040 avec date de naissance...\n",
      "   Traité 6,150,000 auteurs, trouvé 773,486 avec date de naissance...\n",
      "   Traité 6,160,000 auteurs, trouvé 774,980 avec date de naissance...\n",
      "   Traité 6,170,000 auteurs, trouvé 775,865 avec date de naissance...\n",
      "   Traité 6,180,000 auteurs, trouvé 776,856 avec date de naissance...\n",
      "   Traité 6,190,000 auteurs, trouvé 778,148 avec date de naissance...\n",
      "   Traité 6,200,000 auteurs, trouvé 779,506 avec date de naissance...\n",
      "   Traité 6,210,000 auteurs, trouvé 781,382 avec date de naissance...\n",
      "   Traité 6,220,000 auteurs, trouvé 782,831 avec date de naissance...\n",
      "   Traité 6,230,000 auteurs, trouvé 783,402 avec date de naissance...\n",
      "   Traité 6,240,000 auteurs, trouvé 784,499 avec date de naissance...\n",
      "   Traité 6,250,000 auteurs, trouvé 786,376 avec date de naissance...\n",
      "   Traité 6,260,000 auteurs, trouvé 787,365 avec date de naissance...\n",
      "   Traité 6,270,000 auteurs, trouvé 789,327 avec date de naissance...\n",
      "   Traité 6,280,000 auteurs, trouvé 790,225 avec date de naissance...\n",
      "   Traité 6,290,000 auteurs, trouvé 791,081 avec date de naissance...\n",
      "   Traité 6,300,000 auteurs, trouvé 791,956 avec date de naissance...\n",
      "   Traité 6,310,000 auteurs, trouvé 793,678 avec date de naissance...\n",
      "   Traité 6,320,000 auteurs, trouvé 795,143 avec date de naissance...\n",
      "   Traité 6,330,000 auteurs, trouvé 796,559 avec date de naissance...\n",
      "   Traité 6,340,000 auteurs, trouvé 797,500 avec date de naissance...\n",
      "   Traité 6,350,000 auteurs, trouvé 798,423 avec date de naissance...\n",
      "   Traité 6,360,000 auteurs, trouvé 799,631 avec date de naissance...\n",
      "   Traité 6,370,000 auteurs, trouvé 801,024 avec date de naissance...\n",
      "   Traité 6,380,000 auteurs, trouvé 802,991 avec date de naissance...\n",
      "   Traité 6,390,000 auteurs, trouvé 804,476 avec date de naissance...\n",
      "   Traité 6,400,000 auteurs, trouvé 805,020 avec date de naissance...\n",
      "   Traité 6,410,000 auteurs, trouvé 806,003 avec date de naissance...\n",
      "   Traité 6,420,000 auteurs, trouvé 807,857 avec date de naissance...\n",
      "   Traité 6,430,000 auteurs, trouvé 808,788 avec date de naissance...\n",
      "   Traité 6,440,000 auteurs, trouvé 810,723 avec date de naissance...\n",
      "   Traité 6,450,000 auteurs, trouvé 811,713 avec date de naissance...\n",
      "   Traité 6,460,000 auteurs, trouvé 812,608 avec date de naissance...\n",
      "   Traité 6,470,000 auteurs, trouvé 813,530 avec date de naissance...\n",
      "   Traité 6,480,000 auteurs, trouvé 815,346 avec date de naissance...\n",
      "   Traité 6,490,000 auteurs, trouvé 816,814 avec date de naissance...\n",
      "   Traité 6,500,000 auteurs, trouvé 818,315 avec date de naissance...\n",
      "   Traité 6,510,000 auteurs, trouvé 819,208 avec date de naissance...\n",
      "   Traité 6,520,000 auteurs, trouvé 820,168 avec date de naissance...\n",
      "   Traité 6,530,000 auteurs, trouvé 821,438 avec date de naissance...\n",
      "   Traité 6,540,000 auteurs, trouvé 822,794 avec date de naissance...\n",
      "   Traité 6,550,000 auteurs, trouvé 824,706 avec date de naissance...\n",
      "   Traité 6,560,000 auteurs, trouvé 826,046 avec date de naissance...\n",
      "   Traité 6,570,000 auteurs, trouvé 826,598 avec date de naissance...\n",
      "   Traité 6,580,000 auteurs, trouvé 827,576 avec date de naissance...\n",
      "   Traité 6,590,000 auteurs, trouvé 829,345 avec date de naissance...\n",
      "   Traité 6,600,000 auteurs, trouvé 830,380 avec date de naissance...\n",
      "   Traité 6,610,000 auteurs, trouvé 832,189 avec date de naissance...\n",
      "   Traité 6,620,000 auteurs, trouvé 833,112 avec date de naissance...\n",
      "   Traité 6,630,000 auteurs, trouvé 834,025 avec date de naissance...\n",
      "   Traité 6,640,000 auteurs, trouvé 834,932 avec date de naissance...\n",
      "   Traité 6,650,000 auteurs, trouvé 836,616 avec date de naissance...\n",
      "   Traité 6,660,000 auteurs, trouvé 838,096 avec date de naissance...\n",
      "   Traité 6,670,000 auteurs, trouvé 839,619 avec date de naissance...\n",
      "   Traité 6,680,000 auteurs, trouvé 840,466 avec date de naissance...\n",
      "   Traité 6,690,000 auteurs, trouvé 841,437 avec date de naissance...\n",
      "   Traité 6,700,000 auteurs, trouvé 842,683 avec date de naissance...\n",
      "   Traité 6,710,000 auteurs, trouvé 844,032 avec date de naissance...\n",
      "   Traité 6,720,000 auteurs, trouvé 845,970 avec date de naissance...\n",
      "   Traité 6,730,000 auteurs, trouvé 847,333 avec date de naissance...\n",
      "   Traité 6,740,000 auteurs, trouvé 847,932 avec date de naissance...\n",
      "   Traité 6,750,000 auteurs, trouvé 848,940 avec date de naissance...\n",
      "   Traité 6,760,000 auteurs, trouvé 850,906 avec date de naissance...\n",
      "   Traité 6,770,000 auteurs, trouvé 851,787 avec date de naissance...\n",
      "   Traité 6,780,000 auteurs, trouvé 853,733 avec date de naissance...\n",
      "   Traité 6,790,000 auteurs, trouvé 854,671 avec date de naissance...\n",
      "   Traité 6,800,000 auteurs, trouvé 855,525 avec date de naissance...\n",
      "   Traité 6,810,000 auteurs, trouvé 856,418 avec date de naissance...\n",
      "   Traité 6,820,000 auteurs, trouvé 858,109 avec date de naissance...\n",
      "   Traité 6,830,000 auteurs, trouvé 859,602 avec date de naissance...\n",
      "   Traité 6,840,000 auteurs, trouvé 861,125 avec date de naissance...\n",
      "   Traité 6,850,000 auteurs, trouvé 861,940 avec date de naissance...\n",
      "   Traité 6,860,000 auteurs, trouvé 862,860 avec date de naissance...\n",
      "   Traité 6,870,000 auteurs, trouvé 864,049 avec date de naissance...\n",
      "   Traité 6,880,000 auteurs, trouvé 865,381 avec date de naissance...\n",
      "   Traité 6,890,000 auteurs, trouvé 867,272 avec date de naissance...\n",
      "   Traité 6,900,000 auteurs, trouvé 868,683 avec date de naissance...\n",
      "   Traité 6,910,000 auteurs, trouvé 869,305 avec date de naissance...\n",
      "   Traité 6,920,000 auteurs, trouvé 870,370 avec date de naissance...\n",
      "   Traité 6,930,000 auteurs, trouvé 872,307 avec date de naissance...\n",
      "   Traité 6,940,000 auteurs, trouvé 873,290 avec date de naissance...\n",
      "   Traité 6,950,000 auteurs, trouvé 875,285 avec date de naissance...\n",
      "   Traité 6,960,000 auteurs, trouvé 876,219 avec date de naissance...\n",
      "   Traité 6,970,000 auteurs, trouvé 877,080 avec date de naissance...\n",
      "   Traité 6,980,000 auteurs, trouvé 877,985 avec date de naissance...\n",
      "   Traité 6,990,000 auteurs, trouvé 879,712 avec date de naissance...\n",
      "   Traité 7,000,000 auteurs, trouvé 881,140 avec date de naissance...\n",
      "   Traité 7,010,000 auteurs, trouvé 882,620 avec date de naissance...\n",
      "   Traité 7,020,000 auteurs, trouvé 883,479 avec date de naissance...\n",
      "   Traité 7,030,000 auteurs, trouvé 884,411 avec date de naissance...\n",
      "   Traité 7,040,000 auteurs, trouvé 885,637 avec date de naissance...\n",
      "   Traité 7,050,000 auteurs, trouvé 886,967 avec date de naissance...\n",
      "   Traité 7,060,000 auteurs, trouvé 888,834 avec date de naissance...\n",
      "   Traité 7,070,000 auteurs, trouvé 890,163 avec date de naissance...\n",
      "   Traité 7,080,000 auteurs, trouvé 890,809 avec date de naissance...\n",
      "   Traité 7,090,000 auteurs, trouvé 891,795 avec date de naissance...\n",
      "   Traité 7,100,000 auteurs, trouvé 893,613 avec date de naissance...\n",
      "   Traité 7,110,000 auteurs, trouvé 894,576 avec date de naissance...\n",
      "   Traité 7,120,000 auteurs, trouvé 896,399 avec date de naissance...\n",
      "   Traité 7,130,000 auteurs, trouvé 897,337 avec date de naissance...\n",
      "   Traité 7,140,000 auteurs, trouvé 898,144 avec date de naissance...\n",
      "   Traité 7,150,000 auteurs, trouvé 899,070 avec date de naissance...\n",
      "   Traité 7,160,000 auteurs, trouvé 900,761 avec date de naissance...\n",
      "   Traité 7,170,000 auteurs, trouvé 902,278 avec date de naissance...\n",
      "   Traité 7,180,000 auteurs, trouvé 903,849 avec date de naissance...\n",
      "   Traité 7,190,000 auteurs, trouvé 904,582 avec date de naissance...\n",
      "   Traité 7,200,000 auteurs, trouvé 905,655 avec date de naissance...\n",
      "   Traité 7,210,000 auteurs, trouvé 906,937 avec date de naissance...\n",
      "   Traité 7,220,000 auteurs, trouvé 908,254 avec date de naissance...\n",
      "   Traité 7,230,000 auteurs, trouvé 910,295 avec date de naissance...\n",
      "   Traité 7,240,000 auteurs, trouvé 911,471 avec date de naissance...\n",
      "   Traité 7,250,000 auteurs, trouvé 912,275 avec date de naissance...\n",
      "   Traité 7,260,000 auteurs, trouvé 913,157 avec date de naissance...\n",
      "   Traité 7,270,000 auteurs, trouvé 915,012 avec date de naissance...\n",
      "   Traité 7,280,000 auteurs, trouvé 916,148 avec date de naissance...\n",
      "   Traité 7,290,000 auteurs, trouvé 917,817 avec date de naissance...\n",
      "   Traité 7,300,000 auteurs, trouvé 918,748 avec date de naissance...\n",
      "   Traité 7,310,000 auteurs, trouvé 919,615 avec date de naissance...\n",
      "   Traité 7,320,000 auteurs, trouvé 920,632 avec date de naissance...\n",
      "   Traité 7,330,000 auteurs, trouvé 922,205 avec date de naissance...\n",
      "   Traité 7,340,000 auteurs, trouvé 923,858 avec date de naissance...\n",
      "   Traité 7,350,000 auteurs, trouvé 925,485 avec date de naissance...\n",
      "   Traité 7,360,000 auteurs, trouvé 926,063 avec date de naissance...\n",
      "   Traité 7,370,000 auteurs, trouvé 927,062 avec date de naissance...\n",
      "   Traité 7,380,000 auteurs, trouvé 928,476 avec date de naissance...\n",
      "   Traité 7,390,000 auteurs, trouvé 929,648 avec date de naissance...\n",
      "   Traité 7,400,000 auteurs, trouvé 931,739 avec date de naissance...\n",
      "   Traité 7,410,000 auteurs, trouvé 932,937 avec date de naissance...\n",
      "   Traité 7,420,000 auteurs, trouvé 933,772 avec date de naissance...\n",
      "   Traité 7,430,000 auteurs, trouvé 934,559 avec date de naissance...\n",
      "   Traité 7,440,000 auteurs, trouvé 936,445 avec date de naissance...\n",
      "   Traité 7,450,000 auteurs, trouvé 937,666 avec date de naissance...\n",
      "   Traité 7,460,000 auteurs, trouvé 939,318 avec date de naissance...\n",
      "   Traité 7,470,000 auteurs, trouvé 940,251 avec date de naissance...\n",
      "   Traité 7,480,000 auteurs, trouvé 941,105 avec date de naissance...\n",
      "   Traité 7,490,000 auteurs, trouvé 942,177 avec date de naissance...\n",
      "   Traité 7,500,000 auteurs, trouvé 943,676 avec date de naissance...\n",
      "   Traité 7,510,000 auteurs, trouvé 945,301 avec date de naissance...\n",
      "   Traité 7,520,000 auteurs, trouvé 946,978 avec date de naissance...\n",
      "   Traité 7,530,000 auteurs, trouvé 947,512 avec date de naissance...\n",
      "   Traité 7,540,000 auteurs, trouvé 948,484 avec date de naissance...\n",
      "   Traité 7,550,000 auteurs, trouvé 950,024 avec date de naissance...\n",
      "   Traité 7,560,000 auteurs, trouvé 951,263 avec date de naissance...\n",
      "   Traité 7,570,000 auteurs, trouvé 953,285 avec date de naissance...\n",
      "   Traité 7,580,000 auteurs, trouvé 954,382 avec date de naissance...\n",
      "   Traité 7,590,000 auteurs, trouvé 955,275 avec date de naissance...\n",
      "   Traité 7,600,000 auteurs, trouvé 956,065 avec date de naissance...\n",
      "   Traité 7,610,000 auteurs, trouvé 958,010 avec date de naissance...\n",
      "   Traité 7,620,000 auteurs, trouvé 959,264 avec date de naissance...\n",
      "   Traité 7,630,000 auteurs, trouvé 960,861 avec date de naissance...\n",
      "   Traité 7,640,000 auteurs, trouvé 961,811 avec date de naissance...\n",
      "   Traité 7,650,000 auteurs, trouvé 962,609 avec date de naissance...\n",
      "   Traité 7,660,000 auteurs, trouvé 963,657 avec date de naissance...\n",
      "   Traité 7,670,000 auteurs, trouvé 965,192 avec date de naissance...\n",
      "   Traité 7,680,000 auteurs, trouvé 966,918 avec date de naissance...\n",
      "   Traité 7,690,000 auteurs, trouvé 968,422 avec date de naissance...\n",
      "   Traité 7,700,000 auteurs, trouvé 968,888 avec date de naissance...\n",
      "   Traité 7,710,000 auteurs, trouvé 969,992 avec date de naissance...\n",
      "   Traité 7,720,000 auteurs, trouvé 971,533 avec date de naissance...\n",
      "   Traité 7,730,000 auteurs, trouvé 972,665 avec date de naissance...\n",
      "   Traité 7,740,000 auteurs, trouvé 974,701 avec date de naissance...\n",
      "   Traité 7,750,000 auteurs, trouvé 975,808 avec date de naissance...\n",
      "   Traité 7,760,000 auteurs, trouvé 976,717 avec date de naissance...\n",
      "   Traité 7,770,000 auteurs, trouvé 977,516 avec date de naissance...\n",
      "   Traité 7,780,000 auteurs, trouvé 979,296 avec date de naissance...\n",
      "   Traité 7,790,000 auteurs, trouvé 980,576 avec date de naissance...\n",
      "   Traité 7,800,000 auteurs, trouvé 982,115 avec date de naissance...\n",
      "   Traité 7,810,000 auteurs, trouvé 982,988 avec date de naissance...\n",
      "   Traité 7,820,000 auteurs, trouvé 983,929 avec date de naissance...\n",
      "   Traité 7,830,000 auteurs, trouvé 985,033 avec date de naissance...\n",
      "   Traité 7,840,000 auteurs, trouvé 986,606 avec date de naissance...\n",
      "   Traité 7,850,000 auteurs, trouvé 988,298 avec date de naissance...\n",
      "   Traité 7,860,000 auteurs, trouvé 989,861 avec date de naissance...\n",
      "   Traité 7,870,000 auteurs, trouvé 990,366 avec date de naissance...\n",
      "   Traité 7,880,000 auteurs, trouvé 991,380 avec date de naissance...\n",
      "   Traité 7,890,000 auteurs, trouvé 992,958 avec date de naissance...\n",
      "   Traité 7,900,000 auteurs, trouvé 994,091 avec date de naissance...\n",
      "   Traité 7,910,000 auteurs, trouvé 996,132 avec date de naissance...\n",
      "   Traité 7,920,000 auteurs, trouvé 997,245 avec date de naissance...\n",
      "   Traité 7,930,000 auteurs, trouvé 998,138 avec date de naissance...\n",
      "   Traité 7,940,000 auteurs, trouvé 998,945 avec date de naissance...\n",
      "   Traité 7,950,000 auteurs, trouvé 1,000,772 avec date de naissance...\n",
      "   Traité 7,960,000 auteurs, trouvé 1,002,097 avec date de naissance...\n",
      "   Traité 7,970,000 auteurs, trouvé 1,003,628 avec date de naissance...\n",
      "   Traité 7,980,000 auteurs, trouvé 1,004,545 avec date de naissance...\n",
      "   Traité 7,990,000 auteurs, trouvé 1,005,392 avec date de naissance...\n",
      "   Traité 8,000,000 auteurs, trouvé 1,006,500 avec date de naissance...\n",
      "   Traité 8,010,000 auteurs, trouvé 1,008,034 avec date de naissance...\n",
      "   Traité 8,020,000 auteurs, trouvé 1,009,793 avec date de naissance...\n",
      "   Traité 8,030,000 auteurs, trouvé 1,011,368 avec date de naissance...\n",
      "   Traité 8,040,000 auteurs, trouvé 1,011,857 avec date de naissance...\n",
      "   Traité 8,050,000 auteurs, trouvé 1,012,934 avec date de naissance...\n",
      "   Traité 8,060,000 auteurs, trouvé 1,014,669 avec date de naissance...\n",
      "   Traité 8,070,000 auteurs, trouvé 1,015,698 avec date de naissance...\n",
      "   Traité 8,080,000 auteurs, trouvé 1,017,699 avec date de naissance...\n",
      "   Traité 8,090,000 auteurs, trouvé 1,018,733 avec date de naissance...\n",
      "   Traité 8,100,000 auteurs, trouvé 1,019,573 avec date de naissance...\n",
      "   Traité 8,110,000 auteurs, trouvé 1,020,402 avec date de naissance...\n",
      "   Traité 8,120,000 auteurs, trouvé 1,022,175 avec date de naissance...\n",
      "   Traité 8,130,000 auteurs, trouvé 1,023,514 avec date de naissance...\n",
      "   Traité 8,140,000 auteurs, trouvé 1,025,008 avec date de naissance...\n",
      "   Traité 8,150,000 auteurs, trouvé 1,025,930 avec date de naissance...\n",
      "   Traité 8,160,000 auteurs, trouvé 1,026,895 avec date de naissance...\n",
      "   Traité 8,170,000 auteurs, trouvé 1,028,068 avec date de naissance...\n",
      "   Traité 8,180,000 auteurs, trouvé 1,029,456 avec date de naissance...\n",
      "   Traité 8,190,000 auteurs, trouvé 1,031,401 avec date de naissance...\n",
      "   Traité 8,200,000 auteurs, trouvé 1,032,811 avec date de naissance...\n",
      "   Traité 8,210,000 auteurs, trouvé 1,033,430 avec date de naissance...\n",
      "   Traité 8,220,000 auteurs, trouvé 1,034,482 avec date de naissance...\n",
      "   Traité 8,230,000 auteurs, trouvé 1,036,376 avec date de naissance...\n",
      "   Traité 8,240,000 auteurs, trouvé 1,037,304 avec date de naissance...\n",
      "   Traité 8,250,000 auteurs, trouvé 1,039,185 avec date de naissance...\n",
      "   Traité 8,260,000 auteurs, trouvé 1,040,113 avec date de naissance...\n",
      "   Traité 8,270,000 auteurs, trouvé 1,041,000 avec date de naissance...\n",
      "   Traité 8,280,000 auteurs, trouvé 1,041,931 avec date de naissance...\n",
      "   Traité 8,290,000 auteurs, trouvé 1,043,623 avec date de naissance...\n",
      "   Traité 8,300,000 auteurs, trouvé 1,045,105 avec date de naissance...\n",
      "   Traité 8,310,000 auteurs, trouvé 1,046,644 avec date de naissance...\n",
      "   Traité 8,320,000 auteurs, trouvé 1,047,454 avec date de naissance...\n",
      "   Traité 8,330,000 auteurs, trouvé 1,048,453 avec date de naissance...\n",
      "   Traité 8,340,000 auteurs, trouvé 1,049,703 avec date de naissance...\n",
      "   Traité 8,350,000 auteurs, trouvé 1,051,022 avec date de naissance...\n",
      "   Traité 8,360,000 auteurs, trouvé 1,052,996 avec date de naissance...\n",
      "   Traité 8,370,000 auteurs, trouvé 1,054,282 avec date de naissance...\n",
      "   Traité 8,380,000 auteurs, trouvé 1,055,022 avec date de naissance...\n",
      "   Traité 8,390,000 auteurs, trouvé 1,055,925 avec date de naissance...\n",
      "   Traité 8,400,000 auteurs, trouvé 1,057,818 avec date de naissance...\n",
      "   Traité 8,410,000 auteurs, trouvé 1,058,846 avec date de naissance...\n",
      "   Traité 8,420,000 auteurs, trouvé 1,060,624 avec date de naissance...\n",
      "   Traité 8,430,000 auteurs, trouvé 1,061,597 avec date de naissance...\n",
      "   Traité 8,440,000 auteurs, trouvé 1,062,408 avec date de naissance...\n",
      "   Traité 8,450,000 auteurs, trouvé 1,063,394 avec date de naissance...\n",
      "   Traité 8,460,000 auteurs, trouvé 1,065,051 avec date de naissance...\n",
      "   Traité 8,470,000 auteurs, trouvé 1,066,558 avec date de naissance...\n",
      "   Traité 8,480,000 auteurs, trouvé 1,068,059 avec date de naissance...\n",
      "   Traité 8,490,000 auteurs, trouvé 1,068,787 avec date de naissance...\n",
      "   Traité 8,500,000 auteurs, trouvé 1,069,782 avec date de naissance...\n",
      "   Traité 8,510,000 auteurs, trouvé 1,071,080 avec date de naissance...\n",
      "   Traité 8,520,000 auteurs, trouvé 1,072,343 avec date de naissance...\n",
      "   Traité 8,530,000 auteurs, trouvé 1,074,281 avec date de naissance...\n",
      "   Traité 8,540,000 auteurs, trouvé 1,075,605 avec date de naissance...\n",
      "   Traité 8,550,000 auteurs, trouvé 1,076,366 avec date de naissance...\n",
      "   Traité 8,560,000 auteurs, trouvé 1,077,221 avec date de naissance...\n",
      "   Traité 8,570,000 auteurs, trouvé 1,079,064 avec date de naissance...\n",
      "   Traité 8,580,000 auteurs, trouvé 1,080,201 avec date de naissance...\n",
      "   Traité 8,590,000 auteurs, trouvé 1,081,938 avec date de naissance...\n",
      "   Traité 8,600,000 auteurs, trouvé 1,082,840 avec date de naissance...\n",
      "   Traité 8,610,000 auteurs, trouvé 1,083,704 avec date de naissance...\n",
      "   Traité 8,620,000 auteurs, trouvé 1,084,740 avec date de naissance...\n",
      "   Traité 8,630,000 auteurs, trouvé 1,086,350 avec date de naissance...\n",
      "   Traité 8,640,000 auteurs, trouvé 1,087,939 avec date de naissance...\n",
      "   Traité 8,650,000 auteurs, trouvé 1,089,567 avec date de naissance...\n",
      "   Traité 8,660,000 auteurs, trouvé 1,090,118 avec date de naissance...\n",
      "   Traité 8,670,000 auteurs, trouvé 1,091,136 avec date de naissance...\n",
      "   Traité 8,680,000 auteurs, trouvé 1,092,622 avec date de naissance...\n",
      "   Traité 8,690,000 auteurs, trouvé 1,093,833 avec date de naissance...\n",
      "   Traité 8,700,000 auteurs, trouvé 1,095,878 avec date de naissance...\n",
      "   Traité 8,710,000 auteurs, trouvé 1,097,077 avec date de naissance...\n",
      "   Traité 8,720,000 auteurs, trouvé 1,097,887 avec date de naissance...\n",
      "   Traité 8,730,000 auteurs, trouvé 1,098,709 avec date de naissance...\n",
      "   Traité 8,740,000 auteurs, trouvé 1,100,584 avec date de naissance...\n",
      "   Traité 8,750,000 auteurs, trouvé 1,101,686 avec date de naissance...\n",
      "   Traité 8,760,000 auteurs, trouvé 1,103,437 avec date de naissance...\n",
      "   Traité 8,770,000 auteurs, trouvé 1,104,367 avec date de naissance...\n",
      "   Traité 8,780,000 auteurs, trouvé 1,105,222 avec date de naissance...\n",
      "   Traité 8,790,000 auteurs, trouvé 1,106,271 avec date de naissance...\n",
      "   Traité 8,800,000 auteurs, trouvé 1,107,857 avec date de naissance...\n",
      "   Traité 8,810,000 auteurs, trouvé 1,109,454 avec date de naissance...\n",
      "   Traité 8,820,000 auteurs, trouvé 1,111,064 avec date de naissance...\n",
      "   Traité 8,830,000 auteurs, trouvé 1,111,600 avec date de naissance...\n",
      "   Traité 8,840,000 auteurs, trouvé 1,112,596 avec date de naissance...\n",
      "   Traité 8,850,000 auteurs, trouvé 1,114,138 avec date de naissance...\n",
      "   Traité 8,860,000 auteurs, trouvé 1,115,285 avec date de naissance...\n",
      "   Traité 8,870,000 auteurs, trouvé 1,117,311 avec date de naissance...\n",
      "   Traité 8,880,000 auteurs, trouvé 1,118,370 avec date de naissance...\n",
      "   Traité 8,890,000 auteurs, trouvé 1,119,269 avec date de naissance...\n",
      "   Traité 8,900,000 auteurs, trouvé 1,120,027 avec date de naissance...\n",
      "   Traité 8,910,000 auteurs, trouvé 1,121,944 avec date de naissance...\n",
      "   Traité 8,920,000 auteurs, trouvé 1,123,137 avec date de naissance...\n",
      "   Traité 8,930,000 auteurs, trouvé 1,124,780 avec date de naissance...\n",
      "   Traité 8,940,000 auteurs, trouvé 1,125,741 avec date de naissance...\n",
      "   Traité 8,950,000 auteurs, trouvé 1,126,592 avec date de naissance...\n",
      "   Traité 8,960,000 auteurs, trouvé 1,127,636 avec date de naissance...\n",
      "   Traité 8,970,000 auteurs, trouvé 1,129,229 avec date de naissance...\n",
      "   Traité 8,980,000 auteurs, trouvé 1,130,792 avec date de naissance...\n",
      "   Traité 8,990,000 auteurs, trouvé 1,132,419 avec date de naissance...\n",
      "   Traité 9,000,000 auteurs, trouvé 1,132,902 avec date de naissance...\n",
      "   Traité 9,010,000 auteurs, trouvé 1,133,904 avec date de naissance...\n",
      "   Traité 9,020,000 auteurs, trouvé 1,135,451 avec date de naissance...\n",
      "   Traité 9,030,000 auteurs, trouvé 1,136,685 avec date de naissance...\n",
      "   Traité 9,040,000 auteurs, trouvé 1,138,749 avec date de naissance...\n",
      "   Traité 9,050,000 auteurs, trouvé 1,139,873 avec date de naissance...\n",
      "   Traité 9,060,000 auteurs, trouvé 1,140,706 avec date de naissance...\n",
      "   Traité 9,070,000 auteurs, trouvé 1,141,511 avec date de naissance...\n",
      "   Traité 9,080,000 auteurs, trouvé 1,143,370 avec date de naissance...\n",
      "   Traité 9,090,000 auteurs, trouvé 1,144,661 avec date de naissance...\n",
      "   Traité 9,100,000 auteurs, trouvé 1,146,222 avec date de naissance...\n",
      "   Traité 9,110,000 auteurs, trouvé 1,147,168 avec date de naissance...\n",
      "   Traité 9,120,000 auteurs, trouvé 1,148,000 avec date de naissance...\n",
      "   Traité 9,130,000 auteurs, trouvé 1,149,094 avec date de naissance...\n",
      "   Traité 9,140,000 auteurs, trouvé 1,150,645 avec date de naissance...\n",
      "   Traité 9,150,000 auteurs, trouvé 1,152,357 avec date de naissance...\n",
      "   Traité 9,160,000 auteurs, trouvé 1,154,033 avec date de naissance...\n",
      "   Traité 9,170,000 auteurs, trouvé 1,154,539 avec date de naissance...\n",
      "   Traité 9,180,000 auteurs, trouvé 1,155,553 avec date de naissance...\n",
      "   Traité 9,190,000 auteurs, trouvé 1,157,230 avec date de naissance...\n",
      "   Traité 9,200,000 auteurs, trouvé 1,158,397 avec date de naissance...\n",
      "   Traité 9,210,000 auteurs, trouvé 1,160,429 avec date de naissance...\n",
      "   Traité 9,220,000 auteurs, trouvé 1,161,573 avec date de naissance...\n",
      "   Traité 9,230,000 auteurs, trouvé 1,162,457 avec date de naissance...\n",
      "   Traité 9,240,000 auteurs, trouvé 1,163,225 avec date de naissance...\n",
      "   Traité 9,250,000 auteurs, trouvé 1,165,118 avec date de naissance...\n",
      "   Traité 9,260,000 auteurs, trouvé 1,166,472 avec date de naissance...\n",
      "   Traité 9,270,000 auteurs, trouvé 1,168,031 avec date de naissance...\n",
      "   Traité 9,280,000 auteurs, trouvé 1,168,949 avec date de naissance...\n",
      "   Traité 9,290,000 auteurs, trouvé 1,169,812 avec date de naissance...\n",
      "   Traité 9,300,000 auteurs, trouvé 1,170,856 avec date de naissance...\n",
      "   Traité 9,310,000 auteurs, trouvé 1,172,403 avec date de naissance...\n",
      "   Traité 9,320,000 auteurs, trouvé 1,174,163 avec date de naissance...\n",
      "   Traité 9,330,000 auteurs, trouvé 1,175,734 avec date de naissance...\n",
      "   Traité 9,340,000 auteurs, trouvé 1,176,256 avec date de naissance...\n",
      "   Traité 9,350,000 auteurs, trouvé 1,177,297 avec date de naissance...\n",
      "   Traité 9,360,000 auteurs, trouvé 1,178,995 avec date de naissance...\n",
      "   Traité 9,370,000 auteurs, trouvé 1,180,103 avec date de naissance...\n",
      "   Traité 9,380,000 auteurs, trouvé 1,182,185 avec date de naissance...\n",
      "   Traité 9,390,000 auteurs, trouvé 1,183,132 avec date de naissance...\n",
      "   Traité 9,400,000 auteurs, trouvé 1,184,039 avec date de naissance...\n",
      "   Traité 9,410,000 auteurs, trouvé 1,184,832 avec date de naissance...\n",
      "   Traité 9,420,000 auteurs, trouvé 1,186,668 avec date de naissance...\n",
      "   Traité 9,430,000 auteurs, trouvé 1,187,987 avec date de naissance...\n",
      "   Traité 9,440,000 auteurs, trouvé 1,189,437 avec date de naissance...\n",
      "   Traité 9,450,000 auteurs, trouvé 1,190,340 avec date de naissance...\n",
      "   Traité 9,460,000 auteurs, trouvé 1,191,155 avec date de naissance...\n",
      "   Traité 9,470,000 auteurs, trouvé 1,192,337 avec date de naissance...\n",
      "   Traité 9,480,000 auteurs, trouvé 1,193,766 avec date de naissance...\n",
      "   Traité 9,490,000 auteurs, trouvé 1,195,595 avec date de naissance...\n",
      "   Traité 9,500,000 auteurs, trouvé 1,197,076 avec date de naissance...\n",
      "   Traité 9,510,000 auteurs, trouvé 1,197,638 avec date de naissance...\n",
      "   Traité 9,520,000 auteurs, trouvé 1,198,696 avec date de naissance...\n",
      "   Traité 9,530,000 auteurs, trouvé 1,200,527 avec date de naissance...\n",
      "   Traité 9,540,000 auteurs, trouvé 1,201,475 avec date de naissance...\n",
      "   Traité 9,550,000 auteurs, trouvé 1,203,385 avec date de naissance...\n",
      "   Traité 9,560,000 auteurs, trouvé 1,204,332 avec date de naissance...\n",
      "   Traité 9,570,000 auteurs, trouvé 1,205,168 avec date de naissance...\n",
      "   Traité 9,580,000 auteurs, trouvé 1,205,993 avec date de naissance...\n",
      "   Traité 9,590,000 auteurs, trouvé 1,207,705 avec date de naissance...\n",
      "   Traité 9,600,000 auteurs, trouvé 1,209,089 avec date de naissance...\n",
      "   Traité 9,610,000 auteurs, trouvé 1,210,547 avec date de naissance...\n",
      "   Traité 9,620,000 auteurs, trouvé 1,211,485 avec date de naissance...\n",
      "   Traité 9,630,000 auteurs, trouvé 1,212,354 avec date de naissance...\n",
      "   Traité 9,640,000 auteurs, trouvé 1,213,593 avec date de naissance...\n",
      "   Traité 9,650,000 auteurs, trouvé 1,215,032 avec date de naissance...\n",
      "   Traité 9,660,000 auteurs, trouvé 1,216,903 avec date de naissance...\n",
      "   Traité 9,670,000 auteurs, trouvé 1,218,333 avec date de naissance...\n",
      "   Traité 9,680,000 auteurs, trouvé 1,218,932 avec date de naissance...\n",
      "   Traité 9,690,000 auteurs, trouvé 1,220,008 avec date de naissance...\n",
      "   Traité 9,700,000 auteurs, trouvé 1,221,891 avec date de naissance...\n",
      "   Traité 9,710,000 auteurs, trouvé 1,222,856 avec date de naissance...\n",
      "   Traité 9,720,000 auteurs, trouvé 1,224,746 avec date de naissance...\n",
      "   Traité 9,730,000 auteurs, trouvé 1,225,632 avec date de naissance...\n",
      "   Traité 9,740,000 auteurs, trouvé 1,226,497 avec date de naissance...\n",
      "   Traité 9,750,000 auteurs, trouvé 1,227,470 avec date de naissance...\n",
      "   Traité 9,760,000 auteurs, trouvé 1,229,122 avec date de naissance...\n",
      "   Traité 9,770,000 auteurs, trouvé 1,230,538 avec date de naissance...\n",
      "   Traité 9,780,000 auteurs, trouvé 1,232,067 avec date de naissance...\n",
      "   Traité 9,790,000 auteurs, trouvé 1,232,816 avec date de naissance...\n",
      "   Traité 9,800,000 auteurs, trouvé 1,233,873 avec date de naissance...\n",
      "   Traité 9,810,000 auteurs, trouvé 1,235,113 avec date de naissance...\n",
      "   Traité 9,820,000 auteurs, trouvé 1,236,433 avec date de naissance...\n",
      "   Traité 9,830,000 auteurs, trouvé 1,238,474 avec date de naissance...\n",
      "   Traité 9,840,000 auteurs, trouvé 1,239,771 avec date de naissance...\n",
      "   Traité 9,850,000 auteurs, trouvé 1,240,528 avec date de naissance...\n",
      "   Traité 9,860,000 auteurs, trouvé 1,241,398 avec date de naissance...\n",
      "   Traité 9,870,000 auteurs, trouvé 1,243,302 avec date de naissance...\n",
      "   Traité 9,880,000 auteurs, trouvé 1,244,274 avec date de naissance...\n",
      "   Traité 9,890,000 auteurs, trouvé 1,246,007 avec date de naissance...\n",
      "   Traité 9,900,000 auteurs, trouvé 1,246,943 avec date de naissance...\n",
      "   Traité 9,910,000 auteurs, trouvé 1,247,779 avec date de naissance...\n",
      "   Traité 9,920,000 auteurs, trouvé 1,248,837 avec date de naissance...\n",
      "   Traité 9,930,000 auteurs, trouvé 1,250,463 avec date de naissance...\n",
      "   Traité 9,940,000 auteurs, trouvé 1,252,070 avec date de naissance...\n",
      "   Traité 9,950,000 auteurs, trouvé 1,253,684 avec date de naissance...\n",
      "   Traité 9,960,000 auteurs, trouvé 1,254,327 avec date de naissance...\n",
      "   Traité 9,970,000 auteurs, trouvé 1,255,344 avec date de naissance...\n",
      "   Traité 9,980,000 auteurs, trouvé 1,256,764 avec date de naissance...\n",
      "   Traité 9,990,000 auteurs, trouvé 1,257,970 avec date de naissance...\n",
      "   Traité 10,000,000 auteurs, trouvé 1,259,943 avec date de naissance...\n",
      "   Traité 10,010,000 auteurs, trouvé 1,261,195 avec date de naissance...\n",
      "   Traité 10,020,000 auteurs, trouvé 1,261,976 avec date de naissance...\n",
      "   Traité 10,030,000 auteurs, trouvé 1,262,825 avec date de naissance...\n",
      "   Traité 10,040,000 auteurs, trouvé 1,264,760 avec date de naissance...\n",
      "   Traité 10,050,000 auteurs, trouvé 1,265,847 avec date de naissance...\n",
      "   Traité 10,060,000 auteurs, trouvé 1,267,527 avec date de naissance...\n",
      "   Traité 10,070,000 auteurs, trouvé 1,268,421 avec date de naissance...\n",
      "   Traité 10,080,000 auteurs, trouvé 1,269,283 avec date de naissance...\n",
      "   Traité 10,090,000 auteurs, trouvé 1,270,271 avec date de naissance...\n",
      "   Traité 10,100,000 auteurs, trouvé 1,271,831 avec date de naissance...\n",
      "   Traité 10,110,000 auteurs, trouvé 1,273,556 avec date de naissance...\n",
      "   Traité 10,120,000 auteurs, trouvé 1,275,195 avec date de naissance...\n",
      "   Traité 10,130,000 auteurs, trouvé 1,275,703 avec date de naissance...\n",
      "   Traité 10,140,000 auteurs, trouvé 1,276,776 avec date de naissance...\n",
      "   Traité 10,150,000 auteurs, trouvé 1,278,391 avec date de naissance...\n",
      "   Traité 10,160,000 auteurs, trouvé 1,279,529 avec date de naissance...\n",
      "   Traité 10,170,000 auteurs, trouvé 1,281,605 avec date de naissance...\n",
      "   Traité 10,180,000 auteurs, trouvé 1,282,698 avec date de naissance...\n",
      "   Traité 10,190,000 auteurs, trouvé 1,283,556 avec date de naissance...\n",
      "   Traité 10,200,000 auteurs, trouvé 1,284,322 avec date de naissance...\n",
      "   Traité 10,210,000 auteurs, trouvé 1,286,189 avec date de naissance...\n",
      "   Traité 10,220,000 auteurs, trouvé 1,287,511 avec date de naissance...\n",
      "   Traité 10,230,000 auteurs, trouvé 1,289,140 avec date de naissance...\n",
      "   Traité 10,240,000 auteurs, trouvé 1,290,099 avec date de naissance...\n",
      "   Traité 10,250,000 auteurs, trouvé 1,290,943 avec date de naissance...\n",
      "   Traité 10,260,000 auteurs, trouvé 1,291,978 avec date de naissance...\n",
      "   Traité 10,270,000 auteurs, trouvé 1,293,605 avec date de naissance...\n",
      "   Traité 10,280,000 auteurs, trouvé 1,295,181 avec date de naissance...\n",
      "   Traité 10,290,000 auteurs, trouvé 1,296,812 avec date de naissance...\n",
      "   Traité 10,300,000 auteurs, trouvé 1,297,378 avec date de naissance...\n",
      "   Traité 10,310,000 auteurs, trouvé 1,298,403 avec date de naissance...\n",
      "   Traité 10,320,000 auteurs, trouvé 1,299,951 avec date de naissance...\n",
      "   Traité 10,330,000 auteurs, trouvé 1,301,146 avec date de naissance...\n",
      "   Traité 10,340,000 auteurs, trouvé 1,303,176 avec date de naissance...\n",
      "   Traité 10,350,000 auteurs, trouvé 1,304,235 avec date de naissance...\n",
      "   Traité 10,360,000 auteurs, trouvé 1,305,074 avec date de naissance...\n",
      "   Traité 10,370,000 auteurs, trouvé 1,305,859 avec date de naissance...\n",
      "   Traité 10,380,000 auteurs, trouvé 1,307,715 avec date de naissance...\n",
      "   Traité 10,390,000 auteurs, trouvé 1,308,982 avec date de naissance...\n",
      "   Traité 10,400,000 auteurs, trouvé 1,310,418 avec date de naissance...\n",
      "   Traité 10,410,000 auteurs, trouvé 1,311,333 avec date de naissance...\n",
      "   Traité 10,420,000 auteurs, trouvé 1,312,165 avec date de naissance...\n",
      "   Traité 10,430,000 auteurs, trouvé 1,313,262 avec date de naissance...\n",
      "   Traité 10,440,000 auteurs, trouvé 1,314,779 avec date de naissance...\n",
      "   Traité 10,450,000 auteurs, trouvé 1,316,528 avec date de naissance...\n",
      "   Traité 10,460,000 auteurs, trouvé 1,318,110 avec date de naissance...\n",
      "   Traité 10,470,000 auteurs, trouvé 1,318,608 avec date de naissance...\n",
      "   Traité 10,480,000 auteurs, trouvé 1,319,653 avec date de naissance...\n",
      "   Traité 10,490,000 auteurs, trouvé 1,321,260 avec date de naissance...\n",
      "   Traité 10,500,000 auteurs, trouvé 1,322,437 avec date de naissance...\n",
      "   Traité 10,510,000 auteurs, trouvé 1,324,513 avec date de naissance...\n",
      "   Traité 10,520,000 auteurs, trouvé 1,325,595 avec date de naissance...\n",
      "   Traité 10,530,000 auteurs, trouvé 1,326,442 avec date de naissance...\n",
      "   Traité 10,540,000 auteurs, trouvé 1,327,244 avec date de naissance...\n",
      "   Traité 10,550,000 auteurs, trouvé 1,329,133 avec date de naissance...\n",
      "   Traité 10,560,000 auteurs, trouvé 1,330,375 avec date de naissance...\n",
      "   Traité 10,570,000 auteurs, trouvé 1,331,992 avec date de naissance...\n",
      "   Traité 10,580,000 auteurs, trouvé 1,332,949 avec date de naissance...\n",
      "   Traité 10,590,000 auteurs, trouvé 1,333,831 avec date de naissance...\n",
      "   Traité 10,600,000 auteurs, trouvé 1,334,922 avec date de naissance...\n",
      "   Traité 10,610,000 auteurs, trouvé 1,336,454 avec date de naissance...\n",
      "   Traité 10,620,000 auteurs, trouvé 1,338,027 avec date de naissance...\n",
      "   Traité 10,630,000 auteurs, trouvé 1,339,635 avec date de naissance...\n",
      "   Traité 10,640,000 auteurs, trouvé 1,340,130 avec date de naissance...\n",
      "   Traité 10,650,000 auteurs, trouvé 1,341,198 avec date de naissance...\n",
      "   Traité 10,660,000 auteurs, trouvé 1,342,733 avec date de naissance...\n",
      "   Traité 10,670,000 auteurs, trouvé 1,343,898 avec date de naissance...\n",
      "   Traité 10,680,000 auteurs, trouvé 1,345,911 avec date de naissance...\n",
      "   Traité 10,690,000 auteurs, trouvé 1,347,009 avec date de naissance...\n",
      "   Traité 10,700,000 auteurs, trouvé 1,347,854 avec date de naissance...\n",
      "   Traité 10,710,000 auteurs, trouvé 1,348,588 avec date de naissance...\n",
      "   Traité 10,720,000 auteurs, trouvé 1,350,450 avec date de naissance...\n",
      "   Traité 10,730,000 auteurs, trouvé 1,351,664 avec date de naissance...\n",
      "   Traité 10,740,000 auteurs, trouvé 1,353,244 avec date de naissance...\n",
      "   Traité 10,750,000 auteurs, trouvé 1,354,183 avec date de naissance...\n",
      "   Traité 10,760,000 auteurs, trouvé 1,355,037 avec date de naissance...\n",
      "   Traité 10,770,000 auteurs, trouvé 1,356,137 avec date de naissance...\n",
      "   Traité 10,780,000 auteurs, trouvé 1,357,637 avec date de naissance...\n",
      "   Traité 10,790,000 auteurs, trouvé 1,359,381 avec date de naissance...\n",
      "   Traité 10,800,000 auteurs, trouvé 1,360,918 avec date de naissance...\n",
      "   Traité 10,810,000 auteurs, trouvé 1,361,371 avec date de naissance...\n",
      "   Traité 10,820,000 auteurs, trouvé 1,362,385 avec date de naissance...\n",
      "   Traité 10,830,000 auteurs, trouvé 1,364,042 avec date de naissance...\n",
      "   Traité 10,840,000 auteurs, trouvé 1,365,101 avec date de naissance...\n",
      "   Traité 10,850,000 auteurs, trouvé 1,367,088 avec date de naissance...\n",
      "   Traité 10,860,000 auteurs, trouvé 1,368,148 avec date de naissance...\n",
      "   Traité 10,870,000 auteurs, trouvé 1,369,015 avec date de naissance...\n",
      "   Traité 10,880,000 auteurs, trouvé 1,369,807 avec date de naissance...\n",
      "   Traité 10,890,000 auteurs, trouvé 1,371,633 avec date de naissance...\n",
      "   Traité 10,900,000 auteurs, trouvé 1,373,004 avec date de naissance...\n",
      "   Traité 10,910,000 auteurs, trouvé 1,374,484 avec date de naissance...\n",
      "   Traité 10,920,000 auteurs, trouvé 1,375,388 avec date de naissance...\n",
      "   Traité 10,930,000 auteurs, trouvé 1,376,185 avec date de naissance...\n",
      "   Traité 10,940,000 auteurs, trouvé 1,377,304 avec date de naissance...\n",
      "   Traité 10,950,000 auteurs, trouvé 1,378,789 avec date de naissance...\n",
      "   Traité 10,960,000 auteurs, trouvé 1,380,582 avec date de naissance...\n",
      "   Traité 10,970,000 auteurs, trouvé 1,382,113 avec date de naissance...\n",
      "   Traité 10,980,000 auteurs, trouvé 1,382,674 avec date de naissance...\n",
      "   Traité 10,990,000 auteurs, trouvé 1,383,727 avec date de naissance...\n",
      "   Traité 11,000,000 auteurs, trouvé 1,385,564 avec date de naissance...\n",
      "   Traité 11,010,000 auteurs, trouvé 1,386,539 avec date de naissance...\n",
      "   Traité 11,020,000 auteurs, trouvé 1,388,454 avec date de naissance...\n",
      "   Traité 11,030,000 auteurs, trouvé 1,389,406 avec date de naissance...\n",
      "   Traité 11,040,000 auteurs, trouvé 1,390,270 avec date de naissance...\n",
      "   Traité 11,050,000 auteurs, trouvé 1,391,131 avec date de naissance...\n",
      "   Traité 11,060,000 auteurs, trouvé 1,392,915 avec date de naissance...\n",
      "   Traité 11,070,000 auteurs, trouvé 1,394,375 avec date de naissance...\n",
      "   Traité 11,080,000 auteurs, trouvé 1,395,803 avec date de naissance...\n",
      "   Traité 11,090,000 auteurs, trouvé 1,396,698 avec date de naissance...\n",
      "   Traité 11,100,000 auteurs, trouvé 1,397,656 avec date de naissance...\n",
      "   Traité 11,110,000 auteurs, trouvé 1,398,866 avec date de naissance...\n",
      "   Traité 11,120,000 auteurs, trouvé 1,400,196 avec date de naissance...\n",
      "   Traité 11,130,000 auteurs, trouvé 1,402,061 avec date de naissance...\n",
      "   Traité 11,140,000 auteurs, trouvé 1,403,384 avec date de naissance...\n",
      "   Traité 11,150,000 auteurs, trouvé 1,403,930 avec date de naissance...\n",
      "   Traité 11,160,000 auteurs, trouvé 1,404,927 avec date de naissance...\n",
      "   Traité 11,170,000 auteurs, trouvé 1,406,824 avec date de naissance...\n",
      "   Traité 11,180,000 auteurs, trouvé 1,407,737 avec date de naissance...\n",
      "   Traité 11,190,000 auteurs, trouvé 1,409,610 avec date de naissance...\n",
      "   Traité 11,200,000 auteurs, trouvé 1,410,578 avec date de naissance...\n",
      "   Traité 11,210,000 auteurs, trouvé 1,411,519 avec date de naissance...\n",
      "   Traité 11,220,000 auteurs, trouvé 1,412,385 avec date de naissance...\n",
      "   Traité 11,230,000 auteurs, trouvé 1,414,156 avec date de naissance...\n",
      "   Traité 11,240,000 auteurs, trouvé 1,415,654 avec date de naissance...\n",
      "   Traité 11,250,000 auteurs, trouvé 1,417,231 avec date de naissance...\n",
      "   Traité 11,260,000 auteurs, trouvé 1,418,052 avec date de naissance...\n",
      "   Traité 11,270,000 auteurs, trouvé 1,419,049 avec date de naissance...\n",
      "   Traité 11,280,000 auteurs, trouvé 1,420,250 avec date de naissance...\n",
      "   Traité 11,290,000 auteurs, trouvé 1,421,577 avec date de naissance...\n",
      "   Traité 11,300,000 auteurs, trouvé 1,423,487 avec date de naissance...\n",
      "   Traité 11,310,000 auteurs, trouvé 1,424,885 avec date de naissance...\n",
      "   Traité 11,320,000 auteurs, trouvé 1,425,516 avec date de naissance...\n",
      "   Traité 11,330,000 auteurs, trouvé 1,426,517 avec date de naissance...\n",
      "   Traité 11,340,000 auteurs, trouvé 1,428,403 avec date de naissance...\n",
      "   Traité 11,350,000 auteurs, trouvé 1,429,417 avec date de naissance...\n",
      "   Traité 11,360,000 auteurs, trouvé 1,431,355 avec date de naissance...\n",
      "   Traité 11,370,000 auteurs, trouvé 1,432,265 avec date de naissance...\n",
      "   Traité 11,380,000 auteurs, trouvé 1,433,119 avec date de naissance...\n",
      "   Traité 11,390,000 auteurs, trouvé 1,434,053 avec date de naissance...\n",
      "   Traité 11,400,000 auteurs, trouvé 1,435,715 avec date de naissance...\n",
      "   Traité 11,410,000 auteurs, trouvé 1,437,201 avec date de naissance...\n",
      "   Traité 11,420,000 auteurs, trouvé 1,438,725 avec date de naissance...\n",
      "   Traité 11,430,000 auteurs, trouvé 1,439,469 avec date de naissance...\n",
      "   Traité 11,440,000 auteurs, trouvé 1,440,464 avec date de naissance...\n",
      "   Traité 11,450,000 auteurs, trouvé 1,441,747 avec date de naissance...\n",
      "   Traité 11,460,000 auteurs, trouvé 1,443,012 avec date de naissance...\n",
      "   Traité 11,470,000 auteurs, trouvé 1,444,986 avec date de naissance...\n",
      "   Traité 11,480,000 auteurs, trouvé 1,446,309 avec date de naissance...\n",
      "   Traité 11,490,000 auteurs, trouvé 1,446,983 avec date de naissance...\n",
      "   Traité 11,500,000 auteurs, trouvé 1,447,877 avec date de naissance...\n",
      "   Traité 11,510,000 auteurs, trouvé 1,449,767 avec date de naissance...\n",
      "   Traité 11,520,000 auteurs, trouvé 1,450,786 avec date de naissance...\n",
      "   Traité 11,530,000 auteurs, trouvé 1,452,573 avec date de naissance...\n",
      "   Traité 11,540,000 auteurs, trouvé 1,453,536 avec date de naissance...\n",
      "   Traité 11,550,000 auteurs, trouvé 1,454,362 avec date de naissance...\n",
      "   Traité 11,560,000 auteurs, trouvé 1,455,323 avec date de naissance...\n",
      "   Traité 11,570,000 auteurs, trouvé 1,456,991 avec date de naissance...\n",
      "   Traité 11,580,000 auteurs, trouvé 1,458,510 avec date de naissance...\n",
      "   Traité 11,590,000 auteurs, trouvé 1,460,060 avec date de naissance...\n",
      "   Traité 11,600,000 auteurs, trouvé 1,460,749 avec date de naissance...\n",
      "   Traité 11,610,000 auteurs, trouvé 1,461,754 avec date de naissance...\n",
      "   Traité 11,620,000 auteurs, trouvé 1,463,120 avec date de naissance...\n",
      "   Traité 11,630,000 auteurs, trouvé 1,464,339 avec date de naissance...\n",
      "   Traité 11,640,000 auteurs, trouvé 1,466,423 avec date de naissance...\n",
      "   Traité 11,650,000 auteurs, trouvé 1,467,645 avec date de naissance...\n",
      "   Traité 11,660,000 auteurs, trouvé 1,468,434 avec date de naissance...\n",
      "   Traité 11,670,000 auteurs, trouvé 1,469,294 avec date de naissance...\n",
      "   Traité 11,680,000 auteurs, trouvé 1,471,178 avec date de naissance...\n",
      "   Traité 11,690,000 auteurs, trouvé 1,472,243 avec date de naissance...\n",
      "   Traité 11,700,000 auteurs, trouvé 1,473,971 avec date de naissance...\n",
      "   Traité 11,710,000 auteurs, trouvé 1,474,945 avec date de naissance...\n",
      "   Traité 11,720,000 auteurs, trouvé 1,475,823 avec date de naissance...\n",
      "   Traité 11,730,000 auteurs, trouvé 1,476,797 avec date de naissance...\n",
      "   Traité 11,740,000 auteurs, trouvé 1,478,417 avec date de naissance...\n",
      "   Traité 11,750,000 auteurs, trouvé 1,479,936 avec date de naissance...\n",
      "   Traité 11,760,000 auteurs, trouvé 1,481,465 avec date de naissance...\n",
      "   Traité 11,770,000 auteurs, trouvé 1,482,151 avec date de naissance...\n",
      "   Traité 11,780,000 auteurs, trouvé 1,483,137 avec date de naissance...\n",
      "   Traité 11,790,000 auteurs, trouvé 1,484,551 avec date de naissance...\n",
      "   Traité 11,800,000 auteurs, trouvé 1,485,835 avec date de naissance...\n",
      "   Traité 11,810,000 auteurs, trouvé 1,487,946 avec date de naissance...\n",
      "   Traité 11,820,000 auteurs, trouvé 1,489,217 avec date de naissance...\n",
      "   Traité 11,830,000 auteurs, trouvé 1,489,954 avec date de naissance...\n",
      "   Traité 11,840,000 auteurs, trouvé 1,490,833 avec date de naissance...\n",
      "   Traité 11,850,000 auteurs, trouvé 1,492,680 avec date de naissance...\n",
      "   Traité 11,860,000 auteurs, trouvé 1,493,803 avec date de naissance...\n",
      "   Traité 11,870,000 auteurs, trouvé 1,495,520 avec date de naissance...\n",
      "   Traité 11,880,000 auteurs, trouvé 1,496,504 avec date de naissance...\n",
      "   Traité 11,890,000 auteurs, trouvé 1,497,385 avec date de naissance...\n",
      "   Traité 11,900,000 auteurs, trouvé 1,498,389 avec date de naissance...\n",
      "   Traité 11,910,000 auteurs, trouvé 1,499,905 avec date de naissance...\n",
      "   Traité 11,920,000 auteurs, trouvé 1,501,441 avec date de naissance...\n",
      "   Traité 11,930,000 auteurs, trouvé 1,503,004 avec date de naissance...\n",
      "   Traité 11,940,000 auteurs, trouvé 1,503,585 avec date de naissance...\n",
      "   Traité 11,950,000 auteurs, trouvé 1,504,583 avec date de naissance...\n",
      "   Traité 11,960,000 auteurs, trouvé 1,506,024 avec date de naissance...\n",
      "   Traité 11,970,000 auteurs, trouvé 1,507,277 avec date de naissance...\n",
      "   Traité 11,980,000 auteurs, trouvé 1,509,340 avec date de naissance...\n",
      "   Traité 11,990,000 auteurs, trouvé 1,510,524 avec date de naissance...\n",
      "   Traité 12,000,000 auteurs, trouvé 1,511,382 avec date de naissance...\n",
      "   Traité 12,010,000 auteurs, trouvé 1,512,244 avec date de naissance...\n",
      "   Traité 12,020,000 auteurs, trouvé 1,514,151 avec date de naissance...\n",
      "   Traité 12,030,000 auteurs, trouvé 1,515,282 avec date de naissance...\n",
      "   Traité 12,040,000 auteurs, trouvé 1,516,989 avec date de naissance...\n",
      "   Traité 12,050,000 auteurs, trouvé 1,517,888 avec date de naissance...\n",
      "   Traité 12,060,000 auteurs, trouvé 1,518,739 avec date de naissance...\n",
      "   Traité 12,070,000 auteurs, trouvé 1,519,811 avec date de naissance...\n",
      "   Traité 12,080,000 auteurs, trouvé 1,521,429 avec date de naissance...\n",
      "   Traité 12,090,000 auteurs, trouvé 1,523,091 avec date de naissance...\n",
      "   Traité 12,100,000 auteurs, trouvé 1,524,759 avec date de naissance...\n",
      "   Traité 12,110,000 auteurs, trouvé 1,525,272 avec date de naissance...\n",
      "   Traité 12,120,000 auteurs, trouvé 1,526,238 avec date de naissance...\n",
      "   Traité 12,130,000 auteurs, trouvé 1,527,836 avec date de naissance...\n",
      "   Traité 12,140,000 auteurs, trouvé 1,529,041 avec date de naissance...\n",
      "   Traité 12,150,000 auteurs, trouvé 1,531,010 avec date de naissance...\n",
      "   Traité 12,160,000 auteurs, trouvé 1,532,079 avec date de naissance...\n",
      "   Traité 12,170,000 auteurs, trouvé 1,532,964 avec date de naissance...\n",
      "   Traité 12,180,000 auteurs, trouvé 1,533,716 avec date de naissance...\n",
      "   Traité 12,190,000 auteurs, trouvé 1,535,565 avec date de naissance...\n",
      "   Traité 12,200,000 auteurs, trouvé 1,536,831 avec date de naissance...\n",
      "   Traité 12,210,000 auteurs, trouvé 1,538,349 avec date de naissance...\n",
      "   Traité 12,220,000 auteurs, trouvé 1,539,256 avec date de naissance...\n",
      "   Traité 12,230,000 auteurs, trouvé 1,540,125 avec date de naissance...\n",
      "   Traité 12,240,000 auteurs, trouvé 1,541,216 avec date de naissance...\n",
      "   Traité 12,250,000 auteurs, trouvé 1,542,785 avec date de naissance...\n",
      "   Traité 12,260,000 auteurs, trouvé 1,544,466 avec date de naissance...\n",
      "   Traité 12,270,000 auteurs, trouvé 1,546,066 avec date de naissance...\n",
      "   Traité 12,280,000 auteurs, trouvé 1,546,522 avec date de naissance...\n",
      "   Traité 12,290,000 auteurs, trouvé 1,547,580 avec date de naissance...\n",
      "   Traité 12,300,000 auteurs, trouvé 1,549,184 avec date de naissance...\n",
      "   Traité 12,310,000 auteurs, trouvé 1,550,360 avec date de naissance...\n",
      "   Traité 12,320,000 auteurs, trouvé 1,552,435 avec date de naissance...\n",
      "   Traité 12,330,000 auteurs, trouvé 1,553,545 avec date de naissance...\n",
      "   Traité 12,340,000 auteurs, trouvé 1,554,423 avec date de naissance...\n",
      "   Traité 12,350,000 auteurs, trouvé 1,555,179 avec date de naissance...\n",
      "   Traité 12,360,000 auteurs, trouvé 1,557,035 avec date de naissance...\n",
      "   Traité 12,370,000 auteurs, trouvé 1,558,303 avec date de naissance...\n",
      "   Traité 12,380,000 auteurs, trouvé 1,559,867 avec date de naissance...\n",
      "   Traité 12,390,000 auteurs, trouvé 1,560,851 avec date de naissance...\n",
      "   Traité 12,400,000 auteurs, trouvé 1,561,760 avec date de naissance...\n",
      "   Traité 12,410,000 auteurs, trouvé 1,562,862 avec date de naissance...\n",
      "   Traité 12,420,000 auteurs, trouvé 1,564,323 avec date de naissance...\n",
      "   Traité 12,430,000 auteurs, trouvé 1,566,154 avec date de naissance...\n",
      "   Traité 12,440,000 auteurs, trouvé 1,567,572 avec date de naissance...\n",
      "   Traité 12,450,000 auteurs, trouvé 1,568,107 avec date de naissance...\n",
      "   Traité 12,460,000 auteurs, trouvé 1,569,087 avec date de naissance...\n",
      "   Traité 12,470,000 auteurs, trouvé 1,570,917 avec date de naissance...\n",
      "   Traité 12,480,000 auteurs, trouvé 1,571,860 avec date de naissance...\n",
      "   Traité 12,490,000 auteurs, trouvé 1,573,846 avec date de naissance...\n",
      "   Traité 12,500,000 auteurs, trouvé 1,574,857 avec date de naissance...\n",
      "   Traité 12,510,000 auteurs, trouvé 1,575,684 avec date de naissance...\n",
      "   Traité 12,520,000 auteurs, trouvé 1,576,536 avec date de naissance...\n",
      "   Traité 12,530,000 auteurs, trouvé 1,578,352 avec date de naissance...\n",
      "   Traité 12,540,000 auteurs, trouvé 1,579,792 avec date de naissance...\n",
      "   Traité 12,550,000 auteurs, trouvé 1,581,268 avec date de naissance...\n",
      "   Traité 12,560,000 auteurs, trouvé 1,582,217 avec date de naissance...\n",
      "   Traité 12,570,000 auteurs, trouvé 1,583,130 avec date de naissance...\n",
      "   Traité 12,580,000 auteurs, trouvé 1,584,351 avec date de naissance...\n",
      "   Traité 12,590,000 auteurs, trouvé 1,585,665 avec date de naissance...\n",
      "   Traité 12,600,000 auteurs, trouvé 1,587,576 avec date de naissance...\n",
      "   Traité 12,610,000 auteurs, trouvé 1,589,011 avec date de naissance...\n",
      "   Traité 12,620,000 auteurs, trouvé 1,589,623 avec date de naissance...\n",
      "   Traité 12,630,000 auteurs, trouvé 1,590,631 avec date de naissance...\n",
      "   Traité 12,640,000 auteurs, trouvé 1,592,415 avec date de naissance...\n",
      "   Traité 12,650,000 auteurs, trouvé 1,593,428 avec date de naissance...\n",
      "   Traité 12,660,000 auteurs, trouvé 1,595,240 avec date de naissance...\n",
      "   Traité 12,670,000 auteurs, trouvé 1,596,226 avec date de naissance...\n",
      "   Traité 12,680,000 auteurs, trouvé 1,597,064 avec date de naissance...\n",
      "   Traité 12,690,000 auteurs, trouvé 1,598,053 avec date de naissance...\n",
      "   Traité 12,700,000 auteurs, trouvé 1,599,748 avec date de naissance...\n",
      "   Traité 12,710,000 auteurs, trouvé 1,601,245 avec date de naissance...\n",
      "   Traité 12,720,000 auteurs, trouvé 1,602,763 avec date de naissance...\n",
      "   Traité 12,730,000 auteurs, trouvé 1,603,563 avec date de naissance...\n",
      "   Traité 12,740,000 auteurs, trouvé 1,604,563 avec date de naissance...\n",
      "   Traité 12,750,000 auteurs, trouvé 1,605,800 avec date de naissance...\n",
      "   Traité 12,760,000 auteurs, trouvé 1,607,104 avec date de naissance...\n",
      "   Traité 12,770,000 auteurs, trouvé 1,609,019 avec date de naissance...\n",
      "   Traité 12,780,000 auteurs, trouvé 1,610,380 avec date de naissance...\n",
      "   Traité 12,790,000 auteurs, trouvé 1,611,107 avec date de naissance...\n",
      "   Traité 12,800,000 auteurs, trouvé 1,611,993 avec date de naissance...\n",
      "   Traité 12,810,000 auteurs, trouvé 1,613,828 avec date de naissance...\n",
      "   Traité 12,820,000 auteurs, trouvé 1,614,902 avec date de naissance...\n",
      "   Traité 12,830,000 auteurs, trouvé 1,616,714 avec date de naissance...\n",
      "   Traité 12,840,000 auteurs, trouvé 1,617,672 avec date de naissance...\n",
      "   Traité 12,850,000 auteurs, trouvé 1,618,525 avec date de naissance...\n",
      "   Traité 12,860,000 auteurs, trouvé 1,619,487 avec date de naissance...\n",
      "   Traité 12,870,000 auteurs, trouvé 1,621,127 avec date de naissance...\n",
      "   Traité 12,880,000 auteurs, trouvé 1,622,634 avec date de naissance...\n",
      "   Traité 12,890,000 auteurs, trouvé 1,624,204 avec date de naissance...\n",
      "   Traité 12,900,000 auteurs, trouvé 1,624,924 avec date de naissance...\n",
      "   Traité 12,910,000 auteurs, trouvé 1,625,934 avec date de naissance...\n",
      "   Traité 12,920,000 auteurs, trouvé 1,627,314 avec date de naissance...\n",
      "   Traité 12,930,000 auteurs, trouvé 1,628,488 avec date de naissance...\n",
      "   Traité 12,940,000 auteurs, trouvé 1,630,475 avec date de naissance...\n",
      "   Traité 12,950,000 auteurs, trouvé 1,631,770 avec date de naissance...\n",
      "   Traité 12,960,000 auteurs, trouvé 1,632,511 avec date de naissance...\n",
      "   Traité 12,970,000 auteurs, trouvé 1,633,417 avec date de naissance...\n",
      "   Traité 12,980,000 auteurs, trouvé 1,635,249 avec date de naissance...\n",
      "   Traité 12,990,000 auteurs, trouvé 1,636,290 avec date de naissance...\n",
      "   Traité 13,000,000 auteurs, trouvé 1,638,100 avec date de naissance...\n",
      "   Traité 13,010,000 auteurs, trouvé 1,639,069 avec date de naissance...\n",
      "   Traité 13,020,000 auteurs, trouvé 1,639,906 avec date de naissance...\n",
      "   Traité 13,030,000 auteurs, trouvé 1,640,800 avec date de naissance...\n",
      "   Traité 13,040,000 auteurs, trouvé 1,642,412 avec date de naissance...\n",
      "   Traité 13,050,000 auteurs, trouvé 1,643,880 avec date de naissance...\n",
      "   Traité 13,060,000 auteurs, trouvé 1,645,424 avec date de naissance...\n",
      "   Traité 13,070,000 auteurs, trouvé 1,646,200 avec date de naissance...\n",
      "   Traité 13,080,000 auteurs, trouvé 1,647,291 avec date de naissance...\n",
      "   Traité 13,090,000 auteurs, trouvé 1,648,566 avec date de naissance...\n",
      "   Traité 13,100,000 auteurs, trouvé 1,649,884 avec date de naissance...\n",
      "   Traité 13,110,000 auteurs, trouvé 1,651,817 avec date de naissance...\n",
      "   Traité 13,120,000 auteurs, trouvé 1,653,173 avec date de naissance...\n",
      "   Traité 13,130,000 auteurs, trouvé 1,653,892 avec date de naissance...\n",
      "   Traité 13,140,000 auteurs, trouvé 1,654,814 avec date de naissance...\n",
      "   Traité 13,150,000 auteurs, trouvé 1,656,732 avec date de naissance...\n",
      "   Traité 13,160,000 auteurs, trouvé 1,657,777 avec date de naissance...\n",
      "   Traité 13,170,000 auteurs, trouvé 1,659,559 avec date de naissance...\n",
      "   Traité 13,180,000 auteurs, trouvé 1,660,489 avec date de naissance...\n",
      "   Traité 13,190,000 auteurs, trouvé 1,661,403 avec date de naissance...\n",
      "   Traité 13,200,000 auteurs, trouvé 1,662,341 avec date de naissance...\n",
      "   Traité 13,210,000 auteurs, trouvé 1,664,041 avec date de naissance...\n",
      "   Traité 13,220,000 auteurs, trouvé 1,665,473 avec date de naissance...\n",
      "   Traité 13,230,000 auteurs, trouvé 1,667,030 avec date de naissance...\n",
      "   Traité 13,240,000 auteurs, trouvé 1,667,748 avec date de naissance...\n",
      "   Traité 13,250,000 auteurs, trouvé 1,668,684 avec date de naissance...\n",
      "   Traité 13,260,000 auteurs, trouvé 1,669,962 avec date de naissance...\n",
      "   Traité 13,270,000 auteurs, trouvé 1,671,264 avec date de naissance...\n",
      "   Traité 13,280,000 auteurs, trouvé 1,673,254 avec date de naissance...\n",
      "   Traité 13,290,000 auteurs, trouvé 1,674,593 avec date de naissance...\n",
      "   Traité 13,300,000 auteurs, trouvé 1,675,260 avec date de naissance...\n",
      "   Traité 13,310,000 auteurs, trouvé 1,676,240 avec date de naissance...\n",
      "   Traité 13,320,000 auteurs, trouvé 1,678,091 avec date de naissance...\n",
      "   Traité 13,330,000 auteurs, trouvé 1,679,119 avec date de naissance...\n",
      "   Traité 13,340,000 auteurs, trouvé 1,680,942 avec date de naissance...\n",
      "   Traité 13,350,000 auteurs, trouvé 1,681,910 avec date de naissance...\n",
      "   Traité 13,360,000 auteurs, trouvé 1,682,723 avec date de naissance...\n",
      "   Traité 13,370,000 auteurs, trouvé 1,683,633 avec date de naissance...\n",
      "   Traité 13,380,000 auteurs, trouvé 1,685,198 avec date de naissance...\n",
      "   Traité 13,390,000 auteurs, trouvé 1,686,687 avec date de naissance...\n",
      "   Traité 13,400,000 auteurs, trouvé 1,688,272 avec date de naissance...\n",
      "   Traité 13,410,000 auteurs, trouvé 1,688,932 avec date de naissance...\n",
      "   Traité 13,420,000 auteurs, trouvé 1,689,906 avec date de naissance...\n",
      "   Traité 13,430,000 auteurs, trouvé 1,691,175 avec date de naissance...\n",
      "   Traité 13,440,000 auteurs, trouvé 1,692,382 avec date de naissance...\n",
      "   Traité 13,450,000 auteurs, trouvé 1,694,408 avec date de naissance...\n",
      "   Traité 13,460,000 auteurs, trouvé 1,695,623 avec date de naissance...\n",
      "   Traité 13,470,000 auteurs, trouvé 1,696,388 avec date de naissance...\n",
      "   Traité 13,480,000 auteurs, trouvé 1,697,296 avec date de naissance...\n",
      "   Traité 13,490,000 auteurs, trouvé 1,699,160 avec date de naissance...\n",
      "   Traité 13,500,000 auteurs, trouvé 1,700,233 avec date de naissance...\n",
      "   Traité 13,510,000 auteurs, trouvé 1,701,899 avec date de naissance...\n",
      "   Traité 13,520,000 auteurs, trouvé 1,702,876 avec date de naissance...\n",
      "   Traité 13,530,000 auteurs, trouvé 1,703,712 avec date de naissance...\n",
      "   Traité 13,540,000 auteurs, trouvé 1,704,781 avec date de naissance...\n",
      "   Traité 13,550,000 auteurs, trouvé 1,706,309 avec date de naissance...\n",
      "   Traité 13,560,000 auteurs, trouvé 1,707,857 avec date de naissance...\n",
      "   Traité 13,570,000 auteurs, trouvé 1,709,424 avec date de naissance...\n",
      "   Traité 13,580,000 auteurs, trouvé 1,710,031 avec date de naissance...\n",
      "   Traité 13,590,000 auteurs, trouvé 1,711,043 avec date de naissance...\n",
      "   Traité 13,600,000 auteurs, trouvé 1,712,411 avec date de naissance...\n",
      "   Traité 13,610,000 auteurs, trouvé 1,713,664 avec date de naissance...\n",
      "   Traité 13,620,000 auteurs, trouvé 1,715,700 avec date de naissance...\n",
      "   Traité 13,630,000 auteurs, trouvé 1,716,930 avec date de naissance...\n",
      "   Traité 13,640,000 auteurs, trouvé 1,717,731 avec date de naissance...\n",
      "   Traité 13,650,000 auteurs, trouvé 1,718,569 avec date de naissance...\n",
      "   Traité 13,660,000 auteurs, trouvé 1,720,461 avec date de naissance...\n",
      "   Traité 13,670,000 auteurs, trouvé 1,721,594 avec date de naissance...\n",
      "   Traité 13,680,000 auteurs, trouvé 1,723,277 avec date de naissance...\n",
      "   Traité 13,690,000 auteurs, trouvé 1,724,202 avec date de naissance...\n",
      "   Traité 13,700,000 auteurs, trouvé 1,725,054 avec date de naissance...\n",
      "   Traité 13,710,000 auteurs, trouvé 1,726,079 avec date de naissance...\n",
      "   Traité 13,720,000 auteurs, trouvé 1,727,566 avec date de naissance...\n",
      "   Traité 13,730,000 auteurs, trouvé 1,729,219 avec date de naissance...\n",
      "   Traité 13,740,000 auteurs, trouvé 1,730,779 avec date de naissance...\n",
      "   Traité 13,750,000 auteurs, trouvé 1,731,325 avec date de naissance...\n",
      "   Traité 13,760,000 auteurs, trouvé 1,732,239 avec date de naissance...\n",
      "   Traité 13,770,000 auteurs, trouvé 1,733,799 avec date de naissance...\n",
      "   Traité 13,780,000 auteurs, trouvé 1,734,990 avec date de naissance...\n",
      "   Traité 13,790,000 auteurs, trouvé 1,737,028 avec date de naissance...\n",
      "   Traité 13,800,000 auteurs, trouvé 1,738,185 avec date de naissance...\n",
      "   Traité 13,810,000 auteurs, trouvé 1,739,069 avec date de naissance...\n",
      "   Traité 13,820,000 auteurs, trouvé 1,739,818 avec date de naissance...\n",
      "   Traité 13,830,000 auteurs, trouvé 1,741,735 avec date de naissance...\n",
      "   Traité 13,840,000 auteurs, trouvé 1,742,957 avec date de naissance...\n",
      "   Traité 13,850,000 auteurs, trouvé 1,744,574 avec date de naissance...\n",
      "   Traité 13,860,000 auteurs, trouvé 1,745,553 avec date de naissance...\n",
      "   Traité 13,870,000 auteurs, trouvé 1,746,421 avec date de naissance...\n",
      "   Traité 13,880,000 auteurs, trouvé 1,747,501 avec date de naissance...\n",
      "   Traité 13,890,000 auteurs, trouvé 1,749,038 avec date de naissance...\n",
      "   Traité 13,900,000 auteurs, trouvé 1,750,728 avec date de naissance...\n",
      "   Traité 13,910,000 auteurs, trouvé 1,752,296 avec date de naissance...\n",
      "   Traité 13,920,000 auteurs, trouvé 1,752,721 avec date de naissance...\n",
      "   Traité 13,930,000 auteurs, trouvé 1,753,792 avec date de naissance...\n",
      "   Traité 13,940,000 auteurs, trouvé 1,755,460 avec date de naissance...\n",
      "   Traité 13,950,000 auteurs, trouvé 1,756,579 avec date de naissance...\n",
      "   Traité 13,960,000 auteurs, trouvé 1,758,521 avec date de naissance...\n",
      "   Traité 13,970,000 auteurs, trouvé 1,759,611 avec date de naissance...\n",
      "   Traité 13,980,000 auteurs, trouvé 1,760,473 avec date de naissance...\n",
      "   Traité 13,990,000 auteurs, trouvé 1,761,269 avec date de naissance...\n",
      "   Traité 14,000,000 auteurs, trouvé 1,763,049 avec date de naissance...\n",
      "   Traité 14,010,000 auteurs, trouvé 1,764,416 avec date de naissance...\n",
      "   Traité 14,020,000 auteurs, trouvé 1,765,874 avec date de naissance...\n",
      "   Traité 14,030,000 auteurs, trouvé 1,766,785 avec date de naissance...\n",
      "   Traité 14,040,000 auteurs, trouvé 1,767,630 avec date de naissance...\n",
      "   Traité 14,050,000 auteurs, trouvé 1,768,784 avec date de naissance...\n",
      "   Traité 14,060,000 auteurs, trouvé 1,770,169 avec date de naissance...\n",
      "   Traité 14,070,000 auteurs, trouvé 1,771,922 avec date de naissance...\n",
      "   Traité 14,080,000 auteurs, trouvé 1,773,384 avec date de naissance...\n",
      "   Traité 14,090,000 auteurs, trouvé 1,773,866 avec date de naissance...\n",
      "   Traité 14,100,000 auteurs, trouvé 1,774,951 avec date de naissance...\n",
      "   Traité 14,110,000 auteurs, trouvé 1,776,696 avec date de naissance...\n",
      "   Traité 14,120,000 auteurs, trouvé 1,777,718 avec date de naissance...\n",
      "   Traité 14,130,000 auteurs, trouvé 1,779,769 avec date de naissance...\n",
      "   Traité 14,140,000 auteurs, trouvé 1,780,823 avec date de naissance...\n",
      "   Traité 14,150,000 auteurs, trouvé 1,781,704 avec date de naissance...\n",
      "   Traité 14,160,000 auteurs, trouvé 1,782,454 avec date de naissance...\n",
      "   Traité 14,170,000 auteurs, trouvé 1,784,233 avec date de naissance...\n",
      "   Traité 14,180,000 auteurs, trouvé 1,785,560 avec date de naissance...\n",
      "   Traité 14,190,000 auteurs, trouvé 1,787,051 avec date de naissance...\n",
      "   Traité 14,200,000 auteurs, trouvé 1,788,000 avec date de naissance...\n",
      "   Traité 14,210,000 auteurs, trouvé 1,788,844 avec date de naissance...\n",
      "   Traité 14,220,000 auteurs, trouvé 1,790,007 avec date de naissance...\n",
      "   Traité 14,230,000 auteurs, trouvé 1,791,488 avec date de naissance...\n",
      "   Traité 14,240,000 auteurs, trouvé 1,793,286 avec date de naissance...\n",
      "   Traité 14,250,000 auteurs, trouvé 1,794,752 avec date de naissance...\n",
      "   Traité 14,260,000 auteurs, trouvé 1,795,306 avec date de naissance...\n",
      "   Traité 14,270,000 auteurs, trouvé 1,796,376 avec date de naissance...\n",
      "   Traité 14,280,000 auteurs, trouvé 1,798,208 avec date de naissance...\n",
      "   Traité 14,290,000 auteurs, trouvé 1,799,106 avec date de naissance...\n",
      "   Traité 14,300,000 auteurs, trouvé 1,801,055 avec date de naissance...\n",
      "   Traité 14,310,000 auteurs, trouvé 1,802,041 avec date de naissance...\n",
      "   Traité 14,320,000 auteurs, trouvé 1,802,880 avec date de naissance...\n",
      "   Traité 14,330,000 auteurs, trouvé 1,803,727 avec date de naissance...\n",
      "   Traité 14,340,000 auteurs, trouvé 1,805,580 avec date de naissance...\n",
      "   Traité 14,350,000 auteurs, trouvé 1,806,983 avec date de naissance...\n",
      "   Traité 14,360,000 auteurs, trouvé 1,808,461 avec date de naissance...\n",
      "   Traité 14,370,000 auteurs, trouvé 1,809,308 avec date de naissance...\n",
      "   Traité 14,380,000 auteurs, trouvé 1,810,271 avec date de naissance...\n",
      "   Traité 14,390,000 auteurs, trouvé 1,811,435 avec date de naissance...\n",
      "   Traité 14,400,000 auteurs, trouvé 1,812,790 avec date de naissance...\n",
      "   Traité 14,410,000 auteurs, trouvé 1,814,699 avec date de naissance...\n",
      "   Traité 14,420,000 auteurs, trouvé 1,816,067 avec date de naissance...\n",
      "   Traité 14,430,000 auteurs, trouvé 1,816,660 avec date de naissance...\n",
      "   Traité 14,440,000 auteurs, trouvé 1,817,652 avec date de naissance...\n",
      "   Traité 14,450,000 auteurs, trouvé 1,819,556 avec date de naissance...\n",
      "   Traité 14,460,000 auteurs, trouvé 1,820,543 avec date de naissance...\n",
      "   Traité 14,470,000 auteurs, trouvé 1,822,416 avec date de naissance...\n",
      "✅ Extraction terminée : 1,823,288 auteurs avec date de naissance trouvés sur 14,478,559 auteurs traités\n",
      "📊 Création du DataFrame avec 1,823,288 auteurs...\n",
      "\n",
      "📈 STATISTIQUES DU DATAFRAME :\n",
      "   📏 Dimensions : 1,823,288 lignes × 17 colonnes\n",
      "   🎂 Années de naissance : 1000.0 - 2022.0\n",
      "\n",
      "🏛️ RÉPARTITION PAR SIÈCLE :\n",
      "   • 15ème siècle (1401-1500) : 4,847 auteurs\n",
      "   • 16ème siècle (1501-1600) : 15,138 auteurs\n",
      "   • 17ème siècle (1601-1700) : 24,602 auteurs\n",
      "   • 18ème siècle (1701-1800) : 70,825 auteurs\n",
      "   • 19ème siècle (1801-1900) : 456,204 auteurs\n",
      "   • 20ème siècle (1901-2000) : 1,229,893 auteurs\n",
      "   • 21ème siècle (2001-2100) : 207 auteurs\n",
      "\n",
      "📋 TAUX DE REMPLISSAGE DES CHAMPS :\n",
      "   • death_date           : 469,574 ( 25.8%)\n",
      "   • bio                  : 29,067 (  1.6%)\n",
      "   • wikipedia            :      0 (  0.0%)\n",
      "   • wikidata             : 162,363 (  8.9%)\n",
      "   • alternate_names      : 54,182 (  3.0%)\n",
      "   • photos               : 28,015 (  1.5%)\n",
      "   • website              :      4 (  0.0%)\n",
      "\n",
      "👥 STATUT VITAL :\n",
      "   🟢 Probablement vivants : 1,102,083\n",
      "   🔴 Probablement décédés : 678,004\n",
      "   ❓ Statut inconnu       : 43,201\n",
      "\n",
      "📋 APERÇU DU DATAFRAME (premiers 10 auteurs) :\n",
      "================================================================================\n",
      "              name  birth_year  death_year  age_at_death is_alive\n",
      "         Dick Marr      1938.0         NaN           NaN     True\n",
      "   Ghosh, Arabinda      1937.0         NaN           NaN     True\n",
      "    Ching-yuan Lin      1932.0         NaN           NaN     True\n",
      " Walter F. Carroll      1946.0         NaN           NaN     True\n",
      "       Luke Jensen      1954.0         NaN           NaN     True\n",
      "Flexner, Marion W.      1899.0      1992.0          93.0    False\n",
      "        R. Lässer      1950.0         NaN           NaN     True\n",
      "    Lynda S. Boren      1941.0         NaN           NaN     True\n",
      "     Gouri Mirpuri      1960.0         NaN           NaN     True\n",
      "      William Boon      1933.0         NaN           NaN     True\n",
      "\n",
      "🔍 QUELQUES EXEMPLES INTÉRESSANTS :\n",
      "\n",
      "👴 AUTEURS LES PLUS ANCIENS :\n",
      "   • Mis'ar ibn al-Muhalhil Abu Dulaf al-Yanbūʻī - né en 1000 (date de décès inconnue)\n",
      "   • Mufaḍḍal ibn Muḥammad ibn Misʻar - né en 1000 (mort en 1050)\n",
      "   • Jing Yu - né en 1000 (mort en 1064)\n",
      "\n",
      "👶 AUTEURS LES PLUS RÉCENTS :\n",
      "   • Zain ul Abideen - né en 2022 (probablement vivant)\n",
      "   • Tuttle Twins Show - né en 2021 (probablement vivant)\n",
      "   • Stefanie Gercke - né en 2021 (probablement vivant)\n",
      "\n",
      "📚 AUTEURS AVEC BIOGRAPHIE :\n",
      "   • C. J. Diederichs : Claus Jürgen Diederichs (* 14. Juni 1941 in Neustrelitz, Mecklenburg-Vorpommern) ist ein deutscher B...\n",
      "   • Christoph Dolge : Christoph Dolge wurde 1985 in Dresden geboren, studierte in Zittau Umweltbiotechnologie und nahm von...\n",
      "   • Manuel P. Villatoro : Manuel P. Villatoro es licenciado en Periodismo por la Universidad Complutense de Madrid.\n",
      "\n",
      "💾 SAUVEGARDE DU DATAFRAME :\n",
      "Le DataFrame est maintenant disponible dans la variable 'df_authors_birth'\n",
      "\n",
      "📁 Pour sauvegarder en CSV :\n",
      "   df_authors_birth.to_csv('auteurs_avec_date_naissance.csv', index=False)\n",
      "\n",
      "🔍 UTILISATION DU DATAFRAME :\n",
      "   • df_authors_birth.info() - Informations sur le DataFrame\n",
      "   • df_authors_birth.describe() - Statistiques descriptives\n",
      "   • df_authors_birth[df_authors_birth['is_alive'] == True] - Auteurs vivants\n",
      "   • df_authors_birth[df_authors_birth['bio'] != ''] - Auteurs avec biographie\n",
      "   • df_authors_birth.groupby('birth_year').size() - Répartition par année\n"
     ]
    }
   ],
   "source": [
    "# EXÉCUTION DE L'EXTRACTION\n",
    "fichier_auteurs = r\"C:\\Users\\dd758\\Formation_IA_Greta\\Projet_possible certif\\Livre_analyse\\data_book\\databook\\data\\fichier_openlibrary\\ol_dump_authors_2025-05-31.txt\\ol_dump_authors_2025-05-31.txt\"\n",
    "\n",
    "if os.path.exists(fichier_auteurs):\n",
    "    print(f\"✅ Fichier trouvé : {os.path.basename(fichier_auteurs)}\")\n",
    "    \n",
    "    # Demander à l'utilisateur s'il veut limiter le nombre d'auteurs\n",
    "    print(f\"\\n⚠️ ATTENTION : Le fichier complet peut contenir des millions d'auteurs.\")\n",
    "    print(f\"Pour un test rapide, vous pouvez limiter à un échantillon.\")\n",
    "    print(f\"\\nOptions :\")\n",
    "    print(f\"  1. Échantillon rapide (10,000 premiers auteurs avec date de naissance)\")\n",
    "    print(f\"  2. Échantillon moyen (50,000 premiers auteurs avec date de naissance)\")\n",
    "    print(f\"  3. Extraction complète (TOUS les auteurs - peut prendre du temps)\")\n",
    "    \n",
    "    # Pour cet exemple, on prend un échantillon moyen\n",
    "    choice = 3  # Vous pouvez changer cette valeur\n",
    "    \n",
    "    if choice == 1:\n",
    "        max_authors = 10000\n",
    "        print(f\"\\n🚀 Extraction d'un échantillon rapide (max {max_authors:,} auteurs)...\")\n",
    "    elif choice == 2:\n",
    "        max_authors = 50000\n",
    "        print(f\"\\n🚀 Extraction d'un échantillon moyen (max {max_authors:,} auteurs)...\")\n",
    "    else:\n",
    "        max_authors = None\n",
    "        print(f\"\\n🚀 Extraction complète (TOUS les auteurs avec date de naissance)...\")\n",
    "    \n",
    "    # Extraire les données\n",
    "    authors_data = extract_authors_with_birth_date(fichier_auteurs, max_authors=max_authors)\n",
    "    \n",
    "    if authors_data:\n",
    "        # Créer le DataFrame\n",
    "        df_authors_birth = create_authors_dataframe(authors_data)\n",
    "        \n",
    "        # Afficher un aperçu\n",
    "        display_dataframe_sample(df_authors_birth, n=10)\n",
    "        \n",
    "        print(f\"\\n💾 SAUVEGARDE DU DATAFRAME :\")\n",
    "        print(f\"Le DataFrame est maintenant disponible dans la variable 'df_authors_birth'\")\n",
    "        print(f\"\\n📁 Pour sauvegarder en CSV :\")\n",
    "        print(f\"   df_authors_birth.to_csv('auteurs_avec_date_naissance.csv', index=False)\")\n",
    "        \n",
    "        print(f\"\\n🔍 UTILISATION DU DATAFRAME :\")\n",
    "        print(f\"   • df_authors_birth.info() - Informations sur le DataFrame\")\n",
    "        print(f\"   • df_authors_birth.describe() - Statistiques descriptives\")\n",
    "        print(f\"   • df_authors_birth[df_authors_birth['is_alive'] == True] - Auteurs vivants\")\n",
    "        print(f\"   • df_authors_birth[df_authors_birth['bio'] != ''] - Auteurs avec biographie\")\n",
    "        print(f\"   • df_authors_birth.groupby('birth_year').size() - Répartition par année\")\n",
    "    \n",
    "    else:\n",
    "        print(\"❌ Aucune donnée d'auteur extraite\")\n",
    "else:\n",
    "    print(\"❌ Fichier d'auteurs non trouvé\")\n",
    "    print(f\"Chemin recherché : {fichier_auteurs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors_birth.to_csv('auteurs_avec_date_naissance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 EXTRACTION DES INFORMATIONS SUR LES LIVRES\n",
      "============================================================\n",
      "🚀 DÉMARRAGE DE L'ANALYSE DES LIVRES\n",
      "============================================================\n",
      "🔍 RECHERCHE DES FICHIERS DE LIVRES DISPONIBLES :\n",
      "--------------------------------------------------\n",
      "📁 autrices-auteurs-collections-maisons-edition-2018-05-01.csv\n",
      "   Taille : 0.2 MB\n",
      "   Type : Éditions\n",
      "\n",
      "📁 ol_dump_editions_2025-05-31.txt.gz\n",
      "   Taille : 10969.8 MB\n",
      "   Type : Éditions\n",
      "\n",
      "✅ 2 fichier(s) de livres trouvé(s)\n",
      "\n",
      "📚 ANALYSE DES ÉDITIONS\n",
      "   Fichier sélectionné : autrices-auteurs-collections-maisons-edition-2018-05-01.csv\n",
      "📖 ANALYSE D'UN ÉCHANTILLON DE EDITIONS\n",
      "   Fichier : autrices-auteurs-collections-maisons-edition-2018-05-01.csv\n",
      "   Échantillon : 2,000 entrées\n",
      "--------------------------------------------------\n",
      "✅ Échantillon extrait : 0 editions sur 0 entrées traitées\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTION DES INFORMATIONS SUR LES LIVRES\n",
    "print(\"📚 EXTRACTION DES INFORMATIONS SUR LES LIVRES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import gzip\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def analyze_book_files():\n",
    "    \"\"\"Analyse les fichiers disponibles pour les livres\"\"\"\n",
    "    base_path = r\"C:\\Users\\dd758\\Formation_IA_Greta\\Projet_possible certif\\Livre_analyse\\data_book\\databook\\data\\fichier_openlibrary\"\n",
    "    \n",
    "    print(\"🔍 RECHERCHE DES FICHIERS DE LIVRES DISPONIBLES :\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    book_files = []\n",
    "    \n",
    "    # Rechercher les fichiers d'éditions et de works\n",
    "    for filename in os.listdir(base_path):\n",
    "        if 'edition' in filename.lower() or 'work' in filename.lower():\n",
    "            file_path = os.path.join(base_path, filename)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            file_size_mb = file_size / (1024 * 1024)\n",
    "            \n",
    "            book_files.append({\n",
    "                'filename': filename,\n",
    "                'path': file_path,\n",
    "                'size_mb': file_size_mb,\n",
    "                'type': 'editions' if 'edition' in filename.lower() else 'works'\n",
    "            })\n",
    "            \n",
    "            print(f\"📁 {filename}\")\n",
    "            print(f\"   Taille : {file_size_mb:.1f} MB\")\n",
    "            print(f\"   Type : {'Éditions' if 'edition' in filename.lower() else 'Œuvres'}\")\n",
    "            print()\n",
    "    \n",
    "    return book_files\n",
    "\n",
    "def extract_books_sample(filename, max_books=1000, book_type='editions'):\n",
    "    \"\"\"Extrait un échantillon de livres pour analyser la structure\"\"\"\n",
    "    print(f\"📖 ANALYSE D'UN ÉCHANTILLON DE {book_type.upper()}\")\n",
    "    print(f\"   Fichier : {os.path.basename(filename)}\")\n",
    "    print(f\"   Échantillon : {max_books:,} entrées\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    books_data = []\n",
    "    total_processed = 0\n",
    "    books_found = 0\n",
    "    \n",
    "    try:\n",
    "        # Déterminer si le fichier est compressé\n",
    "        open_func = gzip.open if filename.endswith('.gz') else open\n",
    "        mode = 'rt' if filename.endswith('.gz') else 'r'\n",
    "        \n",
    "        with open_func(filename, mode, encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if books_found >= max_books:\n",
    "                    break\n",
    "                \n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 5:\n",
    "                    entry_type = parts[0]\n",
    "                    \n",
    "                    # Filtrer selon le type de livre recherché\n",
    "                    if (book_type == 'editions' and entry_type == '/type/edition') or \\\n",
    "                       (book_type == 'works' and entry_type == '/type/work'):\n",
    "                        \n",
    "                        total_processed += 1\n",
    "                        \n",
    "                        try:\n",
    "                            json_data = json.loads(parts[4])\n",
    "                            \n",
    "                            # Extraire les informations de base\n",
    "                            book_info = {\n",
    "                                'entry_type': entry_type,\n",
    "                                'book_id': parts[1],\n",
    "                                'revision': parts[2],\n",
    "                                'created': parts[3],\n",
    "                                'title': json_data.get('title', ''),\n",
    "                                'subtitle': json_data.get('subtitle', ''),\n",
    "                            }\n",
    "                            \n",
    "                            # Informations spécifiques aux éditions\n",
    "                            if book_type == 'editions':\n",
    "                                book_info.update({\n",
    "                                    'isbn_10': '',\n",
    "                                    'isbn_13': '',\n",
    "                                    'publishers': '',\n",
    "                                    'publish_date': json_data.get('publish_date', ''),\n",
    "                                    'publish_year': None,\n",
    "                                    'pages': json_data.get('number_of_pages', ''),\n",
    "                                    'languages': '',\n",
    "                                    'authors': '',\n",
    "                                    'works': '',\n",
    "                                    'edition_name': json_data.get('edition_name', ''),\n",
    "                                    'physical_format': json_data.get('physical_format', ''),\n",
    "                                    'weight': json_data.get('weight', ''),\n",
    "                                    'dimensions': json_data.get('dimensions', ''),\n",
    "                                })\n",
    "                                \n",
    "                                # Extraire ISBN\n",
    "                                if 'isbn_10' in json_data:\n",
    "                                    book_info['isbn_10'] = ' | '.join(json_data['isbn_10']) if isinstance(json_data['isbn_10'], list) else str(json_data['isbn_10'])\n",
    "                                if 'isbn_13' in json_data:\n",
    "                                    book_info['isbn_13'] = ' | '.join(json_data['isbn_13']) if isinstance(json_data['isbn_13'], list) else str(json_data['isbn_13'])\n",
    "                                \n",
    "                                # Extraire éditeurs\n",
    "                                if 'publishers' in json_data:\n",
    "                                    book_info['publishers'] = ' | '.join(json_data['publishers']) if isinstance(json_data['publishers'], list) else str(json_data['publishers'])\n",
    "                                \n",
    "                                # Extraire langues\n",
    "                                if 'languages' in json_data:\n",
    "                                    if isinstance(json_data['languages'], list):\n",
    "                                        languages = []\n",
    "                                        for lang in json_data['languages']:\n",
    "                                            if isinstance(lang, dict) and 'key' in lang:\n",
    "                                                languages.append(lang['key'].replace('/languages/', ''))\n",
    "                                            else:\n",
    "                                                languages.append(str(lang))\n",
    "                                        book_info['languages'] = ' | '.join(languages)\n",
    "                                \n",
    "                                # Extraire auteurs\n",
    "                                if 'authors' in json_data:\n",
    "                                    if isinstance(json_data['authors'], list):\n",
    "                                        authors = []\n",
    "                                        for author in json_data['authors']:\n",
    "                                            if isinstance(author, dict) and 'key' in author:\n",
    "                                                authors.append(author['key'])\n",
    "                                            else:\n",
    "                                                authors.append(str(author))\n",
    "                                        book_info['authors'] = ' | '.join(authors)\n",
    "                                \n",
    "                                # Extraire works\n",
    "                                if 'works' in json_data:\n",
    "                                    if isinstance(json_data['works'], list):\n",
    "                                        works = []\n",
    "                                        for work in json_data['works']:\n",
    "                                            if isinstance(work, dict) and 'key' in work:\n",
    "                                                works.append(work['key'])\n",
    "                                            else:\n",
    "                                                works.append(str(work))\n",
    "                                        book_info['works'] = ' | '.join(works)\n",
    "                                \n",
    "                                # Extraire l'année de publication\n",
    "                                if book_info['publish_date']:\n",
    "                                    year_match = re.search(r'\\b(\\d{4})\\b', str(book_info['publish_date']))\n",
    "                                    if year_match:\n",
    "                                        year = int(year_match.group(1))\n",
    "                                        if 1000 <= year <= datetime.now().year:\n",
    "                                            book_info['publish_year'] = year\n",
    "                            \n",
    "                            # Informations spécifiques aux works (œuvres)\n",
    "                            elif book_type == 'works':\n",
    "                                book_info.update({\n",
    "                                    'authors': '',\n",
    "                                    'subjects': '',\n",
    "                                    'subject_places': '',\n",
    "                                    'subject_times': '',\n",
    "                                    'subject_people': '',\n",
    "                                    'description': '',\n",
    "                                    'first_publish_date': json_data.get('first_publish_date', ''),\n",
    "                                    'first_publish_year': None,\n",
    "                                    'covers': '',\n",
    "                                    'excerpts': '',\n",
    "                                    'links': '',\n",
    "                                })\n",
    "                                \n",
    "                                # Extraire auteurs\n",
    "                                if 'authors' in json_data:\n",
    "                                    if isinstance(json_data['authors'], list):\n",
    "                                        authors = []\n",
    "                                        for author in json_data['authors']:\n",
    "                                            if isinstance(author, dict):\n",
    "                                                if 'author' in author and isinstance(author['author'], dict) and 'key' in author['author']:\n",
    "                                                    authors.append(author['author']['key'])\n",
    "                                                elif 'key' in author:\n",
    "                                                    authors.append(author['key'])\n",
    "                                            else:\n",
    "                                                authors.append(str(author))\n",
    "                                        book_info['authors'] = ' | '.join(authors)\n",
    "                                \n",
    "                                # Extraire sujets\n",
    "                                if 'subjects' in json_data:\n",
    "                                    book_info['subjects'] = ' | '.join(json_data['subjects']) if isinstance(json_data['subjects'], list) else str(json_data['subjects'])\n",
    "                                \n",
    "                                # Extraire description\n",
    "                                if 'description' in json_data:\n",
    "                                    desc = json_data['description']\n",
    "                                    if isinstance(desc, dict) and 'value' in desc:\n",
    "                                        book_info['description'] = desc['value']\n",
    "                                    elif isinstance(desc, str):\n",
    "                                        book_info['description'] = desc\n",
    "                                \n",
    "                                # Extraire l'année de première publication\n",
    "                                if book_info['first_publish_date']:\n",
    "                                    year_match = re.search(r'\\b(\\d{4})\\b', str(book_info['first_publish_date']))\n",
    "                                    if year_match:\n",
    "                                        year = int(year_match.group(1))\n",
    "                                        if 1000 <= year <= datetime.now().year:\n",
    "                                            book_info['first_publish_year'] = year\n",
    "                            \n",
    "                            books_data.append(book_info)\n",
    "                            books_found += 1\n",
    "                        \n",
    "                        except json.JSONDecodeError:\n",
    "                            continue\n",
    "                \n",
    "                # Afficher le progrès\n",
    "                if total_processed % 1000 == 0 and total_processed > 0:\n",
    "                    print(f\"   Traité {total_processed:,} entrées, trouvé {books_found:,} {book_type}...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'extraction : {e}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"✅ Échantillon extrait : {books_found:,} {book_type} sur {total_processed:,} entrées traitées\")\n",
    "    return books_data\n",
    "\n",
    "def analyze_books_structure(books_data, book_type='editions'):\n",
    "    \"\"\"Analyse la structure des données de livres\"\"\"\n",
    "    if not books_data:\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n📊 ANALYSE DE LA STRUCTURE DES {book_type.upper()}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df = pd.DataFrame(books_data)\n",
    "    \n",
    "    print(f\"📏 Dimensions : {df.shape[0]:,} lignes × {df.shape[1]} colonnes\")\n",
    "    print(f\"\\n📋 COLONNES DISPONIBLES :\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        non_empty = df[col].notna() & (df[col] != '')\n",
    "        percentage = (non_empty.sum() / len(df)) * 100\n",
    "        print(f\"   {i:2d}. {col:<20} : {non_empty.sum():>5,} ({percentage:>5.1f}%)\")\n",
    "    \n",
    "    # Analyse spécifique selon le type\n",
    "    if book_type == 'editions':\n",
    "        print(f\"\\n📚 ANALYSE SPÉCIFIQUE DES ÉDITIONS :\")\n",
    "        \n",
    "        # Années de publication\n",
    "        if 'publish_year' in df.columns:\n",
    "            years = df['publish_year'].dropna()\n",
    "            if len(years) > 0:\n",
    "                print(f\"   📅 Années de publication : {years.min():.0f} - {years.max():.0f}\")\n",
    "                \n",
    "                # Répartition par décennie récente\n",
    "                recent_years = years[years >= 1900]\n",
    "                if len(recent_years) > 0:\n",
    "                    print(f\"   📈 Publications depuis 1900 : {len(recent_years):,}\")\n",
    "                    for decade in range(1900, 2030, 10):\n",
    "                        count = recent_years[(recent_years >= decade) & (recent_years < decade + 10)].count()\n",
    "                        if count > 0:\n",
    "                            print(f\"      • {decade}s : {count:,} éditions\")\n",
    "        \n",
    "        # Langues les plus fréquentes\n",
    "        if 'languages' in df.columns:\n",
    "            all_languages = []\n",
    "            for langs in df['languages'].dropna():\n",
    "                if langs:\n",
    "                    all_languages.extend(langs.split(' | '))\n",
    "            \n",
    "            if all_languages:\n",
    "                lang_counts = pd.Series(all_languages).value_counts().head(10)\n",
    "                print(f\"\\n   🌍 LANGUES LES PLUS FRÉQUENTES :\")\n",
    "                for lang, count in lang_counts.items():\n",
    "                    print(f\"      • {lang:<15} : {count:,} éditions\")\n",
    "        \n",
    "        # Éditeurs les plus fréquents\n",
    "        if 'publishers' in df.columns:\n",
    "            all_publishers = []\n",
    "            for pubs in df['publishers'].dropna():\n",
    "                if pubs:\n",
    "                    all_publishers.extend(pubs.split(' | '))\n",
    "            \n",
    "            if all_publishers:\n",
    "                pub_counts = pd.Series(all_publishers).value_counts().head(10)\n",
    "                print(f\"\\n   🏢 ÉDITEURS LES PLUS FRÉQUENTS :\")\n",
    "                for pub, count in pub_counts.items():\n",
    "                    print(f\"      • {pub:<30} : {count:,} éditions\")\n",
    "    \n",
    "    elif book_type == 'works':\n",
    "        print(f\"\\n📖 ANALYSE SPÉCIFIQUE DES ŒUVRES :\")\n",
    "        \n",
    "        # Années de première publication\n",
    "        if 'first_publish_year' in df.columns:\n",
    "            years = df['first_publish_year'].dropna()\n",
    "            if len(years) > 0:\n",
    "                print(f\"   📅 Premières publications : {years.min():.0f} - {years.max():.0f}\")\n",
    "        \n",
    "        # Sujets les plus fréquents\n",
    "        if 'subjects' in df.columns:\n",
    "            all_subjects = []\n",
    "            for subjects in df['subjects'].dropna():\n",
    "                if subjects:\n",
    "                    all_subjects.extend(subjects.split(' | '))\n",
    "            \n",
    "            if all_subjects:\n",
    "                subject_counts = pd.Series(all_subjects).value_counts().head(15)\n",
    "                print(f\"\\n   🏷️ SUJETS LES PLUS FRÉQUENTS :\")\n",
    "                for subject, count in subject_counts.items():\n",
    "                    print(f\"      • {subject:<35} : {count:,} œuvres\")\n",
    "    \n",
    "    # Exemples de livres\n",
    "    print(f\"\\n📋 EXEMPLES DE {book_type.upper()} :\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    display_cols = ['title', 'publish_year' if book_type == 'editions' else 'first_publish_year']\n",
    "    if book_type == 'editions':\n",
    "        display_cols.extend(['publishers', 'languages'])\n",
    "    else:\n",
    "        display_cols.extend(['subjects'])\n",
    "    \n",
    "    available_cols = [col for col in display_cols if col in df.columns]\n",
    "    \n",
    "    sample_df = df[available_cols].head(5)\n",
    "    for _, book in sample_df.iterrows():\n",
    "        print(f\"📚 {book['title']}\")\n",
    "        for col in available_cols[1:]:  # Skip title\n",
    "            if pd.notna(book[col]) and book[col] != '':\n",
    "                value = str(book[col])[:100] + \"...\" if len(str(book[col])) > 100 else str(book[col])\n",
    "                print(f\"   {col}: {value}\")\n",
    "        print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# LANCEMENT DE L'ANALYSE\n",
    "print(\"🚀 DÉMARRAGE DE L'ANALYSE DES LIVRES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Analyser les fichiers disponibles\n",
    "book_files = analyze_book_files()\n",
    "\n",
    "if book_files:\n",
    "    print(f\"✅ {len(book_files)} fichier(s) de livres trouvé(s)\")\n",
    "    \n",
    "    # 2. Choisir le fichier à analyser (prendre le premier fichier d'éditions)\n",
    "    editions_files = [f for f in book_files if f['type'] == 'editions']\n",
    "    works_files = [f for f in book_files if f['type'] == 'works']\n",
    "    \n",
    "    if editions_files:\n",
    "        print(f\"\\n📚 ANALYSE DES ÉDITIONS\")\n",
    "        selected_file = editions_files[0]\n",
    "        print(f\"   Fichier sélectionné : {selected_file['filename']}\")\n",
    "        \n",
    "        # Extraire un échantillon d'éditions\n",
    "        books_sample = extract_books_sample(selected_file['path'], max_books=2000, book_type='editions')\n",
    "        \n",
    "        if books_sample:\n",
    "            # Analyser la structure\n",
    "            df_books = analyze_books_structure(books_sample, book_type='editions')\n",
    "            print(f\"\\n💾 DataFrame 'df_books' créé avec {len(books_sample):,} éditions\")\n",
    "        \n",
    "    if works_files:\n",
    "        print(f\"\\n📖 ANALYSE DES ŒUVRES\")\n",
    "        selected_file = works_files[0]\n",
    "        print(f\"   Fichier sélectionné : {selected_file['filename']}\")\n",
    "        \n",
    "        # Extraire un échantillon d'œuvres\n",
    "        works_sample = extract_books_sample(selected_file['path'], max_books=2000, book_type='works')\n",
    "        \n",
    "        if works_sample:\n",
    "            # Analyser la structure\n",
    "            df_works = analyze_books_structure(works_sample, book_type='works')\n",
    "            print(f\"\\n💾 DataFrame 'df_works' créé avec {len(works_sample):,} œuvres\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Aucun fichier de livres trouvé\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 EXTRACTION SPÉCIALISÉE DES LIVRES\n",
      "============================================================\n",
      "📚 EXTRACTION SPÉCIALISÉE D'ÉDITIONS\n",
      "   Fichier : autrices-auteurs-collections-maisons-edition-2018-05-01.csv\n",
      "🔍 EXTRACTION AVEC CRITÈRES :\n",
      "   • ISBN requis : True\n",
      "   • Auteurs requis : True\n",
      "   • Années : 1950 - 2024\n",
      "   • Langues : eng, fre, spa, ger, ita, por, rus, jpn, chi\n",
      "   • Maximum : 15,000 livres\n",
      "--------------------------------------------------\n",
      "✅ Extraction terminée : 0 livres trouvés sur 0 éditions traitées\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTION SPÉCIALISÉE DES LIVRES\n",
    "print(\"🎯 EXTRACTION SPÉCIALISÉE DES LIVRES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def extract_books_with_criteria(filename, max_books=10000, criteria=None):\n",
    "    \"\"\"Extrait les livres selon des critères spécifiques\"\"\"\n",
    "    if criteria is None:\n",
    "        criteria = {\n",
    "            'has_isbn': True,\n",
    "            'has_authors': True,\n",
    "            'min_year': 1900,\n",
    "            'max_year': 2024,\n",
    "            'languages': ['eng', 'fre', 'spa', 'ger', 'ita'],  # Langues principales\n",
    "        }\n",
    "    \n",
    "    print(f\"🔍 EXTRACTION AVEC CRITÈRES :\")\n",
    "    print(f\"   • ISBN requis : {criteria.get('has_isbn', False)}\")\n",
    "    print(f\"   • Auteurs requis : {criteria.get('has_authors', False)}\")\n",
    "    print(f\"   • Années : {criteria.get('min_year', 'Toutes')} - {criteria.get('max_year', 'Toutes')}\")\n",
    "    print(f\"   • Langues : {', '.join(criteria.get('languages', ['Toutes']))}\")\n",
    "    print(f\"   • Maximum : {max_books:,} livres\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    books_data = []\n",
    "    total_processed = 0\n",
    "    books_found = 0\n",
    "    \n",
    "    try:\n",
    "        # Déterminer si le fichier est compressé\n",
    "        open_func = gzip.open if filename.endswith('.gz') else open\n",
    "        mode = 'rt' if filename.endswith('.gz') else 'r'\n",
    "        \n",
    "        with open_func(filename, mode, encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if books_found >= max_books:\n",
    "                    break\n",
    "                \n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 5 and parts[0] == '/type/edition':\n",
    "                    total_processed += 1\n",
    "                    \n",
    "                    try:\n",
    "                        json_data = json.loads(parts[4])\n",
    "                        \n",
    "                        # Vérifier les critères\n",
    "                        meets_criteria = True\n",
    "                        \n",
    "                        # Critère ISBN\n",
    "                        if criteria.get('has_isbn', False):\n",
    "                            has_isbn = 'isbn_10' in json_data or 'isbn_13' in json_data\n",
    "                            if not has_isbn:\n",
    "                                meets_criteria = False\n",
    "                                continue\n",
    "                        \n",
    "                        # Critère auteurs\n",
    "                        if criteria.get('has_authors', False):\n",
    "                            has_authors = 'authors' in json_data and json_data['authors']\n",
    "                            if not has_authors:\n",
    "                                meets_criteria = False\n",
    "                                continue\n",
    "                        \n",
    "                        # Critère année\n",
    "                        if criteria.get('min_year') or criteria.get('max_year'):\n",
    "                            publish_year = None\n",
    "                            if 'publish_date' in json_data:\n",
    "                                year_match = re.search(r'\\b(\\d{4})\\b', str(json_data['publish_date']))\n",
    "                                if year_match:\n",
    "                                    publish_year = int(year_match.group(1))\n",
    "                            \n",
    "                            if publish_year:\n",
    "                                if criteria.get('min_year') and publish_year < criteria['min_year']:\n",
    "                                    meets_criteria = False\n",
    "                                    continue\n",
    "                                if criteria.get('max_year') and publish_year > criteria['max_year']:\n",
    "                                    meets_criteria = False\n",
    "                                    continue\n",
    "                        \n",
    "                        # Critère langue\n",
    "                        if criteria.get('languages'):\n",
    "                            book_languages = []\n",
    "                            if 'languages' in json_data:\n",
    "                                for lang in json_data['languages']:\n",
    "                                    if isinstance(lang, dict) and 'key' in lang:\n",
    "                                        lang_code = lang['key'].replace('/languages/', '')\n",
    "                                        book_languages.append(lang_code)\n",
    "                            \n",
    "                            if book_languages:\n",
    "                                has_target_language = any(lang in criteria['languages'] for lang in book_languages)\n",
    "                                if not has_target_language:\n",
    "                                    meets_criteria = False\n",
    "                                    continue\n",
    "                        \n",
    "                        if meets_criteria:\n",
    "                            # Extraire les informations complètes\n",
    "                            book_info = {\n",
    "                                'book_id': parts[1],\n",
    "                                'title': json_data.get('title', ''),\n",
    "                                'subtitle': json_data.get('subtitle', ''),\n",
    "                                'isbn_10': '',\n",
    "                                'isbn_13': '',\n",
    "                                'publishers': '',\n",
    "                                'publish_date': json_data.get('publish_date', ''),\n",
    "                                'publish_year': publish_year,\n",
    "                                'pages': json_data.get('number_of_pages', ''),\n",
    "                                'languages': '',\n",
    "                                'authors': '',\n",
    "                                'works': '',\n",
    "                                'physical_format': json_data.get('physical_format', ''),\n",
    "                                'edition_name': json_data.get('edition_name', ''),\n",
    "                                'description': '',\n",
    "                                'subjects': '',\n",
    "                                'weight': json_data.get('weight', ''),\n",
    "                                'dimensions': json_data.get('dimensions', ''),\n",
    "                                'covers': '',\n",
    "                                'created': parts[3],\n",
    "                                'revision': parts[2],\n",
    "                            }\n",
    "                            \n",
    "                            # Extraire ISBN\n",
    "                            if 'isbn_10' in json_data:\n",
    "                                book_info['isbn_10'] = ' | '.join(json_data['isbn_10']) if isinstance(json_data['isbn_10'], list) else str(json_data['isbn_10'])\n",
    "                            if 'isbn_13' in json_data:\n",
    "                                book_info['isbn_13'] = ' | '.join(json_data['isbn_13']) if isinstance(json_data['isbn_13'], list) else str(json_data['isbn_13'])\n",
    "                            \n",
    "                            # Extraire éditeurs\n",
    "                            if 'publishers' in json_data:\n",
    "                                book_info['publishers'] = ' | '.join(json_data['publishers']) if isinstance(json_data['publishers'], list) else str(json_data['publishers'])\n",
    "                            \n",
    "                            # Extraire langues\n",
    "                            if 'languages' in json_data:\n",
    "                                languages = []\n",
    "                                for lang in json_data['languages']:\n",
    "                                    if isinstance(lang, dict) and 'key' in lang:\n",
    "                                        languages.append(lang['key'].replace('/languages/', ''))\n",
    "                                    else:\n",
    "                                        languages.append(str(lang))\n",
    "                                book_info['languages'] = ' | '.join(languages)\n",
    "                            \n",
    "                            # Extraire auteurs\n",
    "                            if 'authors' in json_data:\n",
    "                                authors = []\n",
    "                                for author in json_data['authors']:\n",
    "                                    if isinstance(author, dict) and 'key' in author:\n",
    "                                        authors.append(author['key'])\n",
    "                                    else:\n",
    "                                        authors.append(str(author))\n",
    "                                book_info['authors'] = ' | '.join(authors)\n",
    "                            \n",
    "                            # Extraire works\n",
    "                            if 'works' in json_data:\n",
    "                                works = []\n",
    "                                for work in json_data['works']:\n",
    "                                    if isinstance(work, dict) and 'key' in work:\n",
    "                                        works.append(work['key'])\n",
    "                                    else:\n",
    "                                        works.append(str(work))\n",
    "                                book_info['works'] = ' | '.join(works)\n",
    "                            \n",
    "                            # Extraire description\n",
    "                            if 'description' in json_data:\n",
    "                                desc = json_data['description']\n",
    "                                if isinstance(desc, dict) and 'value' in desc:\n",
    "                                    book_info['description'] = desc['value']\n",
    "                                elif isinstance(desc, str):\n",
    "                                    book_info['description'] = desc\n",
    "                            \n",
    "                            # Extraire sujets\n",
    "                            if 'subjects' in json_data:\n",
    "                                book_info['subjects'] = ' | '.join(json_data['subjects']) if isinstance(json_data['subjects'], list) else str(json_data['subjects'])\n",
    "                            \n",
    "                            # Extraire covers\n",
    "                            if 'covers' in json_data:\n",
    "                                book_info['covers'] = ' | '.join([str(cover) for cover in json_data['covers']]) if isinstance(json_data['covers'], list) else str(json_data['covers'])\n",
    "                            \n",
    "                            books_data.append(book_info)\n",
    "                            books_found += 1\n",
    "                    \n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "                \n",
    "                # Afficher le progrès\n",
    "                if total_processed % 5000 == 0 and total_processed > 0:\n",
    "                    print(f\"   Traité {total_processed:,} éditions, trouvé {books_found:,} livres correspondants...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'extraction : {e}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"✅ Extraction terminée : {books_found:,} livres trouvés sur {total_processed:,} éditions traitées\")\n",
    "    return books_data\n",
    "\n",
    "def analyze_extracted_books(books_data):\n",
    "    \"\"\"Analyse les livres extraits\"\"\"\n",
    "    if not books_data:\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n📊 ANALYSE DES LIVRES EXTRAITS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df = pd.DataFrame(books_data)\n",
    "    \n",
    "    print(f\"📏 Dimensions : {df.shape[0]:,} livres × {df.shape[1]} colonnes\")\n",
    "    \n",
    "    # Analyse des années de publication\n",
    "    if 'publish_year' in df.columns:\n",
    "        years = df['publish_year'].dropna()\n",
    "        if len(years) > 0:\n",
    "            print(f\"\\n📅 RÉPARTITION PAR DÉCENNIE :\")\n",
    "            for decade in range(1900, 2030, 10):\n",
    "                count = years[(years >= decade) & (years < decade + 10)].count()\n",
    "                if count > 0:\n",
    "                    percentage = (count / len(years)) * 100\n",
    "                    print(f\"   • {decade}s : {count:,} livres ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Analyse des langues\n",
    "    if 'languages' in df.columns:\n",
    "        all_languages = []\n",
    "        for langs in df['languages'].dropna():\n",
    "            if langs:\n",
    "                all_languages.extend(langs.split(' | '))\n",
    "        \n",
    "        if all_languages:\n",
    "            lang_counts = pd.Series(all_languages).value_counts().head(10)\n",
    "            print(f\"\\n🌍 RÉPARTITION PAR LANGUE :\")\n",
    "            for lang, count in lang_counts.items():\n",
    "                percentage = (count / len(all_languages)) * 100\n",
    "                print(f\"   • {lang:<10} : {count:,} livres ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Analyse des éditeurs\n",
    "    if 'publishers' in df.columns:\n",
    "        all_publishers = []\n",
    "        for pubs in df['publishers'].dropna():\n",
    "            if pubs:\n",
    "                all_publishers.extend(pubs.split(' | '))\n",
    "        \n",
    "        if all_publishers:\n",
    "            pub_counts = pd.Series(all_publishers).value_counts().head(10)\n",
    "            print(f\"\\n🏢 TOP 10 ÉDITEURS :\")\n",
    "            for pub, count in pub_counts.items():\n",
    "                print(f\"   • {pub:<35} : {count:,} livres\")\n",
    "    \n",
    "    # Analyse des formats physiques\n",
    "    if 'physical_format' in df.columns:\n",
    "        format_counts = df['physical_format'].value_counts().head(10)\n",
    "        print(f\"\\n📖 FORMATS PHYSIQUES :\")\n",
    "        for format_type, count in format_counts.items():\n",
    "            if format_type and format_type != '':\n",
    "                percentage = (count / len(df)) * 100\n",
    "                print(f\"   • {format_type:<20} : {count:,} livres ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Analyse des pages\n",
    "    if 'pages' in df.columns:\n",
    "        pages_data = pd.to_numeric(df['pages'], errors='coerce').dropna()\n",
    "        if len(pages_data) > 0:\n",
    "            print(f\"\\n📄 STATISTIQUES DES PAGES :\")\n",
    "            print(f\"   • Moyenne : {pages_data.mean():.0f} pages\")\n",
    "            print(f\"   • Médiane : {pages_data.median():.0f} pages\")\n",
    "            print(f\"   • Min - Max : {pages_data.min():.0f} - {pages_data.max():.0f} pages\")\n",
    "            \n",
    "            # Répartition par tranches\n",
    "            print(f\"   • Répartition :\")\n",
    "            print(f\"     - Moins de 100 pages : {(pages_data < 100).sum():,} livres\")\n",
    "            print(f\"     - 100-300 pages : {((pages_data >= 100) & (pages_data <= 300)).sum():,} livres\")\n",
    "            print(f\"     - Plus de 300 pages : {(pages_data > 300).sum():,} livres\")\n",
    "    \n",
    "    # Taux de remplissage des métadonnées\n",
    "    print(f\"\\n📋 QUALITÉ DES MÉTADONNÉES :\")\n",
    "    quality_fields = ['isbn_10', 'isbn_13', 'publishers', 'authors', 'subjects', 'description', 'covers']\n",
    "    for field in quality_fields:\n",
    "        if field in df.columns:\n",
    "            non_empty = df[field].notna() & (df[field] != '')\n",
    "            percentage = (non_empty.sum() / len(df)) * 100\n",
    "            print(f\"   • {field:<15} : {non_empty.sum():>6,} ({percentage:>5.1f}%)\")\n",
    "    \n",
    "    # Exemples de livres de qualité\n",
    "    print(f\"\\n📚 EXEMPLES DE LIVRES AVEC MÉTADONNÉES COMPLÈTES :\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Filtrer les livres avec beaucoup de métadonnées\n",
    "    quality_score = 0\n",
    "    for field in ['isbn_13', 'publishers', 'authors', 'subjects', 'description']:\n",
    "        if field in df.columns:\n",
    "            quality_score += (df[field].notna() & (df[field] != '')).astype(int)\n",
    "    \n",
    "    df['quality_score'] = quality_score\n",
    "    high_quality = df[df['quality_score'] >= 4].head(5)\n",
    "    \n",
    "    for _, book in high_quality.iterrows():\n",
    "        print(f\"📖 {book['title']}\")\n",
    "        if pd.notna(book['subtitle']) and book['subtitle']:\n",
    "            print(f\"   Sous-titre: {book['subtitle']}\")\n",
    "        if pd.notna(book['publish_year']):\n",
    "            print(f\"   Année: {book['publish_year']:.0f}\")\n",
    "        if pd.notna(book['publishers']) and book['publishers']:\n",
    "            publishers = book['publishers'][:100] + \"...\" if len(book['publishers']) > 100 else book['publishers']\n",
    "            print(f\"   Éditeur: {publishers}\")\n",
    "        if pd.notna(book['languages']) and book['languages']:\n",
    "            print(f\"   Langues: {book['languages']}\")\n",
    "        if pd.notna(book['pages']) and book['pages']:\n",
    "            print(f\"   Pages: {book['pages']}\")\n",
    "        print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# LANCEMENT DE L'EXTRACTION SPÉCIALISÉE\n",
    "if 'book_files' in globals() and book_files:\n",
    "    editions_files = [f for f in book_files if f['type'] == 'editions']\n",
    "    \n",
    "    if editions_files:\n",
    "        print(f\"📚 EXTRACTION SPÉCIALISÉE D'ÉDITIONS\")\n",
    "        selected_file = editions_files[0]\n",
    "        print(f\"   Fichier : {selected_file['filename']}\")\n",
    "        \n",
    "        # Définir les critères d'extraction\n",
    "        extraction_criteria = {\n",
    "            'has_isbn': True,           # Livres avec ISBN\n",
    "            'has_authors': True,        # Livres avec auteurs\n",
    "            'min_year': 1950,          # Depuis 1950\n",
    "            'max_year': 2024,          # Jusqu'à 2024\n",
    "            'languages': ['eng', 'fre', 'spa', 'ger', 'ita', 'por', 'rus', 'jpn', 'chi']  # Langues principales\n",
    "        }\n",
    "        \n",
    "        # Extraire les livres\n",
    "        specialized_books = extract_books_with_criteria(\n",
    "            selected_file['path'], \n",
    "            max_books=15000, \n",
    "            criteria=extraction_criteria\n",
    "        )\n",
    "        \n",
    "        if specialized_books:\n",
    "            # Analyser les livres extraits\n",
    "            df_specialized_books = analyze_extracted_books(specialized_books)\n",
    "            print(f\"\\n💾 DataFrame 'df_specialized_books' créé avec {len(specialized_books):,} livres\")\n",
    "            print(f\"\\n📁 Pour sauvegarder en CSV :\")\n",
    "            print(f\"   df_specialized_books.to_csv('livres_specialises.csv', index=False)\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Aucun fichier d'éditions disponible pour l'extraction spécialisée\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 DIAGNOSTIC DES FICHIERS DE LIVRES\n",
      "============================================================\n",
      "📁 FICHIERS DISPONIBLES :\n",
      "------------------------------\n",
      "📄 autrices-auteurs-collections-maisons-edition-2018-05-01.csv\n",
      "   Taille: 0.2 MB\n",
      "\n",
      "📄 extracted_authors.csv\n",
      "   Taille: 740.2 MB\n",
      "\n",
      "📄 isbn-open-data.zip\n",
      "   Taille: 436.5 MB\n",
      "\n",
      "📄 ol_cdump_2025-05-31.txt.gz.opdownload\n",
      "   Taille: 40333.3 MB\n",
      "\n",
      "📄 ol_dump_authors_2025-05-31.txt.gz\n",
      "   Taille: 678.1 MB\n",
      "\n",
      "📄 ol_dump_editions_2025-05-31.txt.gz\n",
      "   Taille: 10969.8 MB\n",
      "\n",
      "📄 ol_dump_lists_2025-05-31.txt.gz\n",
      "   Taille: 35.3 MB\n",
      "\n",
      "📄 test_authors_100k.csv\n",
      "   Taille: 5.1 MB\n",
      "\n",
      "\n",
      "🔍 ANALYSE DÉTAILLÉE DES FICHIERS MIXTES :\n",
      "--------------------------------------------------\n",
      "❌ Fichier mixte non trouvé\n",
      "\n",
      "🔍 ANALYSE SPÉCIFIQUE DES ÉDITIONS :\n",
      "----------------------------------------\n",
      "\n",
      "💡 SUGGESTIONS :\n",
      "   1. Le fichier mixte contient peut-être les éditions plus loin\n",
      "   2. Il pourrait y avoir un fichier d'éditions séparé\n",
      "   3. La structure du fichier pourrait être différente\n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSTIC DES FICHIERS DE LIVRES\n",
    "print(\"🔍 DIAGNOSTIC DES FICHIERS DE LIVRES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "# Vérifier les fichiers disponibles\n",
    "base_path = r\"C:\\Users\\dd758\\Formation_IA_Greta\\Projet_possible certif\\Livre_analyse\\data_book\\databook\\data\\fichier_openlibrary\"\n",
    "\n",
    "print(\"📁 FICHIERS DISPONIBLES :\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if os.path.exists(base_path):\n",
    "    files = os.listdir(base_path)\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(base_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "            print(f\"📄 {filename}\")\n",
    "            print(f\"   Taille: {size_mb:.1f} MB\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"❌ Le répertoire n'existe pas\")\n",
    "\n",
    "print(\"\\n🔍 ANALYSE DÉTAILLÉE DES FICHIERS MIXTES :\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Analyser le fichier mixte principal\n",
    "fichier_mixte = r\"C:\\Users\\dd758\\Formation_IA_Greta\\Projet_possible certif\\Livre_analyse\\data_book\\databook\\data\\fichier_openlibrary\\ol_cdump_2025-05-31.txt.gz\"\n",
    "\n",
    "if os.path.exists(fichier_mixte):\n",
    "    print(f\"✅ Fichier mixte trouvé : {os.path.basename(fichier_mixte)}\")\n",
    "    \n",
    "    # Analyser les 1000 premières lignes\n",
    "    print(\"\\n📊 ANALYSE DES TYPES D'ENTRÉES (1000 premières lignes) :\")\n",
    "    \n",
    "    type_counts = {}\n",
    "    sample_entries = {}\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(fichier_mixte, 'rt', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= 1000:\n",
    "                    break\n",
    "                \n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 1:\n",
    "                    entry_type = parts[0]\n",
    "                    type_counts[entry_type] = type_counts.get(entry_type, 0) + 1\n",
    "                    \n",
    "                    # Garder un échantillon de chaque type\n",
    "                    if entry_type not in sample_entries:\n",
    "                        sample_entries[entry_type] = {\n",
    "                            'line': line.strip(),\n",
    "                            'parts_count': len(parts)\n",
    "                        }\n",
    "        \n",
    "        print(f\"Types d'entrées trouvés :\")\n",
    "        for entry_type, count in sorted(type_counts.items()):\n",
    "            print(f\"   • {entry_type:<20} : {count:,} entrées\")\n",
    "        \n",
    "        print(f\"\\n📋 ÉCHANTILLONS DE CHAQUE TYPE :\")\n",
    "        for entry_type, sample in sample_entries.items():\n",
    "            print(f\"\\n🔸 {entry_type} ({sample['parts_count']} parties) :\")\n",
    "            # Afficher seulement les premières parties pour éviter le JSON complet\n",
    "            parts = sample['line'].split('\\t')[:4]\n",
    "            for i, part in enumerate(parts):\n",
    "                print(f\"   [{i}] {part[:100]}{'...' if len(part) > 100 else ''}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'analyse : {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Fichier mixte non trouvé\")\n",
    "\n",
    "print(\"\\n🔍 ANALYSE SPÉCIFIQUE DES ÉDITIONS :\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Rechercher spécifiquement les éditions dans le fichier mixte\n",
    "if os.path.exists(fichier_mixte):\n",
    "    editions_found = 0\n",
    "    works_found = 0\n",
    "    authors_found = 0\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(fichier_mixte, 'rt', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= 5000:  # Analyser plus de lignes\n",
    "                    break\n",
    "                \n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 5:\n",
    "                    entry_type = parts[0]\n",
    "                    \n",
    "                    if entry_type == '/type/edition':\n",
    "                        editions_found += 1\n",
    "                        if editions_found == 1:  # Premier exemple d'édition\n",
    "                            print(f\"📚 PREMIÈRE ÉDITION TROUVÉE (ligne {i+1}) :\")\n",
    "                            try:\n",
    "                                import json\n",
    "                                json_data = json.loads(parts[4])\n",
    "                                print(f\"   • ID: {parts[1]}\")\n",
    "                                print(f\"   • Titre: {json_data.get('title', 'N/A')}\")\n",
    "                                print(f\"   • Date: {json_data.get('publish_date', 'N/A')}\")\n",
    "                                print(f\"   • ISBN: {json_data.get('isbn_13', json_data.get('isbn_10', 'N/A'))}\")\n",
    "                                print(f\"   • Auteurs: {'Oui' if 'authors' in json_data else 'Non'}\")\n",
    "                            except:\n",
    "                                print(\"   • Erreur lors du parsing JSON\")\n",
    "                    \n",
    "                    elif entry_type == '/type/work':\n",
    "                        works_found += 1\n",
    "                    elif entry_type == '/type/author':\n",
    "                        authors_found += 1\n",
    "        \n",
    "        print(f\"\\n📊 RÉSULTATS DE L'ANALYSE (5000 premières lignes) :\")\n",
    "        print(f\"   • Éditions trouvées : {editions_found:,}\")\n",
    "        print(f\"   • Œuvres trouvées : {works_found:,}\")\n",
    "        print(f\"   • Auteurs trouvés : {authors_found:,}\")\n",
    "        \n",
    "        if editions_found == 0:\n",
    "            print(f\"\\n⚠️ AUCUNE ÉDITION TROUVÉE dans les 5000 premières lignes !\")\n",
    "            print(f\"   Le fichier pourrait contenir les éditions plus loin.\")\n",
    "            print(f\"   Essayons de chercher plus loin...\")\n",
    "            \n",
    "            # Recherche rapide dans tout le fichier\n",
    "            print(f\"\\n🔍 RECHERCHE RAPIDE DES ÉDITIONS :\")\n",
    "            try:\n",
    "                with gzip.open(fichier_mixte, 'rt', encoding='utf-8') as f:\n",
    "                    for i, line in enumerate(f):\n",
    "                        if i % 10000 == 0:  # Échantillonner chaque 10000e ligne\n",
    "                            parts = line.strip().split('\\t')\n",
    "                            if len(parts) >= 1 and parts[0] == '/type/edition':\n",
    "                                print(f\"   ✅ Première édition trouvée à la ligne ~{i+1}\")\n",
    "                                break\n",
    "                        if i > 100000:  # Limiter la recherche\n",
    "                            break\n",
    "                    else:\n",
    "                        print(f\"   ❌ Aucune édition trouvée dans les 100,000 premières lignes\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Erreur lors de la recherche : {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'analyse : {e}\")\n",
    "\n",
    "print(f\"\\n💡 SUGGESTIONS :\")\n",
    "print(f\"   1. Le fichier mixte contient peut-être les éditions plus loin\")\n",
    "print(f\"   2. Il pourrait y avoir un fichier d'éditions séparé\")\n",
    "print(f\"   3. La structure du fichier pourrait être différente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 MISE À JOUR DE LA BASE DE DONNÉES AVEC LES DATES DE MORT\n",
    "print(\"🔄 MISE À JOUR DE LA BASE DE DONNÉES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Connexion à la base de données (ajustez selon votre configuration)\n",
    "import sqlite3  # ou utilisez votre connecteur de base de données\n",
    "\n",
    "def connect_to_database():\n",
    "    \"\"\"Connexion à votre base de données\"\"\"\n",
    "    # AJUSTEZ CES PARAMÈTRES SELON VOTRE BASE DE DONNÉES\n",
    "    \n",
    "    # Pour SQLite (exemple)\n",
    "    # return sqlite3.connect('path/to/your/database.db')\n",
    "    \n",
    "    # Pour MySQL/MariaDB\n",
    "    # import mysql.connector\n",
    "    # return mysql.connector.connect(\n",
    "    #     host='localhost',\n",
    "    #     database='databook',\n",
    "    #     user='your_username',\n",
    "    #     password='your_password'\n",
    "    # )\n",
    "    \n",
    "    # Pour PostgreSQL\n",
    "    # import psycopg2\n",
    "    # return psycopg2.connect(\n",
    "    #     host='localhost',\n",
    "    #     database='databook',\n",
    "    #     user='your_username',\n",
    "    #     password='your_password'\n",
    "    # )\n",
    "    \n",
    "    print(\"⚠️ Veuillez configurer la connexion à votre base de données\")\n",
    "    return None\n",
    "\n",
    "def add_death_date_column():\n",
    "    \"\"\"Ajouter la colonne date_mort si elle n'existe pas\"\"\"\n",
    "    try:\n",
    "        conn = connect_to_database()\n",
    "        if not conn:\n",
    "            return False\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Vérifier si la colonne existe déjà\n",
    "        # La requête varie selon le type de base de données\n",
    "        \n",
    "        # Pour MySQL/MariaDB\n",
    "        check_column_sql = \"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM INFORMATION_SCHEMA.COLUMNS \n",
    "        WHERE TABLE_NAME = 'auteur' \n",
    "          AND COLUMN_NAME = 'date_mort'\n",
    "          AND TABLE_SCHEMA = DATABASE()\n",
    "        \"\"\"\n",
    "        \n",
    "        # Pour SQLite\n",
    "        # check_column_sql = \"PRAGMA table_info(auteur)\"\n",
    "        \n",
    "        cursor.execute(check_column_sql)\n",
    "        column_exists = cursor.fetchone()[0] > 0\n",
    "        \n",
    "        if not column_exists:\n",
    "            print(\"📝 Ajout de la colonne date_mort...\")\n",
    "            \n",
    "            # Ajouter la colonne\n",
    "            alter_sql = \"\"\"\n",
    "            ALTER TABLE auteur \n",
    "            ADD COLUMN date_mort VARCHAR(100) NULL \n",
    "            \"\"\"\n",
    "            \n",
    "            cursor.execute(alter_sql)\n",
    "            conn.commit()\n",
    "            print(\"✅ Colonne date_mort ajoutée avec succès\")\n",
    "        else:\n",
    "            print(\"ℹ️ La colonne date_mort existe déjà\")\n",
    "        \n",
    "        conn.close()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'ajout de la colonne : {e}\")\n",
    "        return False\n",
    "\n",
    "def update_death_dates_from_dataframe():\n",
    "    \"\"\"Mettre à jour les dates de mort depuis le DataFrame des auteurs\"\"\"\n",
    "    \n",
    "    # Vérifier si nous avons des données d'auteurs avec dates de naissance\n",
    "    if 'df_authors_birth' not in globals():\n",
    "        print(\"❌ DataFrame 'df_authors_birth' non trouvé\")\n",
    "        print(\"   Veuillez d'abord exécuter l'extraction des auteurs (cellules 16-18)\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        conn = connect_to_database()\n",
    "        if not conn:\n",
    "            return False\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Filtrer les auteurs avec date de mort\n",
    "        authors_with_death = df_authors_birth[\n",
    "            (df_authors_birth['death_date'].notna()) & \n",
    "            (df_authors_birth['death_date'] != '')\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"🔍 Trouvé {len(authors_with_death):,} auteurs avec date de mort\")\n",
    "        \n",
    "        if len(authors_with_death) == 0:\n",
    "            print(\"ℹ️ Aucun auteur avec date de mort à mettre à jour\")\n",
    "            return True\n",
    "        \n",
    "        # Préparer les données pour la mise à jour\n",
    "        updates_made = 0\n",
    "        \n",
    "        for _, author in authors_with_death.iterrows():\n",
    "            author_id = author['author_id']\n",
    "            death_date = author['death_date']\n",
    "            \n",
    "            # Chercher l'auteur dans la base par ID OpenLibrary\n",
    "            find_sql = \"SELECT id_auteur FROM auteur WHERE id_auteur LIKE %s\"\n",
    "            cursor.execute(find_sql, (f\"%{author_id}%\",))\n",
    "            result = cursor.fetchone()\n",
    "            \n",
    "            if result:\n",
    "                # Mettre à jour la date de mort\n",
    "                update_sql = \"\"\"\n",
    "                UPDATE auteur \n",
    "                SET date_mort = %s \n",
    "                WHERE id_auteur LIKE %s\n",
    "                \"\"\"\n",
    "                cursor.execute(update_sql, (death_date, f\"%{author_id}%\"))\n",
    "                updates_made += 1\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"✅ Mise à jour terminée : {updates_made:,} auteurs mis à jour\")\n",
    "        \n",
    "        conn.close()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de la mise à jour : {e}\")\n",
    "        return False\n",
    "\n",
    "def create_author_mapping():\n",
    "    \"\"\"Créer un mapping entre les auteurs OpenLibrary et la base locale\"\"\"\n",
    "    \n",
    "    if 'df_authors_birth' not in globals():\n",
    "        print(\"❌ DataFrame 'df_authors_birth' non trouvé\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        conn = connect_to_database()\n",
    "        if not conn:\n",
    "            return None\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Récupérer tous les auteurs de la base locale\n",
    "        cursor.execute(\"SELECT id_auteur, nom FROM auteur\")\n",
    "        local_authors = cursor.fetchall()\n",
    "        \n",
    "        print(f\"📊 Auteurs dans la base locale : {len(local_authors):,}\")\n",
    "        print(f\"📊 Auteurs OpenLibrary avec dates : {len(df_authors_birth):,}\")\n",
    "        \n",
    "        # Créer un DataFrame de mapping\n",
    "        mapping_data = []\n",
    "        \n",
    "        for local_id, local_name in local_authors:\n",
    "            # Chercher des correspondances par nom\n",
    "            matches = df_authors_birth[\n",
    "                df_authors_birth['name'].str.contains(local_name, case=False, na=False)\n",
    "            ]\n",
    "            \n",
    "            if len(matches) > 0:\n",
    "                best_match = matches.iloc[0]  # Prendre la première correspondance\n",
    "                mapping_data.append({\n",
    "                    'local_id': local_id,\n",
    "                    'local_name': local_name,\n",
    "                    'openlibrary_id': best_match['author_id'],\n",
    "                    'openlibrary_name': best_match['name'],\n",
    "                    'birth_date': best_match['birth_date'],\n",
    "                    'death_date': best_match['death_date'],\n",
    "                    'birth_year': best_match['birth_year'],\n",
    "                    'death_year': best_match['death_year']\n",
    "                })\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        if mapping_data:\n",
    "            mapping_df = pd.DataFrame(mapping_data)\n",
    "            print(f\"✅ Correspondances trouvées : {len(mapping_df):,}\")\n",
    "            return mapping_df\n",
    "        else:\n",
    "            print(\"❌ Aucune correspondance trouvée\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du mapping : {e}\")\n",
    "        return None\n",
    "\n",
    "# EXÉCUTION DES OPÉRATIONS\n",
    "print(\"🚀 DÉMARRAGE DES OPÉRATIONS DE BASE DE DONNÉES\")\n",
    "print()\n",
    "\n",
    "print(\"1️⃣ CONFIGURATION DE LA CONNEXION :\")\n",
    "print(\"   ⚠️  IMPORTANT : Configurez d'abord la fonction connect_to_database()\")\n",
    "print(\"   📝 Modifiez les paramètres de connexion selon votre base de données\")\n",
    "print()\n",
    "\n",
    "print(\"2️⃣ OPÉRATIONS DISPONIBLES :\")\n",
    "print(\"   • add_death_date_column() - Ajouter la colonne date_mort\")\n",
    "print(\"   • update_death_dates_from_dataframe() - Mettre à jour depuis OpenLibrary\")\n",
    "print(\"   • create_author_mapping() - Créer un mapping des correspondances\")\n",
    "print()\n",
    "\n",
    "print(\"💡 EXEMPLE D'UTILISATION :\")\n",
    "print(\"   # 1. Ajouter la colonne\")\n",
    "print(\"   # add_death_date_column()\")\n",
    "print(\"   # \")\n",
    "print(\"   # 2. Créer le mapping\")\n",
    "print(\"   # mapping_df = create_author_mapping()\")\n",
    "print(\"   # \")\n",
    "print(\"   # 3. Mettre à jour les dates\")\n",
    "print(\"   # update_death_dates_from_dataframe()\")\n",
    "\n",
    "print(\"\\n⚠️ ATTENTION : Configurez d'abord votre connexion à la base de données !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 EXTRACTION DIRECTE DES ÉDITIONS\n",
      "============================================================\n",
      "✅ Fichier d'éditions trouvé\n",
      "🔍 EXTRACTION DEPUIS : ol_dump_editions_2025-05-31.txt.gz\n",
      "   Limite : 10,000 éditions\n",
      "--------------------------------------------------\n",
      "   Ligne 10,000 - Éditions: 10,000 - Extraits: 10,000\n",
      "\n",
      "✅ EXTRACTION TERMINÉE :\n",
      "   • Total lignes lues : 10,001\n",
      "   • Éditions trouvées : 10,000\n",
      "   • Livres extraits : 10,000\n",
      "\n",
      "📊 ANALYSE DES LIVRES EXTRAITS\n",
      "==================================================\n",
      "📏 DataFrame créé : 10,000 livres × 15 colonnes\n",
      "\n",
      "📋 MÉTADONNÉES DISPONIBLES :\n",
      "   • title           : 10,000 (100.0%)\n",
      "   • publish_year    : 9,684 ( 96.8%)\n",
      "   • isbn_13         : 8,871 ( 88.7%)\n",
      "   • isbn_10         : 9,703 ( 97.0%)\n",
      "   • publishers      : 9,894 ( 98.9%)\n",
      "   • languages       : 6,608 ( 66.1%)\n",
      "   • authors         : 8,253 ( 82.5%)\n",
      "   • pages           : 6,710 ( 67.1%)\n",
      "\n",
      "📅 ANNÉES DE PUBLICATION :\n",
      "   • Range : 1657 - 2014\n",
      "   • Moyenne : 1995\n",
      "   • 1980s : 1,251 livres\n",
      "   • 1990s : 3,914 livres\n",
      "   • 2000s : 3,899 livres\n",
      "   • 2010s : 3 livres\n",
      "\n",
      "🌍 LANGUES LES PLUS FRÉQUENTES :\n",
      "   • eng        : 5,999 livres\n",
      "   • spa        : 174 livres\n",
      "   • ger        : 87 livres\n",
      "   • fre        : 73 livres\n",
      "   • ita        : 40 livres\n",
      "   • rus        : 32 livres\n",
      "   • por        : 23 livres\n",
      "   • ind        : 14 livres\n",
      "   • ara        : 13 livres\n",
      "\n",
      "📚 EXEMPLES DE LIVRES :\n",
      "----------------------------------------\n",
      "1. 📖 Index to the House of Lords Parliamentary Debates\n",
      "   Année : 1999\n",
      "   Éditeur : Stationery Office Books...\n",
      "   ISBN-13 : 9780107717629\n",
      "\n",
      "2. 📖 Northern Ireland (Emergency Provisions) Bill\n",
      "   Année : 1998\n",
      "   Éditeur : Stationery Office Books...\n",
      "   ISBN-13 : 9780108366253\n",
      "\n",
      "3. 📖 Sexual Offences (Amendment) Bill (House of Lords Bills)\n",
      "   Année : 1999\n",
      "   Éditeur : Stationery Office Books...\n",
      "   ISBN-13 : 9780108380273\n",
      "\n",
      "4. 📖 Access to Justice Bill [H.L.]\n",
      "   Année : 1999\n",
      "   Éditeur : Stationery Office Books...\n",
      "   ISBN-13 : 9780108383786\n",
      "\n",
      "5. 📖 Encyclopedia of designs for quilting\n",
      "   Année : 1996\n",
      "   Éditeur : American Quilter's Society...\n",
      "   Langue : eng\n",
      "\n",
      "\n",
      "💾 RÉSULTAT :\n",
      "   DataFrame 'df_livres' créé avec 10,000 livres\n",
      "\n",
      "📁 SAUVEGARDE :\n",
      "   df_livres.to_csv('livres_openlibrary.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTION DIRECTE DES ÉDITIONS\n",
    "print(\"📚 EXTRACTION DIRECTE DES ÉDITIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Utiliser le fichier d'éditions spécifique\n",
    "fichier_editions = r\"C:\\Users\\dd758\\Formation_IA_Greta\\Projet_possible certif\\Livre_analyse\\data_book\\databook\\data\\fichier_openlibrary\\ol_dump_editions_2025-05-31.txt.gz\"\n",
    "\n",
    "def extract_editions_simple(filename, max_books=5000):\n",
    "    \"\"\"Extraction simple et directe des éditions\"\"\"\n",
    "    print(f\"🔍 EXTRACTION DEPUIS : {os.path.basename(filename)}\")\n",
    "    print(f\"   Limite : {max_books:,} éditions\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    books_data = []\n",
    "    total_lines = 0\n",
    "    editions_processed = 0\n",
    "    books_extracted = 0\n",
    "    \n",
    "    try:\n",
    "        # Déterminer si le fichier est compressé\n",
    "        open_func = gzip.open if filename.endswith('.gz') else open\n",
    "        mode = 'rt' if filename.endswith('.gz') else 'r'\n",
    "        \n",
    "        with open_func(filename, mode, encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f):\n",
    "                total_lines += 1\n",
    "                \n",
    "                if books_extracted >= max_books:\n",
    "                    break\n",
    "                \n",
    "                # Traiter chaque ligne\n",
    "                parts = line.strip().split('\\t')\n",
    "                \n",
    "                # Vérifier la structure de la ligne\n",
    "                if len(parts) >= 5:\n",
    "                    entry_type = parts[0]\n",
    "                    \n",
    "                    # Ne traiter que les éditions\n",
    "                    if entry_type == '/type/edition':\n",
    "                        editions_processed += 1\n",
    "                        \n",
    "                        try:\n",
    "                            # Parser le JSON\n",
    "                            json_data = json.loads(parts[4])\n",
    "                            \n",
    "                            # Extraire les informations de base\n",
    "                            book_info = {\n",
    "                                'book_id': parts[1],\n",
    "                                'revision': parts[2],\n",
    "                                'created': parts[3],\n",
    "                                'title': json_data.get('title', ''),\n",
    "                                'subtitle': json_data.get('subtitle', ''),\n",
    "                                'publish_date': json_data.get('publish_date', ''),\n",
    "                                'publish_year': None,\n",
    "                                'isbn_10': '',\n",
    "                                'isbn_13': '',\n",
    "                                'publishers': '',\n",
    "                                'languages': '',\n",
    "                                'authors': '',\n",
    "                                'pages': json_data.get('number_of_pages', ''),\n",
    "                                'physical_format': json_data.get('physical_format', ''),\n",
    "                                'edition_name': json_data.get('edition_name', ''),\n",
    "                            }\n",
    "                            \n",
    "                            # Extraire l'année de publication\n",
    "                            if book_info['publish_date']:\n",
    "                                year_match = re.search(r'\\b(\\d{4})\\b', str(book_info['publish_date']))\n",
    "                                if year_match:\n",
    "                                    year = int(year_match.group(1))\n",
    "                                    if 1000 <= year <= datetime.now().year:\n",
    "                                        book_info['publish_year'] = year\n",
    "                            \n",
    "                            # Extraire ISBN\n",
    "                            if 'isbn_10' in json_data and json_data['isbn_10']:\n",
    "                                if isinstance(json_data['isbn_10'], list):\n",
    "                                    book_info['isbn_10'] = json_data['isbn_10'][0]  # Prendre le premier\n",
    "                                else:\n",
    "                                    book_info['isbn_10'] = str(json_data['isbn_10'])\n",
    "                            \n",
    "                            if 'isbn_13' in json_data and json_data['isbn_13']:\n",
    "                                if isinstance(json_data['isbn_13'], list):\n",
    "                                    book_info['isbn_13'] = json_data['isbn_13'][0]  # Prendre le premier\n",
    "                                else:\n",
    "                                    book_info['isbn_13'] = str(json_data['isbn_13'])\n",
    "                            \n",
    "                            # Extraire éditeurs\n",
    "                            if 'publishers' in json_data and json_data['publishers']:\n",
    "                                if isinstance(json_data['publishers'], list):\n",
    "                                    book_info['publishers'] = json_data['publishers'][0]  # Prendre le premier\n",
    "                                else:\n",
    "                                    book_info['publishers'] = str(json_data['publishers'])\n",
    "                            \n",
    "                            # Extraire langues\n",
    "                            if 'languages' in json_data and json_data['languages']:\n",
    "                                languages = []\n",
    "                                for lang in json_data['languages']:\n",
    "                                    if isinstance(lang, dict) and 'key' in lang:\n",
    "                                        lang_code = lang['key'].replace('/languages/', '')\n",
    "                                        languages.append(lang_code)\n",
    "                                    else:\n",
    "                                        languages.append(str(lang))\n",
    "                                book_info['languages'] = languages[0] if languages else ''  # Prendre la première\n",
    "                            \n",
    "                            # Extraire auteurs (IDs seulement pour simplicité)\n",
    "                            if 'authors' in json_data and json_data['authors']:\n",
    "                                authors = []\n",
    "                                for author in json_data['authors']:\n",
    "                                    if isinstance(author, dict) and 'key' in author:\n",
    "                                        authors.append(author['key'])\n",
    "                                    else:\n",
    "                                        authors.append(str(author))\n",
    "                                book_info['authors'] = authors[0] if authors else ''  # Prendre le premier\n",
    "                            \n",
    "                            # Ajouter le livre seulement s'il a un titre\n",
    "                            if book_info['title']:\n",
    "                                books_data.append(book_info)\n",
    "                                books_extracted += 1\n",
    "                        \n",
    "                        except json.JSONDecodeError as e:\n",
    "                            # Ignorer les erreurs JSON\n",
    "                            continue\n",
    "                        except Exception as e:\n",
    "                            # Ignorer les autres erreurs\n",
    "                            continue\n",
    "                \n",
    "                # Afficher le progrès\n",
    "                if total_lines % 10000 == 0:\n",
    "                    print(f\"   Ligne {total_lines:,} - Éditions: {editions_processed:,} - Extraits: {books_extracted:,}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'extraction : {e}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n✅ EXTRACTION TERMINÉE :\")\n",
    "    print(f\"   • Total lignes lues : {total_lines:,}\")\n",
    "    print(f\"   • Éditions trouvées : {editions_processed:,}\")\n",
    "    print(f\"   • Livres extraits : {books_extracted:,}\")\n",
    "    \n",
    "    return books_data\n",
    "\n",
    "def analyze_simple_books(books_data):\n",
    "    \"\"\"Analyse simple des livres extraits\"\"\"\n",
    "    if not books_data:\n",
    "        print(\"❌ Aucune donnée à analyser\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n📊 ANALYSE DES LIVRES EXTRAITS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    df = pd.DataFrame(books_data)\n",
    "    print(f\"📏 DataFrame créé : {df.shape[0]:,} livres × {df.shape[1]} colonnes\")\n",
    "    \n",
    "    # Statistiques de base\n",
    "    print(f\"\\n📋 MÉTADONNÉES DISPONIBLES :\")\n",
    "    for col in ['title', 'publish_year', 'isbn_13', 'isbn_10', 'publishers', 'languages', 'authors', 'pages']:\n",
    "        if col in df.columns:\n",
    "            non_empty = df[col].notna() & (df[col] != '')\n",
    "            percentage = (non_empty.sum() / len(df)) * 100\n",
    "            print(f\"   • {col:<15} : {non_empty.sum():>5,} ({percentage:>5.1f}%)\")\n",
    "    \n",
    "    # Années de publication\n",
    "    if 'publish_year' in df.columns:\n",
    "        years = df['publish_year'].dropna()\n",
    "        if len(years) > 0:\n",
    "            print(f\"\\n📅 ANNÉES DE PUBLICATION :\")\n",
    "            print(f\"   • Range : {years.min():.0f} - {years.max():.0f}\")\n",
    "            print(f\"   • Moyenne : {years.mean():.0f}\")\n",
    "            \n",
    "            # Quelques décennies récentes\n",
    "            for decade in [1980, 1990, 2000, 2010, 2020]:\n",
    "                count = years[(years >= decade) & (years < decade + 10)].count()\n",
    "                if count > 0:\n",
    "                    print(f\"   • {decade}s : {count:,} livres\")\n",
    "    \n",
    "    # Langues\n",
    "    if 'languages' in df.columns:\n",
    "        lang_counts = df['languages'].value_counts().head(10)\n",
    "        print(f\"\\n🌍 LANGUES LES PLUS FRÉQUENTES :\")\n",
    "        for lang, count in lang_counts.items():\n",
    "            if lang and lang != '':\n",
    "                print(f\"   • {lang:<10} : {count:,} livres\")\n",
    "    \n",
    "    # Quelques exemples\n",
    "    print(f\"\\n📚 EXEMPLES DE LIVRES :\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    sample_books = df.head(5)\n",
    "    for i, (_, book) in enumerate(sample_books.iterrows(), 1):\n",
    "        print(f\"{i}. 📖 {book['title']}\")\n",
    "        if pd.notna(book['publish_year']):\n",
    "            print(f\"   Année : {book['publish_year']:.0f}\")\n",
    "        if pd.notna(book['publishers']) and book['publishers']:\n",
    "            print(f\"   Éditeur : {book['publishers'][:50]}...\")\n",
    "        if pd.notna(book['languages']) and book['languages']:\n",
    "            print(f\"   Langue : {book['languages']}\")\n",
    "        if pd.notna(book['isbn_13']) and book['isbn_13']:\n",
    "            print(f\"   ISBN-13 : {book['isbn_13']}\")\n",
    "        print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# EXÉCUTION DE L'EXTRACTION\n",
    "if os.path.exists(fichier_editions):\n",
    "    print(f\"✅ Fichier d'éditions trouvé\")\n",
    "    \n",
    "    # Extraire les livres\n",
    "    books_data = extract_editions_simple(fichier_editions, max_books=10000)\n",
    "    \n",
    "    if books_data and len(books_data) > 0:\n",
    "        # Analyser les résultats\n",
    "        df_livres = analyze_simple_books(books_data)\n",
    "        \n",
    "        print(f\"\\n💾 RÉSULTAT :\")\n",
    "        print(f\"   DataFrame 'df_livres' créé avec {len(books_data):,} livres\")\n",
    "        print(f\"\\n📁 SAUVEGARDE :\")\n",
    "        print(f\"   df_livres.to_csv('livres_openlibrary.csv', index=False)\")\n",
    "    else:\n",
    "        print(\"❌ Aucun livre extrait\")\n",
    "\n",
    "else:\n",
    "    print(f\"❌ Fichier d'éditions non trouvé : {fichier_editions}\")\n",
    "    print(f\"\\n📁 Fichiers disponibles dans le répertoire :\")\n",
    "    if os.path.exists(os.path.dirname(fichier_editions)):\n",
    "        for f in os.listdir(os.path.dirname(fichier_editions)):\n",
    "            print(f\"   • {f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatage objet livre pour pouvoir les insérer dans la base de données sql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
